{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_External_Lab_Ques_CIFAR10_Transfer_Learning_TFIDF_Text_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGIsF1ADyJ58",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-n6tVFayGBe",
        "colab_type": "text"
      },
      "source": [
        "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq8ejXHJyGYq",
        "colab_type": "text"
      },
      "source": [
        "### 1. Import CIFAR10 data and create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWYbxnBayFUP",
        "colab_type": "code",
        "outputId": "23323e0f-d245-4a97-9769-fc00dc7ee1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(trainX, trainY),(testX, testY) = tf.keras.datasets.cifar10.load_data()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTY2ReEhboVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9pOiPmUork6",
        "colab_type": "text"
      },
      "source": [
        "## **Dependencies along with all the data is loaded to the notebook**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6RP_d1XZ3GU",
        "colab_type": "code",
        "outputId": "375d355a-0565-4580-a90e-db20ca13d8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(trainY)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSnA-4tpaRg5",
        "colab_type": "code",
        "outputId": "ec8379a0-ea6a-46e2-abb3-7f1b8d8f35be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(trainX)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwn0rL_FkrzV",
        "colab_type": "code",
        "outputId": "279d4aee-5c25-4810-d2b5-b4f9f1b081ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p = trainY>=5\n",
        "\n",
        "p = p.reshape(50000,)\n",
        "p.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "888vqOLrU3KX",
        "colab_type": "code",
        "outputId": "d4e945da-0409-4c3f-9f55-bfab4140f984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX59 = trainX[p,:,:,:] \n",
        "trainX59.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rUrpw8-t-Uh",
        "colab_type": "code",
        "outputId": "88705197-e80b-44d7-c92a-49a6e8869d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainY59 = trainY[p,:]\n",
        "trainY59.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3w0LYgtYmND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThHoT7xJVuUW",
        "colab_type": "code",
        "outputId": "db88eba4-0954-4b22-9b9a-bacf320b23db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p = testY>=5\n",
        "\n",
        "p = p.reshape(10000,)\n",
        "p.shape\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwhCKqa5W7bY",
        "colab_type": "code",
        "outputId": "56f299ba-92fa-4014-ad6a-40b3550f55a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testX59 = testX[p,:,:,:] \n",
        "testX59.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGSKMR4ZXkE2",
        "colab_type": "code",
        "outputId": "bad7577b-5def-4345-eb3a-fe04585955c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testY59 = testY[p,:]\n",
        "testY59.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OoGxlC9XAso",
        "colab_type": "code",
        "outputId": "70dd72ab-05eb-4780-bd3e-34c038933b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p = trainY<5\n",
        "\n",
        "p = p.reshape(50000,)\n",
        "p.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByJg2JMHWxwc",
        "colab_type": "code",
        "outputId": "04ee918d-d182-49a8-e508-dc8f620b420b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX04 = trainX[p,:,:,:] \n",
        "trainX04.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c80ohah_Wx1P",
        "colab_type": "code",
        "outputId": "1ea3a626-911b-4d30-e177-d31e15c5fe17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainY04 = trainY[p,:]\n",
        "trainY04.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io6pTfOBWx39",
        "colab_type": "code",
        "outputId": "7542d119-cca1-4f30-a848-962747325166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p = testY<5\n",
        "\n",
        "p = p.reshape(10000,)\n",
        "p.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEFGQfpGWx6f",
        "colab_type": "code",
        "outputId": "a5039586-7a5a-4a95-8b62-267740e7bb30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testX04 = testX[p,:,:,:] \n",
        "testX04.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLaBUEoVWx9M",
        "colab_type": "code",
        "outputId": "024603d6-22bd-403c-d22c-d0a36b60af7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testY04 = testY[p,:]\n",
        "testY04.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU0dcCB0Y6ar",
        "colab_type": "code",
        "outputId": "ff305e42-d160-4611-f575-e49650549d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(np.unique(trainY59))\n",
        "print(np.unique(testY59))\n",
        "print(np.unique(trainY04))\n",
        "print(np.unique(testY04))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 6 7 8 9]\n",
            "[5 6 7 8 9]\n",
            "[0 1 2 3 4]\n",
            "[0 1 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wxxMw1So8WQ",
        "colab_type": "text"
      },
      "source": [
        "## **The data has been separated as per the class. 0-4 has been separated in to a separate set of training and testing sets. The values with classes 5-9 have been separated to a separate training and testing sets.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtCKmQh4yXhT",
        "colab_type": "text"
      },
      "source": [
        "### 2. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN5O2kJ3yYa6",
        "colab_type": "code",
        "outputId": "d71c4c48-ab4e-44bc-bc61-a3575dcbf99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y04 = tf.keras.utils.to_categorical(trainY04, num_classes=5)\n",
        "test_y04 = tf.keras.utils.to_categorical(testY04, num_classes=5)\n",
        "train_y04.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZRmJ0dYZ2dN",
        "colab_type": "code",
        "outputId": "fe3b575c-6af3-4548-8ba7-6d7f1aa4b4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "oh = OneHotEncoder()\n",
        "train_y59 = oh.fit_transform(trainY59)\n",
        "test_y59 = oh.transform(testY59)\n",
        "train_y59.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kki5dBEPajMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuOiKWfeybAl",
        "colab_type": "text"
      },
      "source": [
        "### 3. Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HzxNbiiyoBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgy8FxmXpRa2",
        "colab_type": "text"
      },
      "source": [
        "## **Model is now being built**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IXruOry648i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clear any previous model from memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Initialize model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#normalize data\n",
        "model.add(BatchNormalization(input_shape=(32,32,3,)))\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "#normalize data\n",
        "model.add(BatchNormalization(input_shape=(32,32,3,)))\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "#Add Max Pool layer\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides = 2))\n",
        "\n",
        "#normalize data\n",
        "model.add(BatchNormalization(input_shape=(32,32,3,)))\n",
        "\n",
        "#Add Dense Layers after flattening the data\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Add Dropout\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Add Output Layer\n",
        "model.add(Dense(5, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il_fYJ1tcsG_",
        "colab_type": "code",
        "outputId": "bbe9ebc0-bf5f-497d-d75f-cd5e047a72d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 32, 32, 3)         12        \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 30, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 6,723,601\n",
            "Trainable params: 6,722,827\n",
            "Non-trainable params: 774\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aDjdtBkcs4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PWs1dhYkcAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the best model using model checkpoint callback\n",
        "model_checkpoint=tf.keras.callbacks.ModelCheckpoint('first_model.h5', \n",
        "                                                    save_best_only=True, \n",
        "                                                    monitor='val_accuracy', \n",
        "                                                    mode='max', \n",
        "                                                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Q2OahAcvuX",
        "colab_type": "code",
        "outputId": "4640940f-2eae-4347-c8d3-eeedfb5705c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train the model\n",
        "model.fit(trainX04,train_y04,          \n",
        "          validation_data=(testX04,test_y04),\n",
        "          epochs=20,\n",
        "          \n",
        "          callbacks = [model_checkpoint],\n",
        "          batch_size=32,\n",
        "          )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9436\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.79780, saving model to first_model.h5\n",
            "25000/25000 [==============================] - 7s 294us/sample - loss: 0.1580 - accuracy: 0.9436 - val_loss: 1.0356 - val_accuracy: 0.7978\n",
            "Epoch 2/20\n",
            "24832/25000 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.9516\n",
            "Epoch 00002: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 293us/sample - loss: 0.1355 - accuracy: 0.9517 - val_loss: 1.0381 - val_accuracy: 0.7910\n",
            "Epoch 3/20\n",
            "24832/25000 [============================>.] - ETA: 0s - loss: 0.1341 - accuracy: 0.9525\n",
            "Epoch 00003: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 291us/sample - loss: 0.1345 - accuracy: 0.9523 - val_loss: 0.9531 - val_accuracy: 0.7948\n",
            "Epoch 4/20\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9576\n",
            "Epoch 00004: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 292us/sample - loss: 0.1223 - accuracy: 0.9575 - val_loss: 1.1156 - val_accuracy: 0.7900\n",
            "Epoch 5/20\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.9566\n",
            "Epoch 00005: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 288us/sample - loss: 0.1225 - accuracy: 0.9566 - val_loss: 1.0089 - val_accuracy: 0.7874\n",
            "Epoch 6/20\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9576\n",
            "Epoch 00006: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 288us/sample - loss: 0.1189 - accuracy: 0.9575 - val_loss: 1.0086 - val_accuracy: 0.7888\n",
            "Epoch 7/20\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.1086 - accuracy: 0.9624\n",
            "Epoch 00007: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 291us/sample - loss: 0.1086 - accuracy: 0.9624 - val_loss: 1.1873 - val_accuracy: 0.7976\n",
            "Epoch 8/20\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.1207 - accuracy: 0.9600\n",
            "Epoch 00008: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 291us/sample - loss: 0.1206 - accuracy: 0.9600 - val_loss: 1.3374 - val_accuracy: 0.7966\n",
            "Epoch 9/20\n",
            "24832/25000 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9629\n",
            "Epoch 00009: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 297us/sample - loss: 0.1125 - accuracy: 0.9630 - val_loss: 1.1555 - val_accuracy: 0.7958\n",
            "Epoch 10/20\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.1023 - accuracy: 0.9645\n",
            "Epoch 00010: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 296us/sample - loss: 0.1025 - accuracy: 0.9644 - val_loss: 1.2815 - val_accuracy: 0.7932\n",
            "Epoch 11/20\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9651\n",
            "Epoch 00011: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 290us/sample - loss: 0.0993 - accuracy: 0.9650 - val_loss: 1.2834 - val_accuracy: 0.7884\n",
            "Epoch 12/20\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.0950 - accuracy: 0.9686\n",
            "Epoch 00012: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 290us/sample - loss: 0.0950 - accuracy: 0.9686 - val_loss: 1.2989 - val_accuracy: 0.7862\n",
            "Epoch 13/20\n",
            "24832/25000 [============================>.] - ETA: 0s - loss: 0.0894 - accuracy: 0.9694\n",
            "Epoch 00013: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 287us/sample - loss: 0.0895 - accuracy: 0.9694 - val_loss: 1.3046 - val_accuracy: 0.7970\n",
            "Epoch 14/20\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9675\n",
            "Epoch 00014: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 289us/sample - loss: 0.0967 - accuracy: 0.9675 - val_loss: 1.3533 - val_accuracy: 0.7860\n",
            "Epoch 15/20\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9696\n",
            "Epoch 00015: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 292us/sample - loss: 0.0880 - accuracy: 0.9696 - val_loss: 1.3856 - val_accuracy: 0.7894\n",
            "Epoch 16/20\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9677\n",
            "Epoch 00016: val_accuracy did not improve from 0.79780\n",
            "25000/25000 [==============================] - 7s 291us/sample - loss: 0.0977 - accuracy: 0.9677 - val_loss: 1.2396 - val_accuracy: 0.7650\n",
            "Epoch 17/20\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 0.9724\n",
            "Epoch 00017: val_accuracy improved from 0.79780 to 0.80000, saving model to first_model.h5\n",
            "25000/25000 [==============================] - 7s 294us/sample - loss: 0.0805 - accuracy: 0.9724 - val_loss: 1.5333 - val_accuracy: 0.8000\n",
            "Epoch 18/20\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 0.9736\n",
            "Epoch 00018: val_accuracy did not improve from 0.80000\n",
            "25000/25000 [==============================] - 7s 291us/sample - loss: 0.0768 - accuracy: 0.9736 - val_loss: 1.2965 - val_accuracy: 0.7954\n",
            "Epoch 19/20\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 0.9718\n",
            "Epoch 00019: val_accuracy did not improve from 0.80000\n",
            "25000/25000 [==============================] - 7s 290us/sample - loss: 0.0887 - accuracy: 0.9718 - val_loss: 2.2393 - val_accuracy: 0.7874\n",
            "Epoch 20/20\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 0.9734\n",
            "Epoch 00020: val_accuracy did not improve from 0.80000\n",
            "25000/25000 [==============================] - 7s 287us/sample - loss: 0.0823 - accuracy: 0.9732 - val_loss: 1.2672 - val_accuracy: 0.7988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb40e721a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz5lG8oHpbYH",
        "colab_type": "text"
      },
      "source": [
        "## **The best model is saved as \"first_model.h5\". The accuracy of the model is 80%. This model will now be loaded and the weights of the Convulational Layers will be \"Transfered\" to the new model.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woTfNst_ynRG",
        "colab_type": "text"
      },
      "source": [
        "### 4. In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIIMh0IwflgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model = load_model('first_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4QrLVdjm5zI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "ff27bbe4-9a56-4501-b53a-bddb670dc174"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 32, 32, 3)         12        \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 30, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 6,723,601\n",
            "Trainable params: 6,722,827\n",
            "Non-trainable params: 774\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn25JnuipxOs",
        "colab_type": "text"
      },
      "source": [
        "## **The last layer of the model loaded is a softmax layer. That has to be removed before new layers can ba added to improve vaidation accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV2-r5y3m9Vn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "3abbcb31-4ffe-4f7f-ffde-f2ae65331d5e"
      },
      "source": [
        "new_model.pop()\n",
        "new_model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 32, 32, 3)         12        \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 30, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "=================================================================\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "Total params: 6,723,601\n",
            "Trainable params: 6,722,827\n",
            "Non-trainable params: 774\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_VCDB3Byb1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in new_model.layers[:7]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAyxCA7vqDRg",
        "colab_type": "text"
      },
      "source": [
        "## **With the last dense layer (softmax) removed, the Convolutional layers set to non trainable, we now add new layers to the loaded model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "408EOZP_f360",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b9TNcEWhEMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.add(Dense(128, activation='relu'))\n",
        "#Add Dropout\n",
        "new_model.add(Dropout(0.25))\n",
        "\n",
        "#Add Output Layer\n",
        "new_model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgKjDFW8hSvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVEbmpA8haGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Tr2nAPlqsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the best model using model checkpoint callback\n",
        "model_checkpoint=tf.keras.callbacks.ModelCheckpoint('second_model.h5', \n",
        "                                                    save_best_only=True, \n",
        "                                                    monitor='val_accuracy', \n",
        "                                                    mode='max', \n",
        "                                                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-uUPqWpyeyX",
        "colab_type": "text"
      },
      "source": [
        "### 5. Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10  (Use Transfer Learning) <br>\n",
        "Achieve an accuracy of more than 85% on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lElkCCfphbpv",
        "colab_type": "code",
        "outputId": "933071ec-19a2-43ae-f16c-224807676621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train the model\n",
        "new_model.fit(trainX59,train_y59.todense(),          \n",
        "          validation_data=(testX59,test_y59.todense()),\n",
        "          epochs=20,\n",
        "          callbacks = [model_checkpoint],\n",
        "          \n",
        "          batch_size=32,\n",
        "          )"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 1.6540 - accuracy: 0.5272\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.73520, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 214us/sample - loss: 1.6502 - accuracy: 0.5280 - val_loss: 0.8611 - val_accuracy: 0.7352\n",
            "Epoch 2/20\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.8070 - accuracy: 0.7193\n",
            "Epoch 00002: val_accuracy improved from 0.73520 to 0.80980, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 195us/sample - loss: 0.8066 - accuracy: 0.7195 - val_loss: 0.6467 - val_accuracy: 0.8098\n",
            "Epoch 3/20\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.7915\n",
            "Epoch 00003: val_accuracy improved from 0.80980 to 0.83220, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 195us/sample - loss: 0.5775 - accuracy: 0.7915 - val_loss: 0.5486 - val_accuracy: 0.8322\n",
            "Epoch 4/20\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.4490 - accuracy: 0.8384\n",
            "Epoch 00004: val_accuracy improved from 0.83220 to 0.84300, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 196us/sample - loss: 0.4493 - accuracy: 0.8384 - val_loss: 0.5120 - val_accuracy: 0.8430\n",
            "Epoch 5/20\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.3637 - accuracy: 0.8642\n",
            "Epoch 00005: val_accuracy improved from 0.84300 to 0.85580, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 197us/sample - loss: 0.3633 - accuracy: 0.8644 - val_loss: 0.4868 - val_accuracy: 0.8558\n",
            "Epoch 6/20\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.3048 - accuracy: 0.8849\n",
            "Epoch 00006: val_accuracy did not improve from 0.85580\n",
            "25000/25000 [==============================] - 5s 187us/sample - loss: 0.3050 - accuracy: 0.8850 - val_loss: 0.5198 - val_accuracy: 0.8546\n",
            "Epoch 7/20\n",
            "24800/25000 [============================>.] - ETA: 0s - loss: 0.2727 - accuracy: 0.8995\n",
            "Epoch 00007: val_accuracy did not improve from 0.85580\n",
            "25000/25000 [==============================] - 5s 190us/sample - loss: 0.2729 - accuracy: 0.8993 - val_loss: 0.5046 - val_accuracy: 0.8554\n",
            "Epoch 8/20\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.2371 - accuracy: 0.9097\n",
            "Epoch 00008: val_accuracy improved from 0.85580 to 0.85660, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 194us/sample - loss: 0.2370 - accuracy: 0.9098 - val_loss: 0.5568 - val_accuracy: 0.8566\n",
            "Epoch 9/20\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.2186 - accuracy: 0.9179\n",
            "Epoch 00009: val_accuracy improved from 0.85660 to 0.85940, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 200us/sample - loss: 0.2186 - accuracy: 0.9179 - val_loss: 0.5433 - val_accuracy: 0.8594\n",
            "Epoch 10/20\n",
            "24800/25000 [============================>.] - ETA: 0s - loss: 0.2043 - accuracy: 0.9226\n",
            "Epoch 00010: val_accuracy improved from 0.85940 to 0.85960, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 193us/sample - loss: 0.2042 - accuracy: 0.9225 - val_loss: 0.5563 - val_accuracy: 0.8596\n",
            "Epoch 11/20\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9266\n",
            "Epoch 00011: val_accuracy improved from 0.85960 to 0.86620, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 192us/sample - loss: 0.1916 - accuracy: 0.9266 - val_loss: 0.5603 - val_accuracy: 0.8662\n",
            "Epoch 12/20\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9324\n",
            "Epoch 00012: val_accuracy did not improve from 0.86620\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.1771 - accuracy: 0.9322 - val_loss: 0.5998 - val_accuracy: 0.8652\n",
            "Epoch 13/20\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.9356\n",
            "Epoch 00013: val_accuracy did not improve from 0.86620\n",
            "25000/25000 [==============================] - 5s 183us/sample - loss: 0.1752 - accuracy: 0.9356 - val_loss: 0.6194 - val_accuracy: 0.8640\n",
            "Epoch 14/20\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.1632 - accuracy: 0.9365\n",
            "Epoch 00014: val_accuracy did not improve from 0.86620\n",
            "25000/25000 [==============================] - 5s 184us/sample - loss: 0.1631 - accuracy: 0.9364 - val_loss: 0.6283 - val_accuracy: 0.8654\n",
            "Epoch 15/20\n",
            "24800/25000 [============================>.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9423\n",
            "Epoch 00015: val_accuracy improved from 0.86620 to 0.86740, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 188us/sample - loss: 0.1558 - accuracy: 0.9422 - val_loss: 0.6315 - val_accuracy: 0.8674\n",
            "Epoch 16/20\n",
            "24768/25000 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9419\n",
            "Epoch 00016: val_accuracy did not improve from 0.86740\n",
            "25000/25000 [==============================] - 5s 184us/sample - loss: 0.1574 - accuracy: 0.9413 - val_loss: 0.6380 - val_accuracy: 0.8666\n",
            "Epoch 17/20\n",
            "24704/25000 [============================>.] - ETA: 0s - loss: 0.1452 - accuracy: 0.9425\n",
            "Epoch 00017: val_accuracy did not improve from 0.86740\n",
            "25000/25000 [==============================] - 5s 184us/sample - loss: 0.1457 - accuracy: 0.9425 - val_loss: 0.6145 - val_accuracy: 0.8640\n",
            "Epoch 18/20\n",
            "24800/25000 [============================>.] - ETA: 0s - loss: 0.1375 - accuracy: 0.9477\n",
            "Epoch 00018: val_accuracy improved from 0.86740 to 0.87140, saving model to second_model.h5\n",
            "25000/25000 [==============================] - 5s 189us/sample - loss: 0.1380 - accuracy: 0.9476 - val_loss: 0.6816 - val_accuracy: 0.8714\n",
            "Epoch 19/20\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9462\n",
            "Epoch 00019: val_accuracy did not improve from 0.87140\n",
            "25000/25000 [==============================] - 5s 184us/sample - loss: 0.1435 - accuracy: 0.9463 - val_loss: 0.6575 - val_accuracy: 0.8660\n",
            "Epoch 20/20\n",
            "24672/25000 [============================>.] - ETA: 0s - loss: 0.1303 - accuracy: 0.9476\n",
            "Epoch 00020: val_accuracy did not improve from 0.87140\n",
            "25000/25000 [==============================] - 5s 185us/sample - loss: 0.1296 - accuracy: 0.9480 - val_loss: 0.7049 - val_accuracy: 0.8660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb40e30c3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVXYJQtWoTAS",
        "colab_type": "text"
      },
      "source": [
        "## **After transfer learning, the best model is saved in \"second_model.h5\". The validation accuracy of this saved model is 87.14%.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szHjJgDvyfCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zDuRecXzEtr",
        "colab_type": "text"
      },
      "source": [
        "# Text classification using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwzVKxm7t0FD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMPlEJhHzb6P",
        "colab_type": "text"
      },
      "source": [
        "### 6. Load the dataset from sklearn.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe-B59u3zHNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRrMemVQzbHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sZX0UbJzmg5",
        "colab_type": "text"
      },
      "source": [
        "### 7. Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CITr_5aXziJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcESc5QXzr6p",
        "colab_type": "text"
      },
      "source": [
        "### 8. Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysInblUMzpvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DriL2yZ50DQq",
        "colab_type": "text"
      },
      "source": [
        "###  a.  You can access the values for the target variable using .target attribute \n",
        "###  b. You can access the name of the class in the target variable with .target_names\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlUuai99z1hX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = twenty_train.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEKzaDfSz5E-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35b7309d-29fa-462c-c702-030444e01b4d"
      },
      "source": [
        "twenty_train.target_names"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clBMKHzC0_N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = twenty_train.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoNk-1azrRBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = twenty_test.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0OSeTUruJaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = twenty_test.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTz4EaN_1WGc",
        "colab_type": "text"
      },
      "source": [
        "### 9.  Now with dependent and independent data available for both train and test datasets, using TfidfVectorizer fit and transform the training data and test data and get the tfidf features for both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5G477f81C0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a document-term matrix using TF-IDF\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "dtm_train = vect.fit_transform(data_train)\n",
        "dtm_test = vect.transform(data_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwHxH296uv38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ead66e0-aee7-4f99-c58a-56334d9b3123"
      },
      "source": [
        "dtm_train.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35482)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbbX1zxzu0g1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07578379-a402-4b21-aece-8a9fb4119e11"
      },
      "source": [
        "dtm_test.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1502, 35482)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttw3TdFfvNUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp_fDINJ1t4L",
        "colab_type": "text"
      },
      "source": [
        "### 10. Use logisticRegression with tfidf features as input and targets as output and train the model and report the train and test accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THlN2b5d1yQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74d81b16-d62d-4b58-ad2d-bf79da582d5d"
      },
      "source": [
        "logreg = LogisticRegression(C=1e9)\n",
        "logreg.fit(dtm_train, y_train)\n",
        "y_pred_class = logreg.predict(dtm_test)\n",
        "print(\"Test accuracy score\", metrics.accuracy_score(y_test, y_pred_class))\n",
        "y_pred_class = logreg.predict(dtm_train)\n",
        "print(\"Train accuracy score\", metrics.accuracy_score(y_train, y_pred_class))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy score 0.9174434087882823\n",
            "Train accuracy score 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}