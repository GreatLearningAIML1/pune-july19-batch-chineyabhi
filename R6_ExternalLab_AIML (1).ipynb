{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_ExternalLab_AIML (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYk8NG3yOIT9",
        "colab_type": "text"
      },
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFO6PuxzOIT_",
        "colab_type": "text"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNjNImfOIUC",
        "colab_type": "code",
        "outputId": "64b87fb3-816b-43b1-c090-8f52d167945a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "seed = 42\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9C4aAIGOIUH",
        "colab_type": "code",
        "outputId": "5c96924e-fae6-4a08-d53b-0292d2eefc54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXCUq451aNDu",
        "colab_type": "text"
      },
      "source": [
        "- Ensuring that Tensorflow 2.0.0 is the version running in this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcoZBStrOIUQ",
        "colab_type": "text"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA1WsFSeOIUS",
        "colab_type": "code",
        "outputId": "d9f00e0d-e7ea-46b2-f7ec-8d123067c30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnbx7TyQOIUY",
        "colab_type": "code",
        "outputId": "84151650-d1c5-4181-f59d-f8a123d66aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 1us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbiHj5YPOIUc",
        "colab_type": "code",
        "outputId": "2ad9a355-612e-4612-bc61-b6f092f45df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6yo-ffaaUtg",
        "colab_type": "text"
      },
      "source": [
        "- Data has been loaded correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDAYzkwyOIUj",
        "colab_type": "text"
      },
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlfYlANOIUk",
        "colab_type": "code",
        "outputId": "57bb5bb5-63ee-47bc-d4f9-271195cb23b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)\n",
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:2])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "('First 5 examples now are: ', array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RHV3b9mzOIUq",
        "colab_type": "code",
        "outputId": "c9eabc2f-839e-4ed9-8405-1fbe401b5914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "('First 5 examples now are: ', array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwhQ8e7VOIUw",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDML2OoOIUx",
        "colab_type": "code",
        "outputId": "a635cd1c-0d8c-41af-92d6-5b03e914e496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# visualizing the first 10 images in the dataset and their labels\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(trainX[i].reshape(28, 28), cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "    print('label for each of the below image: %s' % (np.argmax(trainY[0:10][i])))\n",
        "plt.show()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label for each of the below image: 9\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 3\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 2\n",
            "label for each of the below image: 7\n",
            "label for each of the below image: 2\n",
            "label for each of the below image: 5\n",
            "label for each of the below image: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABSCAYAAABwglFkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRVEURVF88P8A0wyYl+ZpGWEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4TbJGeSOIU4",
        "colab_type": "text"
      },
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac06XZZTOIU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "#model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQpLv3aOIU_",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59C_-IgOIVB",
        "colab_type": "code",
        "outputId": "a496035b-5681-4e94-c8a7-da52cb9789b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
        "          batch_size = trainX.shape[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 164.5089 - accuracy: 0.1696 - val_loss: 6984.9458 - val_accuracy: 0.1975\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 0s 8us/sample - loss: 6954.1870 - accuracy: 0.1982 - val_loss: 11586.7793 - val_accuracy: 0.3287\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 11622.5703 - accuracy: 0.3359 - val_loss: 13518.5713 - val_accuracy: 0.2733\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 13541.5186 - accuracy: 0.2722 - val_loss: 14069.8115 - val_accuracy: 0.2747\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 14032.1650 - accuracy: 0.2766 - val_loss: 16005.6895 - val_accuracy: 0.1651\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 15936.8896 - accuracy: 0.1653 - val_loss: 10311.0557 - val_accuracy: 0.3000\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 10250.9785 - accuracy: 0.3000 - val_loss: 11711.8174 - val_accuracy: 0.1912\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 11634.1016 - accuracy: 0.1926 - val_loss: 11965.7139 - val_accuracy: 0.2557\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 11836.0449 - accuracy: 0.2507 - val_loss: 7693.0537 - val_accuracy: 0.3027\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 7584.5444 - accuracy: 0.3058 - val_loss: 4902.6919 - val_accuracy: 0.4234\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 4788.7993 - accuracy: 0.4256 - val_loss: 5001.6758 - val_accuracy: 0.4459\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 4908.5708 - accuracy: 0.4572 - val_loss: 5483.5151 - val_accuracy: 0.4591\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 5404.4463 - accuracy: 0.4669 - val_loss: 4085.7432 - val_accuracy: 0.5580\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 4027.9878 - accuracy: 0.5700 - val_loss: 3532.7708 - val_accuracy: 0.5452\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3509.1851 - accuracy: 0.5494 - val_loss: 3059.5161 - val_accuracy: 0.5590\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3004.1514 - accuracy: 0.5664 - val_loss: 4514.4038 - val_accuracy: 0.4460\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 4433.9028 - accuracy: 0.4536 - val_loss: 6215.8862 - val_accuracy: 0.5423\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 6164.3057 - accuracy: 0.5446 - val_loss: 4466.3062 - val_accuracy: 0.5839\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 4404.5396 - accuracy: 0.5901 - val_loss: 2951.3086 - val_accuracy: 0.5935\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2916.1418 - accuracy: 0.5947 - val_loss: 2166.5449 - val_accuracy: 0.5491\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2097.8181 - accuracy: 0.5605 - val_loss: 2322.8364 - val_accuracy: 0.5786\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2282.2073 - accuracy: 0.5773 - val_loss: 3282.9219 - val_accuracy: 0.5516\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3158.3359 - accuracy: 0.5583 - val_loss: 4609.0264 - val_accuracy: 0.6183\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 4517.3262 - accuracy: 0.6239 - val_loss: 5094.6919 - val_accuracy: 0.5740\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 5018.3003 - accuracy: 0.5810 - val_loss: 3356.6809 - val_accuracy: 0.6301\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3280.5552 - accuracy: 0.6355 - val_loss: 2241.6787 - val_accuracy: 0.5736\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2160.5269 - accuracy: 0.5826 - val_loss: 3435.8083 - val_accuracy: 0.6704\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3382.4421 - accuracy: 0.6778 - val_loss: 3141.9419 - val_accuracy: 0.6532\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3092.4922 - accuracy: 0.6595 - val_loss: 2952.1709 - val_accuracy: 0.6677\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2884.1121 - accuracy: 0.6692 - val_loss: 2378.5813 - val_accuracy: 0.6272\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2311.8320 - accuracy: 0.6343 - val_loss: 3512.8264 - val_accuracy: 0.6328\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3444.2017 - accuracy: 0.6372 - val_loss: 3906.7317 - val_accuracy: 0.6591\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3821.6609 - accuracy: 0.6647 - val_loss: 1790.1892 - val_accuracy: 0.6594\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 1731.6643 - accuracy: 0.6670 - val_loss: 2084.7373 - val_accuracy: 0.6926\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2033.1555 - accuracy: 0.6997 - val_loss: 2080.1133 - val_accuracy: 0.6650\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2018.3485 - accuracy: 0.6654 - val_loss: 2637.4482 - val_accuracy: 0.5923\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2551.7629 - accuracy: 0.6017 - val_loss: 3954.1863 - val_accuracy: 0.6445\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3904.3291 - accuracy: 0.6496 - val_loss: 3577.0083 - val_accuracy: 0.6368\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3494.7727 - accuracy: 0.6403 - val_loss: 2181.1201 - val_accuracy: 0.6485\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2134.6792 - accuracy: 0.6528 - val_loss: 2641.5320 - val_accuracy: 0.6076\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2519.3855 - accuracy: 0.6197 - val_loss: 3270.1853 - val_accuracy: 0.6727\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3203.4885 - accuracy: 0.6786 - val_loss: 3151.7156 - val_accuracy: 0.6434\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 3086.7317 - accuracy: 0.6495 - val_loss: 2349.1528 - val_accuracy: 0.6894\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2276.4294 - accuracy: 0.6924 - val_loss: 2584.7148 - val_accuracy: 0.6151\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 0s 6us/sample - loss: 2474.0154 - accuracy: 0.6223 - val_loss: 3509.1372 - val_accuracy: 0.6836\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3448.6479 - accuracy: 0.6922 - val_loss: 3289.0637 - val_accuracy: 0.6703\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 3209.4319 - accuracy: 0.6743 - val_loss: 1881.7155 - val_accuracy: 0.6748\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 1830.0807 - accuracy: 0.6787 - val_loss: 2518.3867 - val_accuracy: 0.6153\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2386.5706 - accuracy: 0.6295 - val_loss: 3032.8188 - val_accuracy: 0.6802\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 0s 7us/sample - loss: 2973.6465 - accuracy: 0.6867 - val_loss: 2416.1299 - val_accuracy: 0.6726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdbce27ba10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ueke1f5fafLm",
        "colab_type": "text"
      },
      "source": [
        "- The network gives around 68% training accuracy and 66% validation accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzDtGwDOIVF",
        "colab_type": "text"
      },
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndfpdidOIVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwk3T5LJOIVN",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLR8tcBOIVP",
        "colab_type": "code",
        "outputId": "0bccc0e8-2e14-43d3-ba55-5745950ac786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
        "          batch_size = trainX.shape[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 2.7075 - accuracy: 0.1307 - val_loss: 29.4049 - val_accuracy: 0.1855\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.4365 - accuracy: 0.1928 - val_loss: 18.1263 - val_accuracy: 0.2078\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.2217 - accuracy: 0.2528 - val_loss: 13.0290 - val_accuracy: 0.2278\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 2.0491 - accuracy: 0.3039 - val_loss: 10.0210 - val_accuracy: 0.2511\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.9084 - accuracy: 0.3467 - val_loss: 8.0158 - val_accuracy: 0.2682\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.7924 - accuracy: 0.3822 - val_loss: 6.5887 - val_accuracy: 0.2849\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.6958 - accuracy: 0.4147 - val_loss: 5.5382 - val_accuracy: 0.3044\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.6144 - accuracy: 0.4425 - val_loss: 4.7559 - val_accuracy: 0.3266\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.5454 - accuracy: 0.4673 - val_loss: 4.1720 - val_accuracy: 0.3539\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.4863 - accuracy: 0.4892 - val_loss: 3.7325 - val_accuracy: 0.3788\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.4352 - accuracy: 0.5082 - val_loss: 3.3957 - val_accuracy: 0.3997\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3907 - accuracy: 0.5234 - val_loss: 3.1309 - val_accuracy: 0.4152\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.3515 - accuracy: 0.5376 - val_loss: 2.9169 - val_accuracy: 0.4309\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.3167 - accuracy: 0.5507 - val_loss: 2.7396 - val_accuracy: 0.4468\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2855 - accuracy: 0.5613 - val_loss: 2.5895 - val_accuracy: 0.4599\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2575 - accuracy: 0.5708 - val_loss: 2.4603 - val_accuracy: 0.4745\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.2321 - accuracy: 0.5800 - val_loss: 2.3475 - val_accuracy: 0.4846\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.2089 - accuracy: 0.5877 - val_loss: 2.2479 - val_accuracy: 0.4935\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.1876 - accuracy: 0.5956 - val_loss: 2.1592 - val_accuracy: 0.5038\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1680 - accuracy: 0.6022 - val_loss: 2.0795 - val_accuracy: 0.5149\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1498 - accuracy: 0.6093 - val_loss: 2.0075 - val_accuracy: 0.5219\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1330 - accuracy: 0.6151 - val_loss: 1.9420 - val_accuracy: 0.5311\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1172 - accuracy: 0.6202 - val_loss: 1.8823 - val_accuracy: 0.5412\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.1025 - accuracy: 0.6254 - val_loss: 1.8275 - val_accuracy: 0.5497\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0887 - accuracy: 0.6305 - val_loss: 1.7770 - val_accuracy: 0.5578\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0756 - accuracy: 0.6349 - val_loss: 1.7304 - val_accuracy: 0.5658\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0633 - accuracy: 0.6388 - val_loss: 1.6871 - val_accuracy: 0.5720\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0517 - accuracy: 0.6424 - val_loss: 1.6469 - val_accuracy: 0.5784\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0407 - accuracy: 0.6463 - val_loss: 1.6093 - val_accuracy: 0.5852\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0302 - accuracy: 0.6500 - val_loss: 1.5742 - val_accuracy: 0.5916\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 1.0203 - accuracy: 0.6531 - val_loss: 1.5413 - val_accuracy: 0.5976\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0108 - accuracy: 0.6561 - val_loss: 1.5103 - val_accuracy: 0.6013\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 1.0017 - accuracy: 0.6590 - val_loss: 1.4812 - val_accuracy: 0.6058\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9930 - accuracy: 0.6619 - val_loss: 1.4537 - val_accuracy: 0.6098\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9847 - accuracy: 0.6645 - val_loss: 1.4277 - val_accuracy: 0.6142\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9768 - accuracy: 0.6671 - val_loss: 1.4030 - val_accuracy: 0.6180\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9691 - accuracy: 0.6697 - val_loss: 1.3796 - val_accuracy: 0.6226\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9617 - accuracy: 0.6722 - val_loss: 1.3574 - val_accuracy: 0.6261\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9547 - accuracy: 0.6749 - val_loss: 1.3363 - val_accuracy: 0.6289\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9478 - accuracy: 0.6772 - val_loss: 1.3162 - val_accuracy: 0.6317\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9413 - accuracy: 0.6793 - val_loss: 1.2970 - val_accuracy: 0.6351\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9349 - accuracy: 0.6814 - val_loss: 1.2787 - val_accuracy: 0.6378\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9288 - accuracy: 0.6830 - val_loss: 1.2611 - val_accuracy: 0.6403\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9229 - accuracy: 0.6850 - val_loss: 1.2444 - val_accuracy: 0.6436\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9171 - accuracy: 0.6866 - val_loss: 1.2283 - val_accuracy: 0.6463\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.9116 - accuracy: 0.6884 - val_loss: 1.2129 - val_accuracy: 0.6487\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9062 - accuracy: 0.6902 - val_loss: 1.1981 - val_accuracy: 0.6511\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.9010 - accuracy: 0.6915 - val_loss: 1.1839 - val_accuracy: 0.6539\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8959 - accuracy: 0.6932 - val_loss: 1.1702 - val_accuracy: 0.6567\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8910 - accuracy: 0.6946 - val_loss: 1.1571 - val_accuracy: 0.6600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdbd6ea71d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_VlPpWxan0E",
        "colab_type": "text"
      },
      "source": [
        "- There is no improvement with batch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py-KwkmjOIVU",
        "colab_type": "text"
      },
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLXUE9jWOIVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJUqA5T4OIVc",
        "colab_type": "code",
        "outputId": "a0ab23ab-7e7f-48ea-bc04-4fbc21954c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
        "          batch_size = trainX.shape[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.8862 - accuracy: 0.6960 - val_loss: 1.1482 - val_accuracy: 0.6609\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8857 - accuracy: 0.6962 - val_loss: 1.1396 - val_accuracy: 0.6613\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8853 - accuracy: 0.6964 - val_loss: 1.1313 - val_accuracy: 0.6623\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8848 - accuracy: 0.6967 - val_loss: 1.1233 - val_accuracy: 0.6630\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8843 - accuracy: 0.6968 - val_loss: 1.1157 - val_accuracy: 0.6639\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8839 - accuracy: 0.6969 - val_loss: 1.1082 - val_accuracy: 0.6645\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8834 - accuracy: 0.6971 - val_loss: 1.1011 - val_accuracy: 0.6652\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8829 - accuracy: 0.6973 - val_loss: 1.0942 - val_accuracy: 0.6659\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8825 - accuracy: 0.6974 - val_loss: 1.0875 - val_accuracy: 0.6667\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8820 - accuracy: 0.6975 - val_loss: 1.0810 - val_accuracy: 0.6674\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8816 - accuracy: 0.6977 - val_loss: 1.0748 - val_accuracy: 0.6678\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8811 - accuracy: 0.6980 - val_loss: 1.0688 - val_accuracy: 0.6681\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8807 - accuracy: 0.6981 - val_loss: 1.0629 - val_accuracy: 0.6691\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8802 - accuracy: 0.6983 - val_loss: 1.0573 - val_accuracy: 0.6705\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8798 - accuracy: 0.6984 - val_loss: 1.0518 - val_accuracy: 0.6707\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8793 - accuracy: 0.6985 - val_loss: 1.0465 - val_accuracy: 0.6716\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8789 - accuracy: 0.6986 - val_loss: 1.0414 - val_accuracy: 0.6728\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8784 - accuracy: 0.6988 - val_loss: 1.0364 - val_accuracy: 0.6735\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8780 - accuracy: 0.6990 - val_loss: 1.0316 - val_accuracy: 0.6735\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8775 - accuracy: 0.6991 - val_loss: 1.0270 - val_accuracy: 0.6740\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8771 - accuracy: 0.6993 - val_loss: 1.0224 - val_accuracy: 0.6746\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8766 - accuracy: 0.6994 - val_loss: 1.0181 - val_accuracy: 0.6754\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8762 - accuracy: 0.6996 - val_loss: 1.0138 - val_accuracy: 0.6759\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8758 - accuracy: 0.6998 - val_loss: 1.0097 - val_accuracy: 0.6766\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8753 - accuracy: 0.7000 - val_loss: 1.0057 - val_accuracy: 0.6770\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8749 - accuracy: 0.7000 - val_loss: 1.0018 - val_accuracy: 0.6772\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8744 - accuracy: 0.7002 - val_loss: 0.9980 - val_accuracy: 0.6778\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8740 - accuracy: 0.7003 - val_loss: 0.9944 - val_accuracy: 0.6781\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8736 - accuracy: 0.7004 - val_loss: 0.9908 - val_accuracy: 0.6788\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8731 - accuracy: 0.7007 - val_loss: 0.9873 - val_accuracy: 0.6798\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8727 - accuracy: 0.7008 - val_loss: 0.9840 - val_accuracy: 0.6800\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8723 - accuracy: 0.7009 - val_loss: 0.9807 - val_accuracy: 0.6801\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8718 - accuracy: 0.7010 - val_loss: 0.9775 - val_accuracy: 0.6802\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8714 - accuracy: 0.7011 - val_loss: 0.9744 - val_accuracy: 0.6808\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8710 - accuracy: 0.7012 - val_loss: 0.9714 - val_accuracy: 0.6817\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8706 - accuracy: 0.7014 - val_loss: 0.9685 - val_accuracy: 0.6823\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8701 - accuracy: 0.7016 - val_loss: 0.9657 - val_accuracy: 0.6827\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8697 - accuracy: 0.7019 - val_loss: 0.9629 - val_accuracy: 0.6835\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8693 - accuracy: 0.7019 - val_loss: 0.9602 - val_accuracy: 0.6843\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8689 - accuracy: 0.7019 - val_loss: 0.9576 - val_accuracy: 0.6850\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8684 - accuracy: 0.7021 - val_loss: 0.9550 - val_accuracy: 0.6858\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8680 - accuracy: 0.7021 - val_loss: 0.9525 - val_accuracy: 0.6865\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8676 - accuracy: 0.7023 - val_loss: 0.9501 - val_accuracy: 0.6866\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8672 - accuracy: 0.7025 - val_loss: 0.9478 - val_accuracy: 0.6869\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8668 - accuracy: 0.7025 - val_loss: 0.9455 - val_accuracy: 0.6873\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8663 - accuracy: 0.7026 - val_loss: 0.9432 - val_accuracy: 0.6876\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8659 - accuracy: 0.7027 - val_loss: 0.9410 - val_accuracy: 0.6882\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8655 - accuracy: 0.7029 - val_loss: 0.9389 - val_accuracy: 0.6882\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 15us/sample - loss: 0.8651 - accuracy: 0.7030 - val_loss: 0.9368 - val_accuracy: 0.6888\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 14us/sample - loss: 0.8647 - accuracy: 0.7031 - val_loss: 0.9348 - val_accuracy: 0.6899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdbd7113210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VChxxMTmatoI",
        "colab_type": "text"
      },
      "source": [
        "- Decreasing the learning rate improves training accuracy but reduces testing accuracy\n",
        "- This leads to potential overfitting \n",
        "- However, only 50 iterations have been tried. Increasing iterations may improve results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CSqKvpOIVk",
        "colab_type": "text"
      },
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGAad54JOIVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 100 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "\n",
        "# Add Dense Layer which provides 100 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "\n",
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ7oIymROIVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-O-fFxnOIVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiP7IL52OIVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr2YsZV0OIV0",
        "colab_type": "text"
      },
      "source": [
        "## Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ojW6-oOIV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFGmbZLOIV5",
        "colab_type": "text"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIkbMEN5OIV7",
        "colab_type": "code",
        "outputId": "25a82964-9219-45e2-a356-3c173bc36ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
        "          batch_size = trainX.shape[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 2.6457 - accuracy: 0.0946 - val_loss: 2.6353 - val_accuracy: 0.0824\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.6222 - accuracy: 0.0940 - val_loss: 2.6124 - val_accuracy: 0.0820\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.6002 - accuracy: 0.0933 - val_loss: 2.5908 - val_accuracy: 0.0821\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.5794 - accuracy: 0.0926 - val_loss: 2.5705 - val_accuracy: 0.0825\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.5598 - accuracy: 0.0918 - val_loss: 2.5514 - val_accuracy: 0.0828\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.5414 - accuracy: 0.0912 - val_loss: 2.5334 - val_accuracy: 0.0826\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.5241 - accuracy: 0.0907 - val_loss: 2.5164 - val_accuracy: 0.0830\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.5078 - accuracy: 0.0903 - val_loss: 2.5004 - val_accuracy: 0.0837\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.4924 - accuracy: 0.0900 - val_loss: 2.4854 - val_accuracy: 0.0854\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.4780 - accuracy: 0.0896 - val_loss: 2.4712 - val_accuracy: 0.0858\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.4644 - accuracy: 0.0897 - val_loss: 2.4578 - val_accuracy: 0.0865\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.4516 - accuracy: 0.0898 - val_loss: 2.4452 - val_accuracy: 0.0873\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.4395 - accuracy: 0.0898 - val_loss: 2.4334 - val_accuracy: 0.0893\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.4282 - accuracy: 0.0902 - val_loss: 2.4222 - val_accuracy: 0.0913\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.4175 - accuracy: 0.0905 - val_loss: 2.4116 - val_accuracy: 0.0927\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.4074 - accuracy: 0.0913 - val_loss: 2.4017 - val_accuracy: 0.0940\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3979 - accuracy: 0.0920 - val_loss: 2.3923 - val_accuracy: 0.0955\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3890 - accuracy: 0.0926 - val_loss: 2.3834 - val_accuracy: 0.0977\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3806 - accuracy: 0.0935 - val_loss: 2.3750 - val_accuracy: 0.0993\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3726 - accuracy: 0.0944 - val_loss: 2.3671 - val_accuracy: 0.1018\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3651 - accuracy: 0.0952 - val_loss: 2.3596 - val_accuracy: 0.1034\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3580 - accuracy: 0.0962 - val_loss: 2.3526 - val_accuracy: 0.1055\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3512 - accuracy: 0.0971 - val_loss: 2.3458 - val_accuracy: 0.1076\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3449 - accuracy: 0.0981 - val_loss: 2.3395 - val_accuracy: 0.1104\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3389 - accuracy: 0.0993 - val_loss: 2.3335 - val_accuracy: 0.1123\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3332 - accuracy: 0.1003 - val_loss: 2.3277 - val_accuracy: 0.1153\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3278 - accuracy: 0.1015 - val_loss: 2.3223 - val_accuracy: 0.1176\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3226 - accuracy: 0.1031 - val_loss: 2.3172 - val_accuracy: 0.1196\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3178 - accuracy: 0.1047 - val_loss: 2.3122 - val_accuracy: 0.1224\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3131 - accuracy: 0.1064 - val_loss: 2.3076 - val_accuracy: 0.1245\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3087 - accuracy: 0.1081 - val_loss: 2.3031 - val_accuracy: 0.1265\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3045 - accuracy: 0.1096 - val_loss: 2.2989 - val_accuracy: 0.1278\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3006 - accuracy: 0.1109 - val_loss: 2.2948 - val_accuracy: 0.1299\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 2.2967 - accuracy: 0.1123 - val_loss: 2.2910 - val_accuracy: 0.1320\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 2.2931 - accuracy: 0.1139 - val_loss: 2.2873 - val_accuracy: 0.1338\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2896 - accuracy: 0.1155 - val_loss: 2.2837 - val_accuracy: 0.1358\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2863 - accuracy: 0.1172 - val_loss: 2.2803 - val_accuracy: 0.1377\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2831 - accuracy: 0.1190 - val_loss: 2.2771 - val_accuracy: 0.1394\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2801 - accuracy: 0.1209 - val_loss: 2.2740 - val_accuracy: 0.1410\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2772 - accuracy: 0.1226 - val_loss: 2.2710 - val_accuracy: 0.1426\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2744 - accuracy: 0.1247 - val_loss: 2.2681 - val_accuracy: 0.1442\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2717 - accuracy: 0.1263 - val_loss: 2.2653 - val_accuracy: 0.1457\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2691 - accuracy: 0.1282 - val_loss: 2.2627 - val_accuracy: 0.1476\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2666 - accuracy: 0.1300 - val_loss: 2.2601 - val_accuracy: 0.1498\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2642 - accuracy: 0.1321 - val_loss: 2.2576 - val_accuracy: 0.1508\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2618 - accuracy: 0.1340 - val_loss: 2.2552 - val_accuracy: 0.1528\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2596 - accuracy: 0.1361 - val_loss: 2.2529 - val_accuracy: 0.1549\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2574 - accuracy: 0.1378 - val_loss: 2.2506 - val_accuracy: 0.1561\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2553 - accuracy: 0.1396 - val_loss: 2.2485 - val_accuracy: 0.1576\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2533 - accuracy: 0.1414 - val_loss: 2.2463 - val_accuracy: 0.1587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdbcb9bd950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPLgbUk7ZrMa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   It is seen that adding 2 additonal layers of 100 neurons does not make any difference to the results\n",
        "2.   What is interesting is that the results actually becomes bad and the network stops learning\n",
        "\n",
        "1.   Howevrer, with ReLU activation function and 3 layers, the results improve a lot (shown below)\n",
        "2.   This suggests that the sigmoid activation function is not learning - it is near its inflection point\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaFgYzUIdc0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 100 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "\n",
        "# Add Dense Layer which provides 100 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "\n",
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5S3CcVSslE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b54415c0-db3b-4b59-84e8-8658d5cacffc"
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
        "          batch_size = trainX.shape[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 2.7786 - accuracy: 0.1398 - val_loss: 23.1285 - val_accuracy: 0.1649\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.6691 - accuracy: 0.1440 - val_loss: 15.2469 - val_accuracy: 0.1684\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.5692 - accuracy: 0.1499 - val_loss: 11.6094 - val_accuracy: 0.1717\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.4776 - accuracy: 0.1584 - val_loss: 9.4068 - val_accuracy: 0.1750\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3932 - accuracy: 0.1697 - val_loss: 7.9031 - val_accuracy: 0.1771\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.3153 - accuracy: 0.1853 - val_loss: 6.8054 - val_accuracy: 0.1795\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2429 - accuracy: 0.2041 - val_loss: 5.9691 - val_accuracy: 0.1804\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.1756 - accuracy: 0.2241 - val_loss: 5.3130 - val_accuracy: 0.1814\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.1129 - accuracy: 0.2450 - val_loss: 4.7868 - val_accuracy: 0.1839\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 2.0542 - accuracy: 0.2653 - val_loss: 4.3574 - val_accuracy: 0.1871\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.9992 - accuracy: 0.2855 - val_loss: 4.0022 - val_accuracy: 0.1896\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.9477 - accuracy: 0.3065 - val_loss: 3.7051 - val_accuracy: 0.1922\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.8993 - accuracy: 0.3273 - val_loss: 3.4544 - val_accuracy: 0.1986\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.8539 - accuracy: 0.3483 - val_loss: 3.2413 - val_accuracy: 0.2046\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.8111 - accuracy: 0.3700 - val_loss: 3.0589 - val_accuracy: 0.2105\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.7709 - accuracy: 0.3895 - val_loss: 2.9014 - val_accuracy: 0.2188\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.7330 - accuracy: 0.4092 - val_loss: 2.7648 - val_accuracy: 0.2288\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.6972 - accuracy: 0.4287 - val_loss: 2.6454 - val_accuracy: 0.2416\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.6635 - accuracy: 0.4464 - val_loss: 2.5406 - val_accuracy: 0.2530\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.6316 - accuracy: 0.4632 - val_loss: 2.4477 - val_accuracy: 0.2652\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.6014 - accuracy: 0.4802 - val_loss: 2.3650 - val_accuracy: 0.2769\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.5728 - accuracy: 0.4943 - val_loss: 2.2911 - val_accuracy: 0.2898\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.5457 - accuracy: 0.5070 - val_loss: 2.2244 - val_accuracy: 0.3016\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.5200 - accuracy: 0.5196 - val_loss: 2.1640 - val_accuracy: 0.3126\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4956 - accuracy: 0.5300 - val_loss: 2.1088 - val_accuracy: 0.3228\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4723 - accuracy: 0.5400 - val_loss: 2.0582 - val_accuracy: 0.3333\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4501 - accuracy: 0.5494 - val_loss: 2.0114 - val_accuracy: 0.3439\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4288 - accuracy: 0.5584 - val_loss: 1.9680 - val_accuracy: 0.3546\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4086 - accuracy: 0.5659 - val_loss: 1.9274 - val_accuracy: 0.3633\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 1.3892 - accuracy: 0.5730 - val_loss: 1.8894 - val_accuracy: 0.3732\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3706 - accuracy: 0.5803 - val_loss: 1.8538 - val_accuracy: 0.3834\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3528 - accuracy: 0.5863 - val_loss: 1.8201 - val_accuracy: 0.3932\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3356 - accuracy: 0.5926 - val_loss: 1.7883 - val_accuracy: 0.4035\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3192 - accuracy: 0.5979 - val_loss: 1.7580 - val_accuracy: 0.4121\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3034 - accuracy: 0.6025 - val_loss: 1.7293 - val_accuracy: 0.4218\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2882 - accuracy: 0.6069 - val_loss: 1.7018 - val_accuracy: 0.4301\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2735 - accuracy: 0.6114 - val_loss: 1.6755 - val_accuracy: 0.4386\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2594 - accuracy: 0.6156 - val_loss: 1.6503 - val_accuracy: 0.4466\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2458 - accuracy: 0.6192 - val_loss: 1.6261 - val_accuracy: 0.4540\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2326 - accuracy: 0.6229 - val_loss: 1.6029 - val_accuracy: 0.4617\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2199 - accuracy: 0.6258 - val_loss: 1.5805 - val_accuracy: 0.4684\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.2077 - accuracy: 0.6288 - val_loss: 1.5589 - val_accuracy: 0.4760\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1958 - accuracy: 0.6317 - val_loss: 1.5380 - val_accuracy: 0.4832\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1843 - accuracy: 0.6346 - val_loss: 1.5178 - val_accuracy: 0.4901\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1732 - accuracy: 0.6375 - val_loss: 1.4983 - val_accuracy: 0.4970\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1624 - accuracy: 0.6407 - val_loss: 1.4794 - val_accuracy: 0.5056\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1520 - accuracy: 0.6434 - val_loss: 1.4611 - val_accuracy: 0.5109\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1419 - accuracy: 0.6458 - val_loss: 1.4433 - val_accuracy: 0.5152\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1321 - accuracy: 0.6481 - val_loss: 1.4260 - val_accuracy: 0.5233\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1226 - accuracy: 0.6507 - val_loss: 1.4092 - val_accuracy: 0.5296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdbca9bb1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T0YmH1Oss5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}