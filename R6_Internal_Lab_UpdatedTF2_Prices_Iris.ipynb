{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_Internal_Lab_UpdatedTF2_Prices_Iris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84Q8JfvaeZZ6"
      },
      "source": [
        "## Linear Classifier in TensorFlow \n",
        "Using Low Level API in Eager Execution mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "outputId": "46fe7c66-f292-44b2-bb52-5c6052510295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElwFCRZQTIXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a366a62b-0602-4d95-b2d6-e6f0cb909691"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mjtb-EMcm5K0",
        "colab": {}
      },
      "source": [
        "#Enable Eager Execution if using tensflow version < 2.0\n",
        "#From tensorflow v2.0 onwards, Eager Execution will be enabled by default\n",
        "#tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a5615429-3adb-4d56-910f-9258f733d8ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiObW4V4SIOz",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/My Drive/prices.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "outputId": "e93bd4c7-4251-4b74-e9ff-3d70ae1d8959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  date symbol        open  ...         low        high     volume\n",
              "0  2016-01-05 00:00:00   WLTW  123.430000  ...  122.309998  126.250000  2163600.0\n",
              "1  2016-01-06 00:00:00   WLTW  125.239998  ...  119.940002  125.540001  2386400.0\n",
              "2  2016-01-07 00:00:00   WLTW  116.379997  ...  114.930000  119.739998  2489500.0\n",
              "3  2016-01-08 00:00:00   WLTW  115.480003  ...  113.500000  117.440002  2006300.0\n",
              "4  2016-01-11 00:00:00   WLTW  117.010002  ...  114.089996  117.330002  1408600.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H_0goIe2PRM",
        "colab_type": "code",
        "outputId": "9a759912-ae81-4aa6-fc4c-07fb94fb62ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date', 'symbol', 'open', 'close', 'low', 'high', 'volume'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "colab": {}
      },
      "source": [
        "data = data.drop(['date','symbol'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlwbUgTwOB6i",
        "outputId": "333136f5-6db6-4945-b18b-e79021b0a50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high     volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
              "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
              "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
              "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
              "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set\n",
        "Target 'Volume' has very high values. Divide 'Volume' by 1000,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIXoPW2w2PRT",
        "colab_type": "code",
        "outputId": "7207246b-9ee1-41c3-feb6-48b88618be86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(851264, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "outputId": "020b1fbd-8023-4e1d-8f9c-c7b7a60864bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = data.iloc[:1000,:]\n",
        "data.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49hAEpZq2PRY",
        "colab_type": "code",
        "outputId": "a3bc0297-30b8-451d-ae59-9eb683fdee21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "data['volume'] = data['volume']/1000000\n",
        "data['volume'].describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1000.000000\n",
              "mean        5.314222\n",
              "std        14.465650\n",
              "min         0.010000\n",
              "25%         0.821625\n",
              "50%         2.064450\n",
              "75%         4.620475\n",
              "max       215.620200\n",
              "Name: volume, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdR1zCSx2PRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.drop('volume', axis = 1)\n",
        "Y = data['volume']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4LE4U8lTdQJq",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=.30,random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYK-aUuLbrz2"
      },
      "source": [
        "#### Convert Training and Test Data to numpy float32 arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ao-S0tQGcncz",
        "outputId": "48ad6048-f501-4bb3-8853-8eacf94a1882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(train_x).dtype"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smSs-XuJ2PRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x =np.array(train_x).astype('float32')\n",
        "test_x = np.array(test_x).astype('float32')\n",
        "train_y =np.array(train_y).astype('float32')\n",
        "test_y = np.array(test_y).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZaTrJ1x2PRj",
        "colab_type": "code",
        "outputId": "9adc51dc-74d2-4f4e-ef80-ac4760f46027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(train_x).dtype"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "im1ZegbDdKgv"
      },
      "source": [
        "### Normalize the data\n",
        "You can use Normalizer from sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2EkKAy7fOB6y",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "transformer = Normalizer() #same as Z-score\n",
        "train_x = transformer.fit_transform(train_x)\n",
        "test_x = transformer.transform(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FQonple2PRo",
        "colab_type": "code",
        "outputId": "aeeb637f-7d3d-46fa-ed47-8c67ce6cc311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbyQfZpf2PRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y=train_y.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Uw4xVi2PRt",
        "colab_type": "code",
        "outputId": "5a8d1f3b-93db-4815-f955-97d3c4a3901b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CivV1hnh2PRu",
        "colab_type": "code",
        "outputId": "853436d0-9028-437b-8209-f75b5675f673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62"
      },
      "source": [
        "## Building the Model in tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A"
      },
      "source": [
        "1.Define Weights and Bias, use tf.zeros to initialize weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "source": [
        "#We are initializing weights and Bias of (Input-Hidden Layer)\n",
        "w1 = tf.random.normal(shape=(4,4))\n",
        "b1 = tf.zeros(shape=(4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMc6XWd32PRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We are initializing weights and Bias of (Hidden-Output)\n",
        "w2 = tf.random.normal(shape=(4,1))\n",
        "b2 = tf.zeros(shape=(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F"
      },
      "source": [
        "2.Define a function to calculate prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "source": [
        "def prediction(x, w1, b1,w2,b2):\n",
        "    \n",
        "    xw_matmul = tf.matmul(x, w1)\n",
        "    net1 = tf.add(xw_matmul, b1)\n",
        "    y=tf.sigmoid(net1)\n",
        "    net2=tf.matmul(y, w2)+b2\n",
        "    out=tf.sigmoid(net2)\n",
        "    return net2,out\n",
        "\n",
        "## net2 for regression and out for classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M"
      },
      "source": [
        "3.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "source": [
        "def loss(predicted_y, desired_y):\n",
        "  return tf.reduce_mean(tf.square(predicted_y - desired_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U"
      },
      "source": [
        "4.Function to train the Model\n",
        "\n",
        "1.   Record all the mathematical steps to calculate Loss\n",
        "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
        "3.   Update Weights and Bias based on gradients and learning rate to minimize loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj802w-3OB7X",
        "colab": {}
      },
      "source": [
        "def train(train_x, train_y, w1, b1,w2,b2, learning_rate=0.01):\n",
        "    \n",
        "    #Record mathematical operations on 'tape' to calculate loss\n",
        "    with tf.GradientTape() as t:\n",
        "        \n",
        "        t.watch([w1,b1,w2,b2]) #which values have to be updated/keep track of/model parameters\n",
        "        \n",
        "        net2,current_prediction = prediction(train_x, w1, b1,w2,b2)\n",
        "        current_loss =loss(net2, train_y)\n",
        "    \n",
        "    #Calculate Gradients for Loss with respect to Weights and Bias\n",
        "    dw1,db1,dw2,db2 = t.gradient(current_loss,[w1, b1,w2,b2])\n",
        "    \n",
        "    #Update Weights at output layer\n",
        "    w2 = w2 - learning_rate*dw2\n",
        "    b2 = b2 - learning_rate*db2\n",
        "    \n",
        "     #Update Weights at hidden layer\n",
        "    w1 = w1 - learning_rate*dw1\n",
        "    b1 = b1 - learning_rate*db1\n",
        "    \n",
        "    return w1, b1,w2,b2, current_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e"
      },
      "source": [
        "## Train the model for 100 epochs \n",
        "1. Observe the training loss at every iteration\n",
        "2. Observe Train loss at every 5th iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVvgj7eQOB7f",
        "outputId": "258883e1-39a5-4254-d1db-915222d01717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(100):\n",
        "    \n",
        "    w1, b1,w2,b2, current_loss = train(train_x, train_y, w1, b1,w2,b2)\n",
        "    print(\"Loss at step {:d}: {:.3f}\".format(i, current_loss))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at step 0: 252.931\n",
            "Loss at step 1: 250.618\n",
            "Loss at step 2: 248.476\n",
            "Loss at step 3: 246.487\n",
            "Loss at step 4: 244.634\n",
            "Loss at step 5: 242.904\n",
            "Loss at step 6: 241.287\n",
            "Loss at step 7: 239.773\n",
            "Loss at step 8: 238.354\n",
            "Loss at step 9: 237.022\n",
            "Loss at step 10: 235.773\n",
            "Loss at step 11: 234.599\n",
            "Loss at step 12: 233.498\n",
            "Loss at step 13: 232.463\n",
            "Loss at step 14: 231.493\n",
            "Loss at step 15: 230.582\n",
            "Loss at step 16: 229.728\n",
            "Loss at step 17: 228.928\n",
            "Loss at step 18: 228.178\n",
            "Loss at step 19: 227.477\n",
            "Loss at step 20: 226.822\n",
            "Loss at step 21: 226.209\n",
            "Loss at step 22: 225.638\n",
            "Loss at step 23: 225.105\n",
            "Loss at step 24: 224.608\n",
            "Loss at step 25: 224.146\n",
            "Loss at step 26: 223.717\n",
            "Loss at step 27: 223.318\n",
            "Loss at step 28: 222.947\n",
            "Loss at step 29: 222.604\n",
            "Loss at step 30: 222.285\n",
            "Loss at step 31: 221.991\n",
            "Loss at step 32: 221.718\n",
            "Loss at step 33: 221.466\n",
            "Loss at step 34: 221.233\n",
            "Loss at step 35: 221.019\n",
            "Loss at step 36: 220.821\n",
            "Loss at step 37: 220.638\n",
            "Loss at step 38: 220.470\n",
            "Loss at step 39: 220.316\n",
            "Loss at step 40: 220.173\n",
            "Loss at step 41: 220.043\n",
            "Loss at step 42: 219.923\n",
            "Loss at step 43: 219.813\n",
            "Loss at step 44: 219.712\n",
            "Loss at step 45: 219.619\n",
            "Loss at step 46: 219.534\n",
            "Loss at step 47: 219.456\n",
            "Loss at step 48: 219.385\n",
            "Loss at step 49: 219.320\n",
            "Loss at step 50: 219.260\n",
            "Loss at step 51: 219.206\n",
            "Loss at step 52: 219.156\n",
            "Loss at step 53: 219.111\n",
            "Loss at step 54: 219.069\n",
            "Loss at step 55: 219.031\n",
            "Loss at step 56: 218.997\n",
            "Loss at step 57: 218.965\n",
            "Loss at step 58: 218.936\n",
            "Loss at step 59: 218.910\n",
            "Loss at step 60: 218.886\n",
            "Loss at step 61: 218.864\n",
            "Loss at step 62: 218.845\n",
            "Loss at step 63: 218.826\n",
            "Loss at step 64: 218.810\n",
            "Loss at step 65: 218.795\n",
            "Loss at step 66: 218.781\n",
            "Loss at step 67: 218.769\n",
            "Loss at step 68: 218.758\n",
            "Loss at step 69: 218.747\n",
            "Loss at step 70: 218.738\n",
            "Loss at step 71: 218.730\n",
            "Loss at step 72: 218.722\n",
            "Loss at step 73: 218.715\n",
            "Loss at step 74: 218.709\n",
            "Loss at step 75: 218.703\n",
            "Loss at step 76: 218.698\n",
            "Loss at step 77: 218.693\n",
            "Loss at step 78: 218.689\n",
            "Loss at step 79: 218.685\n",
            "Loss at step 80: 218.681\n",
            "Loss at step 81: 218.678\n",
            "Loss at step 82: 218.675\n",
            "Loss at step 83: 218.672\n",
            "Loss at step 84: 218.670\n",
            "Loss at step 85: 218.668\n",
            "Loss at step 86: 218.666\n",
            "Loss at step 87: 218.664\n",
            "Loss at step 88: 218.662\n",
            "Loss at step 89: 218.661\n",
            "Loss at step 90: 218.659\n",
            "Loss at step 91: 218.658\n",
            "Loss at step 92: 218.657\n",
            "Loss at step 93: 218.656\n",
            "Loss at step 94: 218.655\n",
            "Loss at step 95: 218.654\n",
            "Loss at step 96: 218.654\n",
            "Loss at step 97: 218.653\n",
            "Loss at step 98: 218.652\n",
            "Loss at step 99: 218.652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqbPCTle6gOV",
        "colab_type": "code",
        "outputId": "9ec0494a-2be7-4fdd-b8a9-c5c934d775b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "j = 0\n",
        "for i in range(100):\n",
        "    j = j+1\n",
        "    w1, b1,w2,b2, current_loss = train(train_x, train_y, w1, b1,w2,b2)\n",
        "    if(j ==5):\n",
        "      print(\"Loss at step {:d}: {:.3f}\".format(i, current_loss))\n",
        "      j = 0"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at step 4: 218.650\n",
            "Loss at step 9: 218.648\n",
            "Loss at step 14: 218.647\n",
            "Loss at step 19: 218.647\n",
            "Loss at step 24: 218.647\n",
            "Loss at step 29: 218.646\n",
            "Loss at step 34: 218.646\n",
            "Loss at step 39: 218.646\n",
            "Loss at step 44: 218.646\n",
            "Loss at step 49: 218.646\n",
            "Loss at step 54: 218.646\n",
            "Loss at step 59: 218.646\n",
            "Loss at step 64: 218.646\n",
            "Loss at step 69: 218.646\n",
            "Loss at step 74: 218.646\n",
            "Loss at step 79: 218.646\n",
            "Loss at step 84: 218.646\n",
            "Loss at step 89: 218.646\n",
            "Loss at step 94: 218.646\n",
            "Loss at step 99: 218.646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "source": [
        "### Get the shapes and values of W and b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "outputId": "21e1f0f9-1646-4958-82fa-76ce744852c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w1.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "outputId": "7293c73a-c042-42a1-f79e-ecf42413bbed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w2.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtqJdoX67e03",
        "colab_type": "code",
        "outputId": "1463ce9c-a9fc-414d-f761-ff003c64529c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b1.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTvrJx_H7fBi",
        "colab_type": "code",
        "outputId": "4aa908ed-be48-423f-93fe-06e3c34d7e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b2.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERq9GOKKciho"
      },
      "source": [
        "### Model Prediction on 1st Examples in Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gKGvUWahcihp",
        "outputId": "1d6dbb4d-3a0f-4eed-e40e-89874ccd053e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_pred,_=prediction(test_x,w1,b1,w2,b2)\n",
        "y_pred"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=10824, shape=(300, 1), dtype=float32, numpy=\n",
              "array([[5.6540956],\n",
              "       [5.6491766],\n",
              "       [5.651331 ],\n",
              "       [5.648365 ],\n",
              "       [5.6510344],\n",
              "       [5.6540847],\n",
              "       [5.649946 ],\n",
              "       [5.6476574],\n",
              "       [5.651206 ],\n",
              "       [5.6550436],\n",
              "       [5.650572 ],\n",
              "       [5.647544 ],\n",
              "       [5.6478214],\n",
              "       [5.65282  ],\n",
              "       [5.64717  ],\n",
              "       [5.6489334],\n",
              "       [5.6600137],\n",
              "       [5.650756 ],\n",
              "       [5.6477213],\n",
              "       [5.647435 ],\n",
              "       [5.6512322],\n",
              "       [5.6477056],\n",
              "       [5.6518526],\n",
              "       [5.6518993],\n",
              "       [5.6493607],\n",
              "       [5.6501083],\n",
              "       [5.6489296],\n",
              "       [5.651355 ],\n",
              "       [5.6480236],\n",
              "       [5.6477046],\n",
              "       [5.6574345],\n",
              "       [5.651604 ],\n",
              "       [5.649398 ],\n",
              "       [5.649975 ],\n",
              "       [5.6476345],\n",
              "       [5.649069 ],\n",
              "       [5.6488395],\n",
              "       [5.647338 ],\n",
              "       [5.6503124],\n",
              "       [5.6502256],\n",
              "       [5.6548834],\n",
              "       [5.647975 ],\n",
              "       [5.648081 ],\n",
              "       [5.650653 ],\n",
              "       [5.649844 ],\n",
              "       [5.6530833],\n",
              "       [5.6504126],\n",
              "       [5.65364  ],\n",
              "       [5.6520376],\n",
              "       [5.6475496],\n",
              "       [5.653496 ],\n",
              "       [5.6500015],\n",
              "       [5.648102 ],\n",
              "       [5.647583 ],\n",
              "       [5.6539717],\n",
              "       [5.64869  ],\n",
              "       [5.6478567],\n",
              "       [5.6487417],\n",
              "       [5.649742 ],\n",
              "       [5.653781 ],\n",
              "       [5.6494684],\n",
              "       [5.647566 ],\n",
              "       [5.6487923],\n",
              "       [5.65211  ],\n",
              "       [5.650999 ],\n",
              "       [5.6473255],\n",
              "       [5.651885 ],\n",
              "       [5.6482253],\n",
              "       [5.6475353],\n",
              "       [5.648611 ],\n",
              "       [5.653237 ],\n",
              "       [5.6493034],\n",
              "       [5.6509695],\n",
              "       [5.649146 ],\n",
              "       [5.6485095],\n",
              "       [5.649699 ],\n",
              "       [5.648799 ],\n",
              "       [5.654907 ],\n",
              "       [5.658696 ],\n",
              "       [5.6525784],\n",
              "       [5.648549 ],\n",
              "       [5.6489167],\n",
              "       [5.6547365],\n",
              "       [5.6494355],\n",
              "       [5.648547 ],\n",
              "       [5.648264 ],\n",
              "       [5.6551967],\n",
              "       [5.6560726],\n",
              "       [5.6507206],\n",
              "       [5.6519976],\n",
              "       [5.649025 ],\n",
              "       [5.648237 ],\n",
              "       [5.648942 ],\n",
              "       [5.6501718],\n",
              "       [5.6515985],\n",
              "       [5.6479535],\n",
              "       [5.647957 ],\n",
              "       [5.6587563],\n",
              "       [5.649228 ],\n",
              "       [5.653945 ],\n",
              "       [5.649718 ],\n",
              "       [5.649453 ],\n",
              "       [5.648376 ],\n",
              "       [5.6473503],\n",
              "       [5.651387 ],\n",
              "       [5.657069 ],\n",
              "       [5.6490817],\n",
              "       [5.647366 ],\n",
              "       [5.6511426],\n",
              "       [5.6474414],\n",
              "       [5.6531262],\n",
              "       [5.648322 ],\n",
              "       [5.6491137],\n",
              "       [5.65147  ],\n",
              "       [5.65506  ],\n",
              "       [5.6513844],\n",
              "       [5.648753 ],\n",
              "       [5.650321 ],\n",
              "       [5.6515245],\n",
              "       [5.64878  ],\n",
              "       [5.6482773],\n",
              "       [5.6506357],\n",
              "       [5.6470485],\n",
              "       [5.6484013],\n",
              "       [5.648529 ],\n",
              "       [5.6574054],\n",
              "       [5.6483765],\n",
              "       [5.653369 ],\n",
              "       [5.6523333],\n",
              "       [5.649784 ],\n",
              "       [5.6478453],\n",
              "       [5.6503267],\n",
              "       [5.6493273],\n",
              "       [5.647109 ],\n",
              "       [5.655964 ],\n",
              "       [5.6488004],\n",
              "       [5.6480365],\n",
              "       [5.65084  ],\n",
              "       [5.649373 ],\n",
              "       [5.655671 ],\n",
              "       [5.647359 ],\n",
              "       [5.654973 ],\n",
              "       [5.64814  ],\n",
              "       [5.650347 ],\n",
              "       [5.649013 ],\n",
              "       [5.647336 ],\n",
              "       [5.652972 ],\n",
              "       [5.6478357],\n",
              "       [5.64978  ],\n",
              "       [5.6481752],\n",
              "       [5.648763 ],\n",
              "       [5.6485934],\n",
              "       [5.6502686],\n",
              "       [5.650031 ],\n",
              "       [5.6500664],\n",
              "       [5.6522884],\n",
              "       [5.655356 ],\n",
              "       [5.650576 ],\n",
              "       [5.6473465],\n",
              "       [5.6471415],\n",
              "       [5.647588 ],\n",
              "       [5.647426 ],\n",
              "       [5.6497817],\n",
              "       [5.652215 ],\n",
              "       [5.6543207],\n",
              "       [5.6543765],\n",
              "       [5.6485906],\n",
              "       [5.650936 ],\n",
              "       [5.650011 ],\n",
              "       [5.6507187],\n",
              "       [5.6480494],\n",
              "       [5.649041 ],\n",
              "       [5.647821 ],\n",
              "       [5.647314 ],\n",
              "       [5.6496663],\n",
              "       [5.6635427],\n",
              "       [5.646951 ],\n",
              "       [5.6524205],\n",
              "       [5.649708 ],\n",
              "       [5.6511097],\n",
              "       [5.648321 ],\n",
              "       [5.650626 ],\n",
              "       [5.651628 ],\n",
              "       [5.6496024],\n",
              "       [5.6553707],\n",
              "       [5.649727 ],\n",
              "       [5.646858 ],\n",
              "       [5.651554 ],\n",
              "       [5.6480722],\n",
              "       [5.6469603],\n",
              "       [5.6477623],\n",
              "       [5.6530733],\n",
              "       [5.650735 ],\n",
              "       [5.6470795],\n",
              "       [5.652741 ],\n",
              "       [5.654502 ],\n",
              "       [5.65174  ],\n",
              "       [5.6476326],\n",
              "       [5.6489897],\n",
              "       [5.6494646],\n",
              "       [5.6508994],\n",
              "       [5.648979 ],\n",
              "       [5.6507015],\n",
              "       [5.6467733],\n",
              "       [5.6489816],\n",
              "       [5.651088 ],\n",
              "       [5.649132 ],\n",
              "       [5.651075 ],\n",
              "       [5.650655 ],\n",
              "       [5.647839 ],\n",
              "       [5.647774 ],\n",
              "       [5.64917  ],\n",
              "       [5.64846  ],\n",
              "       [5.647791 ],\n",
              "       [5.6520863],\n",
              "       [5.649297 ],\n",
              "       [5.6474886],\n",
              "       [5.6472807],\n",
              "       [5.65485  ],\n",
              "       [5.649287 ],\n",
              "       [5.648861 ],\n",
              "       [5.650257 ],\n",
              "       [5.650717 ],\n",
              "       [5.651471 ],\n",
              "       [5.651534 ],\n",
              "       [5.6539116],\n",
              "       [5.6544194],\n",
              "       [5.648119 ],\n",
              "       [5.648821 ],\n",
              "       [5.648535 ],\n",
              "       [5.64748  ],\n",
              "       [5.6540546],\n",
              "       [5.648011 ],\n",
              "       [5.64816  ],\n",
              "       [5.65127  ],\n",
              "       [5.6549664],\n",
              "       [5.6550627],\n",
              "       [5.64734  ],\n",
              "       [5.6476564],\n",
              "       [5.648567 ],\n",
              "       [5.6556463],\n",
              "       [5.649373 ],\n",
              "       [5.650346 ],\n",
              "       [5.6481137],\n",
              "       [5.6495504],\n",
              "       [5.6479807],\n",
              "       [5.648137 ],\n",
              "       [5.6493216],\n",
              "       [5.650218 ],\n",
              "       [5.649041 ],\n",
              "       [5.6492853],\n",
              "       [5.6479917],\n",
              "       [5.6566763],\n",
              "       [5.64944  ],\n",
              "       [5.648593 ],\n",
              "       [5.656169 ],\n",
              "       [5.6506624],\n",
              "       [5.648623 ],\n",
              "       [5.647237 ],\n",
              "       [5.64783  ],\n",
              "       [5.6494493],\n",
              "       [5.650378 ],\n",
              "       [5.651268 ],\n",
              "       [5.6489797],\n",
              "       [5.6553497],\n",
              "       [5.649845 ],\n",
              "       [5.6530895],\n",
              "       [5.6490297],\n",
              "       [5.64756  ],\n",
              "       [5.6502967],\n",
              "       [5.649588 ],\n",
              "       [5.648431 ],\n",
              "       [5.6501007],\n",
              "       [5.6544523],\n",
              "       [5.654414 ],\n",
              "       [5.647585 ],\n",
              "       [5.651334 ],\n",
              "       [5.647242 ],\n",
              "       [5.6486826],\n",
              "       [5.6526732],\n",
              "       [5.649742 ],\n",
              "       [5.650365 ],\n",
              "       [5.648392 ],\n",
              "       [5.6488075],\n",
              "       [5.6515803],\n",
              "       [5.6599665],\n",
              "       [5.6484556],\n",
              "       [5.6515474],\n",
              "       [5.647877 ],\n",
              "       [5.662797 ],\n",
              "       [5.6525927],\n",
              "       [5.6474833],\n",
              "       [5.6480865],\n",
              "       [5.6489058],\n",
              "       [5.652839 ],\n",
              "       [5.649186 ],\n",
              "       [5.6495647],\n",
              "       [5.6530857],\n",
              "       [5.6481967],\n",
              "       [5.6487703]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh02TyrEUCUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fff186bf-ee79-4b16-bc84-dc7902da655d"
      },
      "source": [
        "y_pred,_=prediction(test_x[:1,:],w1,b1,w2,b2)\n",
        "print(\"The predicted value for the first row in test set is = \",y_pred.numpy())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted value for the first row in test set is =  [[5.654095]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfhOJjwL974X",
        "colab_type": "code",
        "outputId": "c53de991-97b6-41df-afac-1b6fa597a1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "y_pred,_=prediction(test_x,w1,b1,w2,b2)\n",
        "cm=metrics.r2_score(test_y,y_pred)\n",
        "print('The r2 value for the predicted data set is',cm)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The r2 value for the predicted data set is -0.006692816626929998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL6_C5I7_WF-",
        "colab_type": "code",
        "outputId": "e89d485d-5dce-4739-dfc3-f0bcf4e40084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('The loss is',loss(y_pred, test_y).numpy())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The loss is 187.02774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "source": [
        "## Classification using tf.Keras\n",
        "\n",
        "In this exercise, we will build a Deep Neural Network using tf.Keras. We will use Iris Dataset for this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O0g6lorycihf"
      },
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6xFvb5sRcihg",
        "colab": {}
      },
      "source": [
        "data_iris = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SAB--Qdwcihm"
      },
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJr5dYnocihm",
        "outputId": "ccf91b42-1a99-43be-c38d-c638edd6e620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data_iris.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D95nY5ILcihj"
      },
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyMQoLMucihj",
        "colab": {}
      },
      "source": [
        "X = data_iris.drop('Species', axis = 1)\n",
        "Y = data_iris['Species']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFkJ6c05_wDB",
        "colab_type": "code",
        "outputId": "ac853e25-5dc5-470e-a26b-e2f213a5f0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM9-AjOhACII",
        "colab_type": "code",
        "outputId": "ceac47e2-49f0-47a9-afad-bb44b5b705dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = X.drop('Id', axis = 1)\n",
        "X.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo0p0K9H_ywL",
        "colab_type": "code",
        "outputId": "2736d70d-d467-49d5-b58d-de7110d092f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0XvQjgtD_hW",
        "colab_type": "code",
        "outputId": "b7d01905-e384-4a8f-efcc-e8f9d5b405ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y=np.array(Y).reshape(-1,1)\n",
        "Y = pd.DataFrame(Y)\n",
        "Y.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7BC5l6dFDsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y['species'] = Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsFFBROWFala",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = Y.drop(0, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz2kAa0LFb_C",
        "colab_type": "code",
        "outputId": "891a5acf-b22b-4d8e-fe48-a3c919689e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "Y.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       species\n",
              "0  Iris-setosa\n",
              "1  Iris-setosa\n",
              "2  Iris-setosa\n",
              "3  Iris-setosa\n",
              "4  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GXIoeSsCuNc",
        "colab_type": "code",
        "outputId": "f5430397-7c0c-4d6e-cc7a-ba4ac3c48182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "Y =pd.get_dummies(Y)\n",
        "Y.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species_Iris-setosa</th>\n",
              "      <th>species_Iris-versicolor</th>\n",
              "      <th>species_Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   species_Iris-setosa  species_Iris-versicolor  species_Iris-virginica\n",
              "0                    1                        0                       0\n",
              "1                    1                        0                       0\n",
              "2                    1                        0                       0\n",
              "3                    1                        0                       0\n",
              "4                    1                        0                       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP2tU334Cubm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=.30,random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuTTLTOXCulx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mDfU_zNCuvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x =np.array(train_x).astype('float32')\n",
        "test_x = np.array(test_x).astype('float32')\n",
        "train_y =np.array(train_y).astype('float32')\n",
        "test_y = np.array(test_y).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b22qpC5xcihr"
      },
      "source": [
        "###  Building Model in tf.keras\n",
        "\n",
        "Build a Linear Classifier model  <br>\n",
        "1.  Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3<br> \n",
        "2. Apply Softmax on Dense Layer outputs <br>\n",
        "3. Use SGD as Optimizer\n",
        "4. Use categorical_crossentropy as loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hov_UFnUciht",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d619716-06f4-4747-8a8b-22cfc281133e"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un3YlcAm_t61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.compat.v1.disable_eager_execution()\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(4, input_dim = 4, kernel_initializer='normal', activation='softmax'))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))    \n",
        "    # Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T5FdzqIKcihw"
      },
      "source": [
        "### Model Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4qLEdHPscihx",
        "outputId": "60d83b27-7c92-4bcd-87d0-b7e3a8656045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model.fit(train_x, train_y,validation_data = (test_x,test_y), epochs = 50)\n",
        "#print(output)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 1s 9ms/sample - loss: 1.0724 - accuracy: 0.3524 - val_loss: 1.0799 - val_accuracy: 0.2889\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 254us/sample - loss: 1.0680 - accuracy: 0.3524 - val_loss: 1.0765 - val_accuracy: 0.2889\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 252us/sample - loss: 1.0649 - accuracy: 0.3524 - val_loss: 1.0730 - val_accuracy: 0.2889\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 250us/sample - loss: 1.0588 - accuracy: 0.3524 - val_loss: 1.0687 - val_accuracy: 0.2889\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 266us/sample - loss: 1.0543 - accuracy: 0.3524 - val_loss: 1.0642 - val_accuracy: 0.2889\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 230us/sample - loss: 1.0494 - accuracy: 0.3524 - val_loss: 1.0596 - val_accuracy: 0.2889\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 259us/sample - loss: 1.0452 - accuracy: 0.3524 - val_loss: 1.0556 - val_accuracy: 0.2889\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 246us/sample - loss: 1.0399 - accuracy: 0.3524 - val_loss: 1.0506 - val_accuracy: 0.2889\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 253us/sample - loss: 1.0348 - accuracy: 0.3524 - val_loss: 1.0470 - val_accuracy: 0.2889\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 276us/sample - loss: 1.0293 - accuracy: 0.3524 - val_loss: 1.0418 - val_accuracy: 0.3111\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 260us/sample - loss: 1.0237 - accuracy: 0.3714 - val_loss: 1.0372 - val_accuracy: 0.3111\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 296us/sample - loss: 1.0182 - accuracy: 0.4000 - val_loss: 1.0316 - val_accuracy: 0.3111\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 258us/sample - loss: 1.0127 - accuracy: 0.4476 - val_loss: 1.0277 - val_accuracy: 0.3111\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 277us/sample - loss: 1.0078 - accuracy: 0.4286 - val_loss: 1.0222 - val_accuracy: 0.4000\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 261us/sample - loss: 1.0021 - accuracy: 0.5524 - val_loss: 1.0137 - val_accuracy: 0.6444\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 257us/sample - loss: 0.9960 - accuracy: 0.6667 - val_loss: 1.0083 - val_accuracy: 0.6667\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 278us/sample - loss: 0.9906 - accuracy: 0.6667 - val_loss: 1.0014 - val_accuracy: 0.6667\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 265us/sample - loss: 0.9840 - accuracy: 0.6667 - val_loss: 0.9959 - val_accuracy: 0.6667\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 251us/sample - loss: 0.9786 - accuracy: 0.6667 - val_loss: 0.9892 - val_accuracy: 0.6667\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 220us/sample - loss: 0.9723 - accuracy: 0.6667 - val_loss: 0.9831 - val_accuracy: 0.6667\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 241us/sample - loss: 0.9660 - accuracy: 0.6667 - val_loss: 0.9742 - val_accuracy: 0.6667\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 239us/sample - loss: 0.9594 - accuracy: 0.6667 - val_loss: 0.9665 - val_accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 270us/sample - loss: 0.9528 - accuracy: 0.6667 - val_loss: 0.9591 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 228us/sample - loss: 0.9464 - accuracy: 0.6667 - val_loss: 0.9518 - val_accuracy: 0.6667\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 273us/sample - loss: 0.9400 - accuracy: 0.6667 - val_loss: 0.9469 - val_accuracy: 0.6667\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 265us/sample - loss: 0.9344 - accuracy: 0.6667 - val_loss: 0.9407 - val_accuracy: 0.6667\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 268us/sample - loss: 0.9282 - accuracy: 0.6667 - val_loss: 0.9339 - val_accuracy: 0.6667\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 247us/sample - loss: 0.9223 - accuracy: 0.6667 - val_loss: 0.9273 - val_accuracy: 0.6667\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 248us/sample - loss: 0.9169 - accuracy: 0.6667 - val_loss: 0.9229 - val_accuracy: 0.6667\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 236us/sample - loss: 0.9110 - accuracy: 0.6667 - val_loss: 0.9163 - val_accuracy: 0.6667\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 243us/sample - loss: 0.9049 - accuracy: 0.6667 - val_loss: 0.9087 - val_accuracy: 0.6667\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 279us/sample - loss: 0.8995 - accuracy: 0.6667 - val_loss: 0.9048 - val_accuracy: 0.6667\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 227us/sample - loss: 0.8943 - accuracy: 0.6667 - val_loss: 0.8982 - val_accuracy: 0.6667\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 294us/sample - loss: 0.8886 - accuracy: 0.6667 - val_loss: 0.8946 - val_accuracy: 0.6667\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 262us/sample - loss: 0.8841 - accuracy: 0.6667 - val_loss: 0.8904 - val_accuracy: 0.6667\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 272us/sample - loss: 0.8790 - accuracy: 0.6667 - val_loss: 0.8841 - val_accuracy: 0.6667\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 272us/sample - loss: 0.8749 - accuracy: 0.6667 - val_loss: 0.8781 - val_accuracy: 0.6667\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 253us/sample - loss: 0.8697 - accuracy: 0.6667 - val_loss: 0.8724 - val_accuracy: 0.6667\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 256us/sample - loss: 0.8644 - accuracy: 0.6667 - val_loss: 0.8684 - val_accuracy: 0.6667\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 238us/sample - loss: 0.8600 - accuracy: 0.6667 - val_loss: 0.8643 - val_accuracy: 0.6667\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 280us/sample - loss: 0.8558 - accuracy: 0.6667 - val_loss: 0.8602 - val_accuracy: 0.6667\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 223us/sample - loss: 0.8517 - accuracy: 0.6667 - val_loss: 0.8539 - val_accuracy: 0.6667\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 267us/sample - loss: 0.8475 - accuracy: 0.6667 - val_loss: 0.8497 - val_accuracy: 0.6667\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 264us/sample - loss: 0.8433 - accuracy: 0.6667 - val_loss: 0.8454 - val_accuracy: 0.6667\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 263us/sample - loss: 0.8395 - accuracy: 0.6667 - val_loss: 0.8430 - val_accuracy: 0.6667\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 243us/sample - loss: 0.8358 - accuracy: 0.6667 - val_loss: 0.8377 - val_accuracy: 0.6667\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 287us/sample - loss: 0.8318 - accuracy: 0.6667 - val_loss: 0.8332 - val_accuracy: 0.6667\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 226us/sample - loss: 0.8284 - accuracy: 0.6667 - val_loss: 0.8286 - val_accuracy: 0.6667\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 267us/sample - loss: 0.8245 - accuracy: 0.6667 - val_loss: 0.8248 - val_accuracy: 0.6667\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 254us/sample - loss: 0.8215 - accuracy: 0.6667 - val_loss: 0.8212 - val_accuracy: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f26b8f56668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTf9Qyw_UC1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-SgSSdRcih5"
      },
      "source": [
        "### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GBgKZkhkcih6",
        "outputId": "87258249-dd3f-4be1-fba8-d6ad2c596e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "\n",
        "y_pred = model.predict(test_x)\n",
        "y_pred"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.54598814, 0.23632866, 0.21768321],\n",
              "       [0.52592987, 0.24454494, 0.22952521],\n",
              "       [0.19251   , 0.3256129 , 0.48187703],\n",
              "       [0.5368166 , 0.2402098 , 0.2229736 ],\n",
              "       [0.5164635 , 0.2475341 , 0.23600243],\n",
              "       [0.19266117, 0.32361534, 0.4837235 ],\n",
              "       [0.523063  , 0.24544026, 0.23149674],\n",
              "       [0.17915003, 0.3243096 , 0.4965404 ],\n",
              "       [0.18343964, 0.32450336, 0.49205703],\n",
              "       [0.52967566, 0.24314384, 0.22718047],\n",
              "       [0.57353973, 0.2243025 , 0.20215783],\n",
              "       [0.54100764, 0.2386753 , 0.22031704],\n",
              "       [0.5625673 , 0.22955817, 0.20787455],\n",
              "       [0.56584513, 0.22725664, 0.20689818],\n",
              "       [0.2525164 , 0.3196648 , 0.42781878],\n",
              "       [0.23399262, 0.3221167 , 0.44389063],\n",
              "       [0.48887312, 0.26011696, 0.25100997],\n",
              "       [0.25631937, 0.3201263 , 0.42355433],\n",
              "       [0.18549272, 0.3239898 , 0.49051747],\n",
              "       [0.250311  , 0.321896  , 0.42779303],\n",
              "       [0.21754017, 0.32309604, 0.45936376],\n",
              "       [0.26061445, 0.31871766, 0.42066792],\n",
              "       [0.19666278, 0.3242534 , 0.4790838 ],\n",
              "       [0.24704657, 0.3217741 , 0.4311793 ],\n",
              "       [0.2307312 , 0.3233089 , 0.44595993],\n",
              "       [0.5264041 , 0.24412227, 0.22947356],\n",
              "       [0.5485658 , 0.2354293 , 0.2160049 ],\n",
              "       [0.213908  , 0.32393637, 0.46215558],\n",
              "       [0.53915924, 0.23817168, 0.2226691 ],\n",
              "       [0.18750605, 0.32351857, 0.4889754 ],\n",
              "       [0.2139077 , 0.32412502, 0.4619673 ],\n",
              "       [0.5233623 , 0.24500105, 0.23163673],\n",
              "       [0.2988594 , 0.3132044 , 0.38793617],\n",
              "       [0.17715615, 0.32276353, 0.50008035],\n",
              "       [0.23258364, 0.32312495, 0.44429144],\n",
              "       [0.6118418 , 0.20770735, 0.18045081],\n",
              "       [0.18227667, 0.32450715, 0.49321613],\n",
              "       [0.23840919, 0.32172215, 0.43986872],\n",
              "       [0.24291663, 0.3231306 , 0.43395275],\n",
              "       [0.20581438, 0.32370725, 0.47047845],\n",
              "       [0.23663825, 0.322238  , 0.44112375],\n",
              "       [0.25744033, 0.31939015, 0.42316952],\n",
              "       [0.18171453, 0.32386157, 0.49442387],\n",
              "       [0.29198232, 0.31637868, 0.391639  ],\n",
              "       [0.53992206, 0.23849748, 0.22158052]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9m-wr0mUDmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_test_class = np.argmax(test_y,axis = 1)\n",
        "y_pred_class = np.argmax(y_pred, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgQjbfzZWQyf",
        "colab_type": "text"
      },
      "source": [
        "The location of the maximum probability is checked against the original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC2e1nTrXTl-",
        "colab_type": "code",
        "outputId": "6822b9aa-856b-4489-92b0-5db90c6ca455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_pred_class"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt1XBBjZW3cH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EITqGJ3FTen6",
        "colab_type": "code",
        "outputId": "c95b1081-8834-48cb-9973-90384387b2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test_class,y_pred_class))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       0.00      0.00      0.00        15\n",
            "           2       0.46      1.00      0.63        13\n",
            "\n",
            "    accuracy                           0.67        45\n",
            "   macro avg       0.49      0.67      0.54        45\n",
            "weighted avg       0.51      0.67      0.56        45\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFOpZuw1aUP0",
        "colab_type": "code",
        "outputId": "fc2a6a5c-a0f4-402c-eb62-0a6eaf66b520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(confusion_matrix(y_test_class,y_pred_class))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[17  0  0]\n",
            " [ 0  0 15]\n",
            " [ 0  0 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P32ASP1Vjt0a"
      },
      "source": [
        "### Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8rd0jjAjyTR",
        "colab": {}
      },
      "source": [
        "model.save('iris_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XiipRpe7rbVh"
      },
      "source": [
        "### Build and Train a Deep Neural network with 2 hidden layer  - Optional - For Practice\n",
        "\n",
        "Does it perform better than Linear Classifier? What could be the reason for difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v5Du3lubr4sA",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(4, input_dim = 4, kernel_initializer='normal', activation='softmax'))\n",
        "model.add(tf.keras.layers.Dense(3, kernel_initializer='normal', activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))    \n",
        "    # Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk8RbGV4WrOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0da47c13-155d-472d-94aa-3698c87cda03"
      },
      "source": [
        "model.fit(train_x, train_y,validation_data = (test_x,test_y), epochs = 50)\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 1s 5ms/sample - loss: 1.1497 - accuracy: 0.3143 - val_loss: 1.1096 - val_accuracy: 0.3778\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 278us/sample - loss: 1.1469 - accuracy: 0.3143 - val_loss: 1.1079 - val_accuracy: 0.3778\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 280us/sample - loss: 1.1439 - accuracy: 0.3143 - val_loss: 1.1066 - val_accuracy: 0.3778\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 249us/sample - loss: 1.1415 - accuracy: 0.3143 - val_loss: 1.1056 - val_accuracy: 0.3778\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 283us/sample - loss: 1.1394 - accuracy: 0.3143 - val_loss: 1.1041 - val_accuracy: 0.3778\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 261us/sample - loss: 1.1366 - accuracy: 0.3143 - val_loss: 1.1028 - val_accuracy: 0.3778\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 230us/sample - loss: 1.1344 - accuracy: 0.3143 - val_loss: 1.1019 - val_accuracy: 0.3778\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 254us/sample - loss: 1.1325 - accuracy: 0.3143 - val_loss: 1.1009 - val_accuracy: 0.3778\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 264us/sample - loss: 1.1304 - accuracy: 0.3143 - val_loss: 1.0997 - val_accuracy: 0.3778\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 250us/sample - loss: 1.1280 - accuracy: 0.3143 - val_loss: 1.0988 - val_accuracy: 0.3778\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 310us/sample - loss: 1.1262 - accuracy: 0.3143 - val_loss: 1.0981 - val_accuracy: 0.3778\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 281us/sample - loss: 1.1245 - accuracy: 0.3143 - val_loss: 1.0973 - val_accuracy: 0.3778\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 261us/sample - loss: 1.1230 - accuracy: 0.3143 - val_loss: 1.0969 - val_accuracy: 0.3778\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 269us/sample - loss: 1.1213 - accuracy: 0.3143 - val_loss: 1.0964 - val_accuracy: 0.3778\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 256us/sample - loss: 1.1202 - accuracy: 0.3143 - val_loss: 1.0959 - val_accuracy: 0.3778\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 261us/sample - loss: 1.1185 - accuracy: 0.3143 - val_loss: 1.0956 - val_accuracy: 0.3778\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 251us/sample - loss: 1.1176 - accuracy: 0.3143 - val_loss: 1.0953 - val_accuracy: 0.3778\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 255us/sample - loss: 1.1167 - accuracy: 0.3143 - val_loss: 1.0952 - val_accuracy: 0.3778\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 275us/sample - loss: 1.1162 - accuracy: 0.3143 - val_loss: 1.0950 - val_accuracy: 0.3778\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 260us/sample - loss: 1.1152 - accuracy: 0.3143 - val_loss: 1.0948 - val_accuracy: 0.3778\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 268us/sample - loss: 1.1142 - accuracy: 0.3143 - val_loss: 1.0946 - val_accuracy: 0.3778\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 283us/sample - loss: 1.1131 - accuracy: 0.3143 - val_loss: 1.0944 - val_accuracy: 0.3778\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 252us/sample - loss: 1.1125 - accuracy: 0.3143 - val_loss: 1.0942 - val_accuracy: 0.3778\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 314us/sample - loss: 1.1118 - accuracy: 0.3143 - val_loss: 1.0941 - val_accuracy: 0.3778\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 268us/sample - loss: 1.1107 - accuracy: 0.3143 - val_loss: 1.0941 - val_accuracy: 0.3778\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 247us/sample - loss: 1.1100 - accuracy: 0.3143 - val_loss: 1.0941 - val_accuracy: 0.3778\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 253us/sample - loss: 1.1090 - accuracy: 0.3143 - val_loss: 1.0940 - val_accuracy: 0.3778\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 239us/sample - loss: 1.1082 - accuracy: 0.3143 - val_loss: 1.0941 - val_accuracy: 0.3778\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 235us/sample - loss: 1.1076 - accuracy: 0.3143 - val_loss: 1.0941 - val_accuracy: 0.3778\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 267us/sample - loss: 1.1070 - accuracy: 0.3143 - val_loss: 1.0941 - val_accuracy: 0.3778\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 266us/sample - loss: 1.1067 - accuracy: 0.3143 - val_loss: 1.0941 - val_accuracy: 0.3778\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 263us/sample - loss: 1.1062 - accuracy: 0.3143 - val_loss: 1.0942 - val_accuracy: 0.3778\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 277us/sample - loss: 1.1058 - accuracy: 0.3143 - val_loss: 1.0944 - val_accuracy: 0.3778\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 274us/sample - loss: 1.1053 - accuracy: 0.3143 - val_loss: 1.0945 - val_accuracy: 0.3778\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 222us/sample - loss: 1.1049 - accuracy: 0.3143 - val_loss: 1.0945 - val_accuracy: 0.3778\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 246us/sample - loss: 1.1048 - accuracy: 0.3143 - val_loss: 1.0945 - val_accuracy: 0.3778\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 260us/sample - loss: 1.1045 - accuracy: 0.3143 - val_loss: 1.0947 - val_accuracy: 0.3778\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 248us/sample - loss: 1.1040 - accuracy: 0.3143 - val_loss: 1.0947 - val_accuracy: 0.3778\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 267us/sample - loss: 1.1040 - accuracy: 0.3143 - val_loss: 1.0949 - val_accuracy: 0.3778\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 268us/sample - loss: 1.1033 - accuracy: 0.3143 - val_loss: 1.0952 - val_accuracy: 0.3778\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 270us/sample - loss: 1.1028 - accuracy: 0.3143 - val_loss: 1.0952 - val_accuracy: 0.3778\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 258us/sample - loss: 1.1024 - accuracy: 0.3143 - val_loss: 1.0952 - val_accuracy: 0.3778\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 258us/sample - loss: 1.1022 - accuracy: 0.3143 - val_loss: 1.0952 - val_accuracy: 0.3778\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 245us/sample - loss: 1.1021 - accuracy: 0.3143 - val_loss: 1.0953 - val_accuracy: 0.3778\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 260us/sample - loss: 1.1020 - accuracy: 0.3143 - val_loss: 1.0955 - val_accuracy: 0.3778\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 238us/sample - loss: 1.1018 - accuracy: 0.3143 - val_loss: 1.0958 - val_accuracy: 0.3778\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 245us/sample - loss: 1.1013 - accuracy: 0.3143 - val_loss: 1.0957 - val_accuracy: 0.3778\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 268us/sample - loss: 1.1012 - accuracy: 0.3143 - val_loss: 1.0958 - val_accuracy: 0.3778\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 262us/sample - loss: 1.1012 - accuracy: 0.3143 - val_loss: 1.0962 - val_accuracy: 0.3778\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 295us/sample - loss: 1.1010 - accuracy: 0.3143 - val_loss: 1.0962 - val_accuracy: 0.3778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f26b51ad860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh5xS0IvWwAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "1ee4b515-d516-4d5f-a845-c793f755c8c0"
      },
      "source": [
        "\n",
        "y_pred = model.predict(test_x)\n",
        "y_pred"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35388234, 0.31696913, 0.32914862],\n",
              "       [0.35387444, 0.31696638, 0.32915914],\n",
              "       [0.35367927, 0.31698474, 0.329336  ],\n",
              "       [0.3538467 , 0.3169654 , 0.32918796],\n",
              "       [0.35387638, 0.31697908, 0.32914454],\n",
              "       [0.3535581 , 0.31701615, 0.32942572],\n",
              "       [0.35382038, 0.31696776, 0.32921183],\n",
              "       [0.35358065, 0.3170028 , 0.32941654],\n",
              "       [0.3536128 , 0.31699997, 0.3293872 ],\n",
              "       [0.3538347 , 0.3169623 , 0.32920307],\n",
              "       [0.3538192 , 0.3169809 , 0.32919994],\n",
              "       [0.35390022, 0.31696436, 0.32913545],\n",
              "       [0.3538208 , 0.3169655 , 0.32921368],\n",
              "       [0.353811  , 0.31698507, 0.32920396],\n",
              "       [0.35370287, 0.31700107, 0.32929605],\n",
              "       [0.3536135 , 0.3169949 , 0.3293916 ],\n",
              "       [0.35383326, 0.31694582, 0.3292209 ],\n",
              "       [0.35372445, 0.31699088, 0.3292847 ],\n",
              "       [0.3535797 , 0.3170056 , 0.32941467],\n",
              "       [0.35372338, 0.3169797 , 0.32929686],\n",
              "       [0.35359636, 0.317002  , 0.32940164],\n",
              "       [0.35363713, 0.316995  , 0.3293679 ],\n",
              "       [0.35361576, 0.31700006, 0.3293842 ],\n",
              "       [0.35372624, 0.31698677, 0.32928696],\n",
              "       [0.35361883, 0.31698507, 0.32939607],\n",
              "       [0.3538699 , 0.3169703 , 0.32915986],\n",
              "       [0.35386178, 0.3169657 , 0.3291725 ],\n",
              "       [0.3536647 , 0.31699696, 0.32933843],\n",
              "       [0.35384864, 0.31698492, 0.3291665 ],\n",
              "       [0.35356167, 0.31701955, 0.32941875],\n",
              "       [0.35363826, 0.31699225, 0.32936946],\n",
              "       [0.35380876, 0.31697088, 0.32922038],\n",
              "       [0.35372248, 0.3169817 , 0.32929575],\n",
              "       [0.35352448, 0.31703502, 0.32944041],\n",
              "       [0.35376382, 0.31699288, 0.3292433 ],\n",
              "       [0.35376552, 0.31698415, 0.32925034],\n",
              "       [0.35360667, 0.31699854, 0.32939482],\n",
              "       [0.35368225, 0.31699848, 0.3293192 ],\n",
              "       [0.35371262, 0.316976  , 0.3293114 ],\n",
              "       [0.3535413 , 0.31699723, 0.3294615 ],\n",
              "       [0.35368085, 0.31699342, 0.32932577],\n",
              "       [0.35366273, 0.31699428, 0.3293431 ],\n",
              "       [0.35357845, 0.3170098 , 0.32941175],\n",
              "       [0.35377827, 0.31696793, 0.32925373],\n",
              "       [0.35386828, 0.31697455, 0.3291572 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHwg2p7eW40N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "15d312b3-04a9-4b51-a8f2-ad1ceeceb7e1"
      },
      "source": [
        "y_pred_class"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOD5I4rGW5vj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1641c270-add3-4c1c-9663-ba932ba0a3f0"
      },
      "source": [
        "print(classification_report(y_test_class,y_pred_class))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       0.00      0.00      0.00        15\n",
            "           2       0.46      1.00      0.63        13\n",
            "\n",
            "    accuracy                           0.67        45\n",
            "   macro avg       0.49      0.67      0.54        45\n",
            "weighted avg       0.51      0.67      0.56        45\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_GTunfoXFyB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "32967765-d4e4-4988-fb38-41e14b692589"
      },
      "source": [
        "print(confusion_matrix(y_test_class,y_pred_class))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[17  0  0]\n",
            " [ 0  0 15]\n",
            " [ 0  0 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAQkfR2DXRih",
        "colab_type": "text"
      },
      "source": [
        "There is not much change after adding a layer over the linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zdn6AxVXXd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}