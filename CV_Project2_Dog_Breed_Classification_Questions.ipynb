{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CV_Project2_Dog_Breed_Classification_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kIWaR5ZpKlJ"
      },
      "source": [
        "## Dog Breed Classification\n",
        "\n",
        "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUSE9M3IhkXm",
        "colab_type": "code",
        "outputId": "6371819a-4cc4-4c24-9d55-28a4235b73ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGDKa2IheYpC",
        "colab_type": "text"
      },
      "source": [
        "#### **Note that the notebook has been run in several batches as colab keeps crashing for excess RAM usage. So some cells may not be executed in sequence.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F7MDmaAw2xGO"
      },
      "source": [
        "### Load Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BZWpQv1OwqYK",
        "outputId": "f511b48c-59f2-4d0d-deea-315081fc076e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fVhB9OopxFbX",
        "outputId": "de7fbdfe-efe7-4e9d-9de0-5b5cbe4b3dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import misc\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1q2zzIaUprk_"
      },
      "source": [
        "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tp6FvAToxUFs",
        "colab": {}
      },
      "source": [
        "project_path = \"/content/drive/My Drive/Colab Notebooks/AIML/res_8/project/\"\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rydR_j8lqUei"
      },
      "source": [
        "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3350WZM4w4EL",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'train.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3NHq1iBCfFjE"
      },
      "source": [
        "Repeat the same step for test.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_fxzynvB2YCb",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'test.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jnUMhQrDfJmz"
      },
      "source": [
        "Repeat the same step for sample_submission.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4PyTxE8q2jLf",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'sample_submission.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2G9RIxB-fOLT"
      },
      "source": [
        "Repeat the same step for labels.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rXtnEoEixbgi",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'labels.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sJc1lVrW_jmL"
      },
      "source": [
        "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aYmJKmDqqpng"
      },
      "source": [
        "### Read labels.csv file using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WmlJ2VMY96IZ",
        "colab": {}
      },
      "source": [
        "labels = pd.read_csv('labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hPvb1RSc96If",
        "outputId": "6dcee881-8fda-4804-d5c3-368739042f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id             breed\n",
              "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
              "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
              "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
              "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv80ZCmFjmM9",
        "colab_type": "code",
        "outputId": "42de6022-2840-4664-ac9c-e257a01101da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "labels.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10222 entries, 0 to 10221\n",
            "Data columns (total 2 columns):\n",
            "id       10222 non-null object\n",
            "breed    10222 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 159.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN-G4uIEjma7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsuxAD03jmVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTI6W7cyjmTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QP8YAzQvqyK-"
      },
      "source": [
        "### Print the count of each category of Dogs given in the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3L2naXlr96Im",
        "outputId": "7d285a0e-5d8b-4009-ff05-3237de90f680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "labels.breed.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scottish_deerhound      126\n",
              "maltese_dog             117\n",
              "afghan_hound            116\n",
              "entlebucher             115\n",
              "bernese_mountain_dog    114\n",
              "                       ... \n",
              "komondor                 67\n",
              "golden_retriever         67\n",
              "brabancon_griffon        67\n",
              "briard                   66\n",
              "eskimo_dog               66\n",
              "Name: breed, Length: 120, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CLm3W5RN96Ir",
        "outputId": "a97a510a-8d3c-410f-9e8c-c6986bbc274f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (20,10))\n",
        "g = sns.countplot(x='breed',data=labels);\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJIAAALbCAYAAAChaqqBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHka77dEmXuy",
        "colab_type": "text"
      },
      "source": [
        "### **The top 20 breeds represented in the data are listed below:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23nR73sSl8Xi",
        "colab_type": "code",
        "outputId": "d37c53e1-77a8-4ace-ce9e-9a756524a331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "labels.breed.value_counts().sort_values(ascending = False).head(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scottish_deerhound      126\n",
              "maltese_dog             117\n",
              "afghan_hound            116\n",
              "entlebucher             115\n",
              "bernese_mountain_dog    114\n",
              "shih-tzu                112\n",
              "pomeranian              111\n",
              "great_pyrenees          111\n",
              "basenji                 110\n",
              "samoyed                 109\n",
              "airedale                107\n",
              "tibetan_terrier         107\n",
              "cairn                   106\n",
              "leonberg                106\n",
              "beagle                  105\n",
              "japanese_spaniel        105\n",
              "miniature_pinscher      102\n",
              "australian_terrier      102\n",
              "blenheim_spaniel        102\n",
              "irish_wolfhound         101\n",
              "Name: breed, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J48j9p1FT6KS",
        "colab_type": "text"
      },
      "source": [
        "**The bottom 20 breeds represented in the data are listed below:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IvQnPLTUCDd",
        "colab_type": "code",
        "outputId": "ca55a9ec-0059-4311-c559-ac449a19f38c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "labels.breed.value_counts().sort_values().head(20).sort_values(ascending = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "border_collie                  72\n",
              "flat-coated_retriever          72\n",
              "standard_schnauzer             72\n",
              "redbone                        72\n",
              "curly-coated_retriever         72\n",
              "chihuahua                      71\n",
              "soft-coated_wheaten_terrier    71\n",
              "kuvasz                         71\n",
              "vizsla                         70\n",
              "french_bulldog                 70\n",
              "otterhound                     69\n",
              "german_shepherd                69\n",
              "walker_hound                   69\n",
              "tibetan_mastiff                69\n",
              "giant_schnauzer                69\n",
              "brabancon_griffon              67\n",
              "komondor                       67\n",
              "golden_retriever               67\n",
              "briard                         66\n",
              "eskimo_dog                     66\n",
              "Name: breed, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VWaJ9naXfoiU"
      },
      "source": [
        "## Preparing training dataset\n",
        "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
        "2. Create 2 variables <br> \n",
        "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
        "     b.  y_train - Corresponding label of the dog <br>\n",
        "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
        "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mscY2FvtdnS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAOgdjUFdpJd",
        "colab_type": "text"
      },
      "source": [
        "**(128,128,3), (64,64,3) and (224,224,3) were tried for best accuaracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aC2f9ecR0XGR",
        "outputId": "7ab6acaf-43ec-48ce-9b82-133e265edff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_rows = 224\n",
        "img_cols = 224\n",
        "x_train = []\n",
        "y_train = []\n",
        "i = 0 # initialisation\n",
        "for f, img in tqdm(labels.values): # f for format ,jpg\n",
        "   \n",
        "    train_img = cv2.imread('/content/drive/My Drive/Colab Notebooks/AIML/res_8/project/train/{}.jpg'.format(f), 1)\n",
        "    img_resize = cv2.resize(train_img, (img_rows, img_cols)) \n",
        "    x_train.append(img_resize)\n",
        "    y_train.append(img)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10222/10222 [01:33<00:00, 109.63it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WI94_Qcc0D4M"
      },
      "source": [
        "### Get one-hot encodings of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkkZEpOe0ipk",
        "outputId": "8ee4d9b1-5bdc-461e-c781-e78d7edb5046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = np.array(x_train, np.float32)\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10222, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2YdjUWlBwtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=np.array(y_train).reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "larVyW3zCPHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oe = OneHotEncoder()\n",
        "y_train = oe.fit_transform(y_train).todense()\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJRXaJ1YioL2",
        "colab_type": "code",
        "outputId": "1986fb4e-8595-45fc-8f15-8aaa259c6119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6ioWDEgElBOs"
      },
      "source": [
        "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ARn76j3U1CDa",
        "colab": {}
      },
      "source": [
        "#x_train_scaled = np.subtract(x_train, np.min(x_train))/np.subtract(np.max(x_train),np.min(x_train))\n",
        "x_train_scaled = x_train/255.0\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bdCXuAE11gZL"
      },
      "source": [
        "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kpWx-pgV96Jv",
        "colab": {}
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(x_train_scaled, y_train, test_size=0.1)\n",
        "#plt.imshow(X_train[12])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frf62jOoInnZ",
        "colab_type": "code",
        "outputId": "164341f6-9418-403a-a303-2ccda0f03ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9199, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XkL-N1jDsU8m"
      },
      "source": [
        "### Loading the test data\n",
        "Read the id column from the samples_submission.csv and store it in test_img"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DnpXdpd9b3E7",
        "colab": {}
      },
      "source": [
        "submision = pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOQtByCoDjxP",
        "colab_type": "code",
        "outputId": "01448e50-b10b-467f-9d61-d88d589ca849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "submision.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>affenpinscher</th>\n",
              "      <th>afghan_hound</th>\n",
              "      <th>african_hunting_dog</th>\n",
              "      <th>airedale</th>\n",
              "      <th>american_staffordshire_terrier</th>\n",
              "      <th>appenzeller</th>\n",
              "      <th>australian_terrier</th>\n",
              "      <th>basenji</th>\n",
              "      <th>basset</th>\n",
              "      <th>beagle</th>\n",
              "      <th>bedlington_terrier</th>\n",
              "      <th>bernese_mountain_dog</th>\n",
              "      <th>black-and-tan_coonhound</th>\n",
              "      <th>blenheim_spaniel</th>\n",
              "      <th>bloodhound</th>\n",
              "      <th>bluetick</th>\n",
              "      <th>border_collie</th>\n",
              "      <th>border_terrier</th>\n",
              "      <th>borzoi</th>\n",
              "      <th>boston_bull</th>\n",
              "      <th>bouvier_des_flandres</th>\n",
              "      <th>boxer</th>\n",
              "      <th>brabancon_griffon</th>\n",
              "      <th>briard</th>\n",
              "      <th>brittany_spaniel</th>\n",
              "      <th>bull_mastiff</th>\n",
              "      <th>cairn</th>\n",
              "      <th>cardigan</th>\n",
              "      <th>chesapeake_bay_retriever</th>\n",
              "      <th>chihuahua</th>\n",
              "      <th>chow</th>\n",
              "      <th>clumber</th>\n",
              "      <th>cocker_spaniel</th>\n",
              "      <th>collie</th>\n",
              "      <th>curly-coated_retriever</th>\n",
              "      <th>dandie_dinmont</th>\n",
              "      <th>dhole</th>\n",
              "      <th>dingo</th>\n",
              "      <th>doberman</th>\n",
              "      <th>...</th>\n",
              "      <th>norwegian_elkhound</th>\n",
              "      <th>norwich_terrier</th>\n",
              "      <th>old_english_sheepdog</th>\n",
              "      <th>otterhound</th>\n",
              "      <th>papillon</th>\n",
              "      <th>pekinese</th>\n",
              "      <th>pembroke</th>\n",
              "      <th>pomeranian</th>\n",
              "      <th>pug</th>\n",
              "      <th>redbone</th>\n",
              "      <th>rhodesian_ridgeback</th>\n",
              "      <th>rottweiler</th>\n",
              "      <th>saint_bernard</th>\n",
              "      <th>saluki</th>\n",
              "      <th>samoyed</th>\n",
              "      <th>schipperke</th>\n",
              "      <th>scotch_terrier</th>\n",
              "      <th>scottish_deerhound</th>\n",
              "      <th>sealyham_terrier</th>\n",
              "      <th>shetland_sheepdog</th>\n",
              "      <th>shih-tzu</th>\n",
              "      <th>siberian_husky</th>\n",
              "      <th>silky_terrier</th>\n",
              "      <th>soft-coated_wheaten_terrier</th>\n",
              "      <th>staffordshire_bullterrier</th>\n",
              "      <th>standard_poodle</th>\n",
              "      <th>standard_schnauzer</th>\n",
              "      <th>sussex_spaniel</th>\n",
              "      <th>tibetan_mastiff</th>\n",
              "      <th>tibetan_terrier</th>\n",
              "      <th>toy_poodle</th>\n",
              "      <th>toy_terrier</th>\n",
              "      <th>vizsla</th>\n",
              "      <th>walker_hound</th>\n",
              "      <th>weimaraner</th>\n",
              "      <th>welsh_springer_spaniel</th>\n",
              "      <th>west_highland_white_terrier</th>\n",
              "      <th>whippet</th>\n",
              "      <th>wire-haired_fox_terrier</th>\n",
              "      <th>yorkshire_terrier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id  ...  yorkshire_terrier\n",
              "0  000621fb3cbb32d8935728e48679680e  ...           0.008333\n",
              "1  00102ee9d8eb90812350685311fe5890  ...           0.008333\n",
              "2  0012a730dfa437f5f3613fb75efcd4ce  ...           0.008333\n",
              "3  001510bc8570bbeee98c8d80c8a95ec1  ...           0.008333\n",
              "4  001a5f3114548acdefa3d4da05474c2e  ...           0.008333\n",
              "\n",
              "[5 rows x 121 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pdpHd1_DumJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img = submision.id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DEJqZIMbm0Jo"
      },
      "source": [
        "Run the below code to load the test image files in x_test_feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awGOr51zDtv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = submision.drop('id', axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBA1rJb0d92v",
        "colab_type": "text"
      },
      "source": [
        "**Since the best result is obtained for 224,224,3, the test set is loaded for 224,224,3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zf7n4WG-b3Hv",
        "outputId": "089be313-e4a0-4e04-b9e0-0a1c4849d469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test_features = []\n",
        "\n",
        "\n",
        "i = 0 # initialisation\n",
        "for f in tqdm(submision.id): # f for format ,jpg\n",
        "   \n",
        "    test_img = cv2.imread('./test/{}.jpg'.format(f), 1)\n",
        "    img_resize = cv2.resize(test_img, (224, 224)) \n",
        "    x_test_features.append(img_resize)\n",
        "    \n",
        "    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10357/10357 [01:24<00:00, 123.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPa_2-yPJngw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9323ade7-7a5c-48e3-8138-7cbf791fde97"
      },
      "source": [
        "x_test = np.array(x_test_features, np.float32)\n",
        "x_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10357, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9My6qSyDnE-_"
      },
      "source": [
        "Normalize the test data and convert it into 4 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "93n-IntMnJGI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66336775-58f3-46b3-dbd1-c92690428f64"
      },
      "source": [
        "x_test_scaled = x_test/255.0\n",
        "x_test_scaled.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10357, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEMOhvvLKd_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zKezNJVMsocP"
      },
      "source": [
        "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
        "\n",
        "1. Add a Dense layer with 256 neurons with `relu` activation\n",
        "\n",
        "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D2jxTY2S96J4",
        "colab": {}
      },
      "source": [
        "#Clear any previous model from memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Initialize model\n",
        "model = tf.keras.models.Sequential()\n",
        "#normalize data\n",
        "#model.add(tf.keras.layers.BatchNormalization(input_shape=(img_rows,img_cols,3,)))\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(tf.keras.layers.Conv2D(128, input_shape=(img_rows,img_cols,3,),kernel_size=(5,5), activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Conv Layer\n",
        "#model.add(tf.keras.layers.Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Add Dense Layers after flattening the data\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "#Add Output Layer\n",
        "model.add(tf.keras.layers.Dense(120, activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f_BAvCzo96J6",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "adm = optimizers.Adam(lr = 1e-3)\n",
        "model.compile(optimizer=adm, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOeTMTWB3yGR",
        "colab_type": "code",
        "outputId": "447e290e-6fb0-4628-a237-2db03db125b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 60, 60, 128)       9728      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 60, 60, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 58, 58, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 58, 58, 256)       1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 861184)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               220463360 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 220,801,656\n",
            "Trainable params: 220,800,376\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ui8EXw6_oqpR"
      },
      "source": [
        "### Use batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IriIc37NozbK",
        "outputId": "060d3477-017b-44d7-9b26-f34f0b44149c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, Y_train,\n",
        "          validation_data = (X_val, Y_val),\n",
        "                    epochs=50,\n",
        "                    batch_size = 128,steps_per_epoch = len(X_train)//128\n",
        "                    \n",
        "                    )\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9199 samples, validate on 1023 samples\n",
            "Epoch 1/50\n",
            "9088/9199 [============================>.] - ETA: 0s - loss: 4.8510 - accuracy: 0.0298 - val_loss: 4.9603 - val_accuracy: 0.0049Epoch 2/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 4.4411 - accuracy: 0.0625 - val_loss: 5.0316 - val_accuracy: 0.0108Epoch 3/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 3.9094 - accuracy: 0.1386 - val_loss: 5.3210 - val_accuracy: 0.0127Epoch 4/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 3.1045 - accuracy: 0.3137 - val_loss: 5.8708 - val_accuracy: 0.0078Epoch 5/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 1.9176 - accuracy: 0.6683 - val_loss: 6.3927 - val_accuracy: 0.0147Epoch 6/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.8919 - accuracy: 0.9136 - val_loss: 7.0165 - val_accuracy: 0.0147Epoch 7/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.9864 - val_loss: 6.4522 - val_accuracy: 0.0186Epoch 8/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.1842 - accuracy: 0.9971 - val_loss: 5.6191 - val_accuracy: 0.0196Epoch 9/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9991 - val_loss: 4.7302 - val_accuracy: 0.0430Epoch 10/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9985 - val_loss: 4.4682 - val_accuracy: 0.0547Epoch 11/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9989 - val_loss: 4.3943 - val_accuracy: 0.0635Epoch 12/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0455 - accuracy: 0.9990 - val_loss: 4.3767 - val_accuracy: 0.0704Epoch 13/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9992 - val_loss: 4.3783 - val_accuracy: 0.0694Epoch 14/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9988 - val_loss: 4.4221 - val_accuracy: 0.0674Epoch 15/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9991 - val_loss: 4.3751 - val_accuracy: 0.0704Epoch 16/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9990 - val_loss: 4.3738 - val_accuracy: 0.0704Epoch 17/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9990 - val_loss: 4.3789 - val_accuracy: 0.0762Epoch 18/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9991 - val_loss: 4.3847 - val_accuracy: 0.0704Epoch 19/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9991 - val_loss: 4.4045 - val_accuracy: 0.0723Epoch 20/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9992 - val_loss: 4.4086 - val_accuracy: 0.0704Epoch 21/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9990 - val_loss: 4.3976 - val_accuracy: 0.0665Epoch 22/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9988 - val_loss: 4.4119 - val_accuracy: 0.0704Epoch 23/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9994 - val_loss: 4.4308 - val_accuracy: 0.0694Epoch 24/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9997 - val_loss: 4.3974 - val_accuracy: 0.0694Epoch 25/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9994 - val_loss: 4.4047 - val_accuracy: 0.0704Epoch 26/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9989 - val_loss: 4.4463 - val_accuracy: 0.0674Epoch 27/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9991 - val_loss: 4.4056 - val_accuracy: 0.0704Epoch 28/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9991 - val_loss: 4.4180 - val_accuracy: 0.0674Epoch 29/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9993 - val_loss: 4.4589 - val_accuracy: 0.0684Epoch 30/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9996 - val_loss: 4.4772 - val_accuracy: 0.0665Epoch 31/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9991 - val_loss: 4.4392 - val_accuracy: 0.0665Epoch 32/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9990 - val_loss: 4.4364 - val_accuracy: 0.0635Epoch 33/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9992 - val_loss: 4.5341 - val_accuracy: 0.0616Epoch 34/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9993 - val_loss: 4.4910 - val_accuracy: 0.0645Epoch 35/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9990 - val_loss: 4.4922 - val_accuracy: 0.0714Epoch 36/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9994 - val_loss: 4.4372 - val_accuracy: 0.0723Epoch 37/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9990 - val_loss: 4.4564 - val_accuracy: 0.0645Epoch 38/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993 - val_loss: 4.4368 - val_accuracy: 0.0704Epoch 39/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 4.4421 - val_accuracy: 0.0674Epoch 40/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993 - val_loss: 4.4438 - val_accuracy: 0.0723Epoch 41/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9992 - val_loss: 4.5384 - val_accuracy: 0.0782Epoch 42/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9990 - val_loss: 4.4781 - val_accuracy: 0.0655Epoch 43/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9994 - val_loss: 4.5560 - val_accuracy: 0.0674Epoch 44/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9994 - val_loss: 4.4726 - val_accuracy: 0.0743Epoch 45/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9996 - val_loss: 4.5029 - val_accuracy: 0.0694Epoch 46/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9992 - val_loss: 4.4830 - val_accuracy: 0.0665Epoch 47/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9992 - val_loss: 4.4746 - val_accuracy: 0.0655Epoch 48/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9994 - val_loss: 4.4787 - val_accuracy: 0.0645Epoch 49/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9993 - val_loss: 4.5410 - val_accuracy: 0.0645Epoch 50/50\n",
            "9071/9199 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9991 - val_loss: 4.4714 - val_accuracy: 0.0626dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSIlTIhARKXFKBCIiJU6JQESkxP0f/c/p4VL50MwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0PR9j5_Xozmd",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z8hWaKmjoz69"
      },
      "source": [
        "#The model accuracy is very poor !!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "agJKkc6xtKiq"
      },
      "source": [
        "### Use Data Augmentation in the above model to see if the accuracy improves\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lBILl-PdCBt",
        "colab_type": "text"
      },
      "source": [
        "Fit the model using fit_generator() using train_generator and val_generator from the above step with 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "31Mn8qnZb3Ru",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    \n",
        "   \n",
        "    shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDLQVFDP96KI",
        "colab": {}
      },
      "source": [
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqt_7b4F7At2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valgen = ImageDataGenerator(\n",
        "     shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "valgen.fit(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bqTlW0qHb3Xb",
        "outputId": "c9d00f73-d81c-43ea-ffab-d3c6b7b8169e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(datagen.flow(X_train, Y_train,batch_size = 128),\n",
        "          validation_data = valgen.flow(X_val, Y_val),\n",
        "          steps_per_epoch=len(X_train) // 128,\n",
        "                    epochs=50\n",
        "                    \n",
        "                    \n",
        "                    )\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-53-377c6719e520>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 71 steps, validate for 32 steps\n",
            "Epoch 1/50\n",
            "71/71 [==============================] - 11s 160ms/step - loss: 5.5308 - accuracy: 0.0488 - val_loss: 31.3742 - val_accuracy: 0.0088\n",
            "Epoch 2/50\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.6207 - accuracy: 0.0757 - val_loss: 6.4360 - val_accuracy: 0.0186\n",
            "Epoch 3/50\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.1473 - accuracy: 0.1127 - val_loss: 4.6424 - val_accuracy: 0.0303\n",
            "Epoch 4/50\n",
            "71/71 [==============================] - 11s 153ms/step - loss: 3.7486 - accuracy: 0.1605 - val_loss: 4.4992 - val_accuracy: 0.0557\n",
            "Epoch 5/50\n",
            "71/71 [==============================] - 11s 153ms/step - loss: 3.4367 - accuracy: 0.2112 - val_loss: 4.3000 - val_accuracy: 0.0645\n",
            "Epoch 6/50\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 3.1508 - accuracy: 0.2703 - val_loss: 4.3636 - val_accuracy: 0.0899\n",
            "Epoch 7/50\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 2.9049 - accuracy: 0.3200 - val_loss: 4.2991 - val_accuracy: 0.0792\n",
            "Epoch 8/50\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 2.6645 - accuracy: 0.3781 - val_loss: 4.5023 - val_accuracy: 0.0831\n",
            "Epoch 9/50\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 2.4084 - accuracy: 0.4350 - val_loss: 4.2696 - val_accuracy: 0.1036\n",
            "Epoch 10/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 2.1979 - accuracy: 0.4765 - val_loss: 4.3135 - val_accuracy: 0.0948\n",
            "Epoch 11/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 1.9809 - accuracy: 0.5278 - val_loss: 4.3714 - val_accuracy: 0.1017\n",
            "Epoch 12/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 1.8084 - accuracy: 0.5742 - val_loss: 4.7334 - val_accuracy: 0.0880\n",
            "Epoch 13/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 1.6342 - accuracy: 0.6075 - val_loss: 4.2827 - val_accuracy: 0.0919\n",
            "Epoch 14/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 1.4380 - accuracy: 0.6573 - val_loss: 4.2519 - val_accuracy: 0.0997\n",
            "Epoch 15/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 1.3666 - accuracy: 0.6697 - val_loss: 4.6913 - val_accuracy: 0.1017\n",
            "Epoch 16/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 1.2431 - accuracy: 0.6931 - val_loss: 4.4130 - val_accuracy: 0.1085\n",
            "Epoch 17/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 1.1043 - accuracy: 0.7319 - val_loss: 4.5291 - val_accuracy: 0.1124\n",
            "Epoch 18/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 1.0517 - accuracy: 0.7398 - val_loss: 4.4675 - val_accuracy: 0.1124\n",
            "Epoch 19/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 0.9471 - accuracy: 0.7677 - val_loss: 4.5509 - val_accuracy: 0.0948\n",
            "Epoch 20/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.8662 - accuracy: 0.7818 - val_loss: 5.1068 - val_accuracy: 0.1056\n",
            "Epoch 21/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.8166 - accuracy: 0.7977 - val_loss: 4.6722 - val_accuracy: 0.1065\n",
            "Epoch 22/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 0.7347 - accuracy: 0.8138 - val_loss: 4.8106 - val_accuracy: 0.1085\n",
            "Epoch 23/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.6971 - accuracy: 0.8242 - val_loss: 4.6976 - val_accuracy: 0.0997\n",
            "Epoch 24/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.6528 - accuracy: 0.8353 - val_loss: 5.0137 - val_accuracy: 0.1036\n",
            "Epoch 25/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.6091 - accuracy: 0.8429 - val_loss: 4.7050 - val_accuracy: 0.1232\n",
            "Epoch 26/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.5907 - accuracy: 0.8501 - val_loss: 4.8615 - val_accuracy: 0.1046\n",
            "Epoch 27/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.5464 - accuracy: 0.8601 - val_loss: 4.5909 - val_accuracy: 0.1114\n",
            "Epoch 28/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.5166 - accuracy: 0.8691 - val_loss: 4.5527 - val_accuracy: 0.1026\n",
            "Epoch 29/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.4815 - accuracy: 0.8765 - val_loss: 5.0466 - val_accuracy: 0.1065\n",
            "Epoch 30/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.4666 - accuracy: 0.8783 - val_loss: 5.2494 - val_accuracy: 0.0850\n",
            "Epoch 31/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.4286 - accuracy: 0.8900 - val_loss: 4.8504 - val_accuracy: 0.1114\n",
            "Epoch 32/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.4201 - accuracy: 0.8932 - val_loss: 5.1166 - val_accuracy: 0.1065\n",
            "Epoch 33/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.3917 - accuracy: 0.8988 - val_loss: 4.8623 - val_accuracy: 0.1105\n",
            "Epoch 34/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.4024 - accuracy: 0.8908 - val_loss: 5.4230 - val_accuracy: 0.1095\n",
            "Epoch 35/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 0.3784 - accuracy: 0.8997 - val_loss: 5.3125 - val_accuracy: 0.0997\n",
            "Epoch 36/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 0.3352 - accuracy: 0.9125 - val_loss: 5.1171 - val_accuracy: 0.0997\n",
            "Epoch 37/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.3200 - accuracy: 0.9180 - val_loss: 4.9954 - val_accuracy: 0.0899\n",
            "Epoch 38/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.3298 - accuracy: 0.9138 - val_loss: 5.9377 - val_accuracy: 0.1056\n",
            "Epoch 39/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.3024 - accuracy: 0.9219 - val_loss: 5.0635 - val_accuracy: 0.1095\n",
            "Epoch 40/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.3055 - accuracy: 0.9185 - val_loss: 5.5544 - val_accuracy: 0.1046\n",
            "Epoch 41/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.3060 - accuracy: 0.9188 - val_loss: 5.3814 - val_accuracy: 0.1065\n",
            "Epoch 42/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.2876 - accuracy: 0.9218 - val_loss: 5.3140 - val_accuracy: 0.0929\n",
            "Epoch 43/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.2764 - accuracy: 0.9268 - val_loss: 5.2661 - val_accuracy: 0.1065\n",
            "Epoch 44/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.2701 - accuracy: 0.9268 - val_loss: 5.7939 - val_accuracy: 0.0958\n",
            "Epoch 45/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.2614 - accuracy: 0.9298 - val_loss: 5.1479 - val_accuracy: 0.0978\n",
            "Epoch 46/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.2540 - accuracy: 0.9302 - val_loss: 5.0690 - val_accuracy: 0.0899\n",
            "Epoch 47/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.2444 - accuracy: 0.9337 - val_loss: 5.2559 - val_accuracy: 0.1075\n",
            "Epoch 48/50\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 0.2342 - accuracy: 0.9373 - val_loss: 4.9509 - val_accuracy: 0.0929\n",
            "Epoch 49/50\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 0.2325 - accuracy: 0.9385 - val_loss: 5.3141 - val_accuracy: 0.1173\n",
            "Epoch 50/50\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 0.2291 - accuracy: 0.9343 - val_loss: 5.3213 - val_accuracy: 0.1075\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niMSMgl9EJGYU/CIiMaPgFxGJmf8PxWejyGiklzIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYuoO0n2YcMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sehaRgT-96KQ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J1K2MqHbuPUa",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q2zmLztqo5DY"
      },
      "source": [
        "# Model accuracy is still poor!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rSTATrhsAo7L"
      },
      "source": [
        "### Lets use Transfer Learning\n",
        "\n",
        "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zy5JdbW6pIvD"
      },
      "source": [
        "Use the below code to load VGG16 weights trained on ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yrqs0zg7ApNw",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "# Instantiate the model with the pre-trained weights (no top)\n",
        "base_model= VGG16(weights=(project_path+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
        "                 include_top=False, pooling='avg', input_shape = (64,64,3))\n",
        "#tf.keras.backend.clear_session()\n",
        "#base_model= VGG16(weights='imagenet',\n",
        "#                 include_top=False, pooling='avg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EItOlRBGpV_A"
      },
      "source": [
        "Print the summary of the base_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lQsEBgnlpHjH",
        "outputId": "7365f00a-7c11-4493-c6f0-412758a7cac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su_sdvWKRxxy",
        "colab_type": "code",
        "outputId": "1c8d8ee8-5c0d-45d8-96f0-bbec799d73cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "new_model = tf.keras.models.Sequential()\n",
        "new_model.add(base_model)\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fHpeOyW0qauW"
      },
      "source": [
        "### Add the following classification layers to the imported VGG Model <br>\n",
        "1. Flatten Layer\n",
        "2. Dense layer with 1024 neurons with activation as Relu\n",
        "3. Dense layer with 256 neurons with activation as Relu\n",
        "4. Dense layer with 120 neurons with activation as Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0BpT4MLkqoaO",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#Add Dense Layers after flattening the data\n",
        "new_model.add(tf.keras.layers.Flatten())\n",
        "new_model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "new_model.add(tf.keras.layers.Dropout(0.5))\n",
        "new_model.add(tf.keras.layers.BatchNormalization())\n",
        "#new_model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "#new_model.add(tf.keras.layers.BatchNormalization())\n",
        "#new_model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "#new_model.add(tf.keras.layers.BatchNormalization())\n",
        "new_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "new_model.add(tf.keras.layers.Dropout(0.5))\n",
        "new_model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Output Layer\n",
        "new_model.add(tf.keras.layers.Dense(120, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LeQem0pHITIj"
      },
      "source": [
        "### Make all the layers in the base_model (VGG16) to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7w9CSPvIRnX",
        "colab": {}
      },
      "source": [
        "for layer in new_model.layers[:1]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxvjBaPoTozA",
        "colab_type": "code",
        "outputId": "b858f10a-6f43-48b9-dad3-491c7acc659b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "for layer in new_model.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.training.Model object at 0x7fb90016ee10> False\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7fb900141cc0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb900141cf8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fb900141ef0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb9000c3668> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb9000c32e8> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fb9000d9a58> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb900100f98> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb900100e80> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLGqshivUnRs",
        "colab_type": "code",
        "outputId": "aead414c-dafd-44d4-ba9c-09dd4ff1dcd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 15,538,360\n",
            "Trainable params: 821,112\n",
            "Non-trainable params: 14,717,248\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kj-BwqgfIkdv"
      },
      "source": [
        "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YD5fAgVQIpKZ"
      },
      "source": [
        "Try to get training and validation accuracy to be more than 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEUMs8lqMeR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GawjTeexM1xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SZk2SWvjIoRP",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "adm = optimizers.Adam(lr = 0.0001)\n",
        "new_model.compile(optimizer=adm, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6-bxiHeoew-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the best model using model checkpoint callback\n",
        "model_checkpoint=tf.keras.callbacks.ModelCheckpoint('first_model3.h5', \n",
        "                                                    save_best_only=True, \n",
        "                                                    monitor='val_accuracy', \n",
        "                                                    mode='max', \n",
        "                                                    verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxAFIlirMaMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlAqOTyvTHCv",
        "colab_type": "code",
        "outputId": "62cef128-edca-428f-fe58-b29d2ddcaea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = new_model.fit_generator(datagen.flow(X_train, Y_train,batch_size = 128),\n",
        "          validation_data = (X_val, Y_val),\n",
        "          steps_per_epoch=len(X_train) // 128,\n",
        "                    epochs=200, initial_epoch = 100, \n",
        "               callbacks = [model_checkpoint]\n",
        "                    \n",
        "                    )\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 71 steps, validate on 1023 samples\n",
            "Epoch 101/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.4097 - accuracy: 0.2041\n",
            "Epoch 00101: val_accuracy did not improve from 0.13881\n",
            "71/71 [==============================] - 9s 121ms/step - loss: 3.4119 - accuracy: 0.2038 - val_loss: 3.9304 - val_accuracy: 0.1329\n",
            "Epoch 102/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3992 - accuracy: 0.2080\n",
            "Epoch 00102: val_accuracy did not improve from 0.13881\n",
            "71/71 [==============================] - 9s 125ms/step - loss: 3.4002 - accuracy: 0.2079 - val_loss: 3.9307 - val_accuracy: 0.1271\n",
            "Epoch 103/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.4124 - accuracy: 0.2057\n",
            "Epoch 00103: val_accuracy did not improve from 0.13881\n",
            "71/71 [==============================] - 9s 122ms/step - loss: 3.4116 - accuracy: 0.2059 - val_loss: 3.9255 - val_accuracy: 0.1339\n",
            "Epoch 104/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3916 - accuracy: 0.2094\n",
            "Epoch 00104: val_accuracy did not improve from 0.13881\n",
            "71/71 [==============================] - 9s 129ms/step - loss: 3.3902 - accuracy: 0.2097 - val_loss: 3.9234 - val_accuracy: 0.1329\n",
            "Epoch 105/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3787 - accuracy: 0.2032\n",
            "Epoch 00105: val_accuracy improved from 0.13881 to 0.14370, saving model to first_model3.h5\n",
            "71/71 [==============================] - 10s 142ms/step - loss: 3.3798 - accuracy: 0.2036 - val_loss: 3.9199 - val_accuracy: 0.1437\n",
            "Epoch 106/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3861 - accuracy: 0.2079\n",
            "Epoch 00106: val_accuracy did not improve from 0.14370\n",
            "71/71 [==============================] - 9s 122ms/step - loss: 3.3859 - accuracy: 0.2081 - val_loss: 3.9329 - val_accuracy: 0.1339\n",
            "Epoch 107/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3815 - accuracy: 0.2079\n",
            "Epoch 00107: val_accuracy did not improve from 0.14370\n",
            "71/71 [==============================] - 9s 124ms/step - loss: 3.3814 - accuracy: 0.2085 - val_loss: 3.9336 - val_accuracy: 0.1369\n",
            "Epoch 108/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3670 - accuracy: 0.2090\n",
            "Epoch 00108: val_accuracy did not improve from 0.14370\n",
            "71/71 [==============================] - 9s 124ms/step - loss: 3.3673 - accuracy: 0.2092 - val_loss: 3.9295 - val_accuracy: 0.1310\n",
            "Epoch 109/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3530 - accuracy: 0.2135\n",
            "Epoch 00109: val_accuracy improved from 0.14370 to 0.14467, saving model to first_model3.h5\n",
            "71/71 [==============================] - 10s 142ms/step - loss: 3.3522 - accuracy: 0.2136 - val_loss: 3.9248 - val_accuracy: 0.1447\n",
            "Epoch 110/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3377 - accuracy: 0.2212\n",
            "Epoch 00110: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 127ms/step - loss: 3.3385 - accuracy: 0.2213 - val_loss: 3.9225 - val_accuracy: 0.1359\n",
            "Epoch 111/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3118 - accuracy: 0.2254\n",
            "Epoch 00111: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 124ms/step - loss: 3.3113 - accuracy: 0.2259 - val_loss: 3.9449 - val_accuracy: 0.1417\n",
            "Epoch 112/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3231 - accuracy: 0.2178\n",
            "Epoch 00112: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 124ms/step - loss: 3.3206 - accuracy: 0.2179 - val_loss: 3.9328 - val_accuracy: 0.1427\n",
            "Epoch 113/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.3255 - accuracy: 0.2206\n",
            "Epoch 00113: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 3.3242 - accuracy: 0.2211 - val_loss: 3.9273 - val_accuracy: 0.1369\n",
            "Epoch 114/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2962 - accuracy: 0.2208\n",
            "Epoch 00114: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 123ms/step - loss: 3.2954 - accuracy: 0.2205 - val_loss: 3.9342 - val_accuracy: 0.1378\n",
            "Epoch 115/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2790 - accuracy: 0.2267\n",
            "Epoch 00115: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 125ms/step - loss: 3.2766 - accuracy: 0.2275 - val_loss: 3.9426 - val_accuracy: 0.1349\n",
            "Epoch 116/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2733 - accuracy: 0.2302\n",
            "Epoch 00116: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 3.2752 - accuracy: 0.2303 - val_loss: 3.9198 - val_accuracy: 0.1447\n",
            "Epoch 117/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2663 - accuracy: 0.2280\n",
            "Epoch 00117: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 127ms/step - loss: 3.2654 - accuracy: 0.2289 - val_loss: 3.9135 - val_accuracy: 0.1339\n",
            "Epoch 118/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2582 - accuracy: 0.2267\n",
            "Epoch 00118: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 122ms/step - loss: 3.2616 - accuracy: 0.2265 - val_loss: 3.9158 - val_accuracy: 0.1320\n",
            "Epoch 119/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2542 - accuracy: 0.2341\n",
            "Epoch 00119: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 3.2539 - accuracy: 0.2347 - val_loss: 3.9313 - val_accuracy: 0.1388\n",
            "Epoch 120/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2497 - accuracy: 0.2331\n",
            "Epoch 00120: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 3.2508 - accuracy: 0.2336 - val_loss: 3.9236 - val_accuracy: 0.1359\n",
            "Epoch 121/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2397 - accuracy: 0.2324\n",
            "Epoch 00121: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 124ms/step - loss: 3.2400 - accuracy: 0.2321 - val_loss: 3.9369 - val_accuracy: 0.1339\n",
            "Epoch 122/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2160 - accuracy: 0.2353\n",
            "Epoch 00122: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 125ms/step - loss: 3.2188 - accuracy: 0.2350 - val_loss: 3.9417 - val_accuracy: 0.1359\n",
            "Epoch 123/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.2236 - accuracy: 0.2404\n",
            "Epoch 00123: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 122ms/step - loss: 3.2217 - accuracy: 0.2409 - val_loss: 3.9218 - val_accuracy: 0.1369\n",
            "Epoch 124/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1956 - accuracy: 0.2479\n",
            "Epoch 00124: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 125ms/step - loss: 3.1964 - accuracy: 0.2479 - val_loss: 3.9361 - val_accuracy: 0.1447\n",
            "Epoch 125/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1980 - accuracy: 0.2474\n",
            "Epoch 00125: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 121ms/step - loss: 3.1983 - accuracy: 0.2476 - val_loss: 3.9218 - val_accuracy: 0.1378\n",
            "Epoch 126/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1827 - accuracy: 0.2469\n",
            "Epoch 00126: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 3.1814 - accuracy: 0.2475 - val_loss: 3.9232 - val_accuracy: 0.1437\n",
            "Epoch 127/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1884 - accuracy: 0.2490\n",
            "Epoch 00127: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 3.1891 - accuracy: 0.2487 - val_loss: 3.9393 - val_accuracy: 0.1281\n",
            "Epoch 128/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1954 - accuracy: 0.2382\n",
            "Epoch 00128: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 3.1945 - accuracy: 0.2372 - val_loss: 3.9370 - val_accuracy: 0.1349\n",
            "Epoch 129/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1503 - accuracy: 0.2548\n",
            "Epoch 00129: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 9s 121ms/step - loss: 3.1506 - accuracy: 0.2554 - val_loss: 3.9344 - val_accuracy: 0.1349\n",
            "Epoch 130/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1514 - accuracy: 0.2541\n",
            "Epoch 00130: val_accuracy did not improve from 0.14467\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 3.1516 - accuracy: 0.2528 - val_loss: 3.9312 - val_accuracy: 0.1359\n",
            "Epoch 131/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1695 - accuracy: 0.2432\n",
            "Epoch 00131: val_accuracy improved from 0.14467 to 0.14956, saving model to first_model3.h5\n",
            "71/71 [==============================] - 10s 139ms/step - loss: 3.1707 - accuracy: 0.2430 - val_loss: 3.9282 - val_accuracy: 0.1496\n",
            "Epoch 132/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1364 - accuracy: 0.2530\n",
            "Epoch 00132: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 116ms/step - loss: 3.1356 - accuracy: 0.2537 - val_loss: 3.9337 - val_accuracy: 0.1466\n",
            "Epoch 133/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1409 - accuracy: 0.2555\n",
            "Epoch 00133: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 122ms/step - loss: 3.1402 - accuracy: 0.2555 - val_loss: 3.9412 - val_accuracy: 0.1417\n",
            "Epoch 134/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1396 - accuracy: 0.2556\n",
            "Epoch 00134: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 3.1395 - accuracy: 0.2561 - val_loss: 3.9544 - val_accuracy: 0.1417\n",
            "Epoch 135/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1125 - accuracy: 0.2554\n",
            "Epoch 00135: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 3.1142 - accuracy: 0.2550 - val_loss: 3.9402 - val_accuracy: 0.1466\n",
            "Epoch 136/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1416 - accuracy: 0.2529\n",
            "Epoch 00136: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 3.1387 - accuracy: 0.2525 - val_loss: 3.9356 - val_accuracy: 0.1398\n",
            "Epoch 137/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1020 - accuracy: 0.2566\n",
            "Epoch 00137: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 3.1024 - accuracy: 0.2563 - val_loss: 3.9343 - val_accuracy: 0.1437\n",
            "Epoch 138/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.1041 - accuracy: 0.2623\n",
            "Epoch 00138: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 122ms/step - loss: 3.1041 - accuracy: 0.2616 - val_loss: 3.9308 - val_accuracy: 0.1359\n",
            "Epoch 139/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0777 - accuracy: 0.2648\n",
            "Epoch 00139: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 3.0737 - accuracy: 0.2651 - val_loss: 3.9366 - val_accuracy: 0.1369\n",
            "Epoch 140/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0758 - accuracy: 0.2634\n",
            "Epoch 00140: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 3.0774 - accuracy: 0.2637 - val_loss: 3.9336 - val_accuracy: 0.1427\n",
            "Epoch 141/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0595 - accuracy: 0.2623\n",
            "Epoch 00141: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 3.0594 - accuracy: 0.2625 - val_loss: 3.9450 - val_accuracy: 0.1427\n",
            "Epoch 142/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0620 - accuracy: 0.2668\n",
            "Epoch 00142: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 3.0640 - accuracy: 0.2660 - val_loss: 3.9354 - val_accuracy: 0.1359\n",
            "Epoch 143/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0714 - accuracy: 0.2645\n",
            "Epoch 00143: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 3.0688 - accuracy: 0.2652 - val_loss: 3.9466 - val_accuracy: 0.1427\n",
            "Epoch 144/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0489 - accuracy: 0.2700\n",
            "Epoch 00144: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 3.0472 - accuracy: 0.2701 - val_loss: 3.9309 - val_accuracy: 0.1359\n",
            "Epoch 145/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0498 - accuracy: 0.2742\n",
            "Epoch 00145: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 123ms/step - loss: 3.0522 - accuracy: 0.2736 - val_loss: 3.9451 - val_accuracy: 0.1378\n",
            "Epoch 146/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0097 - accuracy: 0.2770\n",
            "Epoch 00146: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 3.0131 - accuracy: 0.2765 - val_loss: 3.9444 - val_accuracy: 0.1427\n",
            "Epoch 147/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0229 - accuracy: 0.2762\n",
            "Epoch 00147: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 3.0249 - accuracy: 0.2759 - val_loss: 3.9479 - val_accuracy: 0.1476\n",
            "Epoch 148/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0185 - accuracy: 0.2769\n",
            "Epoch 00148: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 3.0186 - accuracy: 0.2764 - val_loss: 3.9422 - val_accuracy: 0.1329\n",
            "Epoch 149/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0117 - accuracy: 0.2789\n",
            "Epoch 00149: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 3.0108 - accuracy: 0.2788 - val_loss: 3.9485 - val_accuracy: 0.1329\n",
            "Epoch 150/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0107 - accuracy: 0.2782\n",
            "Epoch 00150: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 3.0087 - accuracy: 0.2789 - val_loss: 3.9487 - val_accuracy: 0.1408\n",
            "Epoch 151/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 3.0085 - accuracy: 0.2771\n",
            "Epoch 00151: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 3.0071 - accuracy: 0.2776 - val_loss: 3.9564 - val_accuracy: 0.1417\n",
            "Epoch 152/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9714 - accuracy: 0.2835\n",
            "Epoch 00152: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 123ms/step - loss: 2.9734 - accuracy: 0.2823 - val_loss: 3.9455 - val_accuracy: 0.1408\n",
            "Epoch 153/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9707 - accuracy: 0.2845\n",
            "Epoch 00153: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.9711 - accuracy: 0.2848 - val_loss: 3.9476 - val_accuracy: 0.1447\n",
            "Epoch 154/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9613 - accuracy: 0.2872\n",
            "Epoch 00154: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 2.9625 - accuracy: 0.2866 - val_loss: 3.9492 - val_accuracy: 0.1427\n",
            "Epoch 155/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9651 - accuracy: 0.2857\n",
            "Epoch 00155: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 2.9667 - accuracy: 0.2850 - val_loss: 3.9511 - val_accuracy: 0.1417\n",
            "Epoch 156/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9484 - accuracy: 0.2925\n",
            "Epoch 00156: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.9504 - accuracy: 0.2928 - val_loss: 3.9344 - val_accuracy: 0.1359\n",
            "Epoch 157/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9588 - accuracy: 0.2813\n",
            "Epoch 00157: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.9589 - accuracy: 0.2812 - val_loss: 3.9393 - val_accuracy: 0.1339\n",
            "Epoch 158/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9297 - accuracy: 0.2992\n",
            "Epoch 00158: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 2.9308 - accuracy: 0.2984 - val_loss: 3.9453 - val_accuracy: 0.1378\n",
            "Epoch 159/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9536 - accuracy: 0.2902\n",
            "Epoch 00159: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 121ms/step - loss: 2.9511 - accuracy: 0.2902 - val_loss: 3.9629 - val_accuracy: 0.1398\n",
            "Epoch 160/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9368 - accuracy: 0.2873\n",
            "Epoch 00160: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 2.9362 - accuracy: 0.2868 - val_loss: 3.9571 - val_accuracy: 0.1417\n",
            "Epoch 161/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9269 - accuracy: 0.2902\n",
            "Epoch 00161: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.9290 - accuracy: 0.2899 - val_loss: 3.9689 - val_accuracy: 0.1359\n",
            "Epoch 162/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9038 - accuracy: 0.3050\n",
            "Epoch 00162: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 116ms/step - loss: 2.9030 - accuracy: 0.3054 - val_loss: 3.9511 - val_accuracy: 0.1417\n",
            "Epoch 163/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.9015 - accuracy: 0.3043\n",
            "Epoch 00163: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 2.9018 - accuracy: 0.3046 - val_loss: 3.9602 - val_accuracy: 0.1369\n",
            "Epoch 164/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8823 - accuracy: 0.2995\n",
            "Epoch 00164: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.8783 - accuracy: 0.2997 - val_loss: 3.9717 - val_accuracy: 0.1496\n",
            "Epoch 165/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8785 - accuracy: 0.3027\n",
            "Epoch 00165: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.8784 - accuracy: 0.3025 - val_loss: 3.9771 - val_accuracy: 0.1447\n",
            "Epoch 166/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8797 - accuracy: 0.3022\n",
            "Epoch 00166: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.8825 - accuracy: 0.3016 - val_loss: 3.9662 - val_accuracy: 0.1466\n",
            "Epoch 167/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8781 - accuracy: 0.3035\n",
            "Epoch 00167: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 120ms/step - loss: 2.8819 - accuracy: 0.3029 - val_loss: 3.9631 - val_accuracy: 0.1447\n",
            "Epoch 168/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8617 - accuracy: 0.3078\n",
            "Epoch 00168: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 2.8623 - accuracy: 0.3082 - val_loss: 3.9702 - val_accuracy: 0.1476\n",
            "Epoch 169/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8684 - accuracy: 0.3034\n",
            "Epoch 00169: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 116ms/step - loss: 2.8696 - accuracy: 0.3029 - val_loss: 3.9654 - val_accuracy: 0.1378\n",
            "Epoch 170/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8530 - accuracy: 0.3081\n",
            "Epoch 00170: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 121ms/step - loss: 2.8521 - accuracy: 0.3080 - val_loss: 3.9768 - val_accuracy: 0.1349\n",
            "Epoch 171/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8794 - accuracy: 0.2970\n",
            "Epoch 00171: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.8782 - accuracy: 0.2965 - val_loss: 3.9957 - val_accuracy: 0.1378\n",
            "Epoch 172/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8600 - accuracy: 0.3143\n",
            "Epoch 00172: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 2.8592 - accuracy: 0.3145 - val_loss: 3.9842 - val_accuracy: 0.1417\n",
            "Epoch 173/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8591 - accuracy: 0.3122\n",
            "Epoch 00173: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 2.8572 - accuracy: 0.3126 - val_loss: 3.9830 - val_accuracy: 0.1437\n",
            "Epoch 174/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8373 - accuracy: 0.3114\n",
            "Epoch 00174: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 2.8359 - accuracy: 0.3115 - val_loss: 3.9943 - val_accuracy: 0.1378\n",
            "Epoch 175/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8412 - accuracy: 0.3085\n",
            "Epoch 00175: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 2.8412 - accuracy: 0.3088 - val_loss: 3.9839 - val_accuracy: 0.1349\n",
            "Epoch 176/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8299 - accuracy: 0.3130\n",
            "Epoch 00176: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 116ms/step - loss: 2.8312 - accuracy: 0.3124 - val_loss: 4.0102 - val_accuracy: 0.1339\n",
            "Epoch 177/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8229 - accuracy: 0.3121\n",
            "Epoch 00177: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 2.8238 - accuracy: 0.3119 - val_loss: 3.9871 - val_accuracy: 0.1408\n",
            "Epoch 178/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8146 - accuracy: 0.3186\n",
            "Epoch 00178: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 2.8120 - accuracy: 0.3191 - val_loss: 3.9834 - val_accuracy: 0.1349\n",
            "Epoch 179/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8182 - accuracy: 0.3159\n",
            "Epoch 00179: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 2.8201 - accuracy: 0.3161 - val_loss: 3.9763 - val_accuracy: 0.1417\n",
            "Epoch 180/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.8011 - accuracy: 0.3168\n",
            "Epoch 00180: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 116ms/step - loss: 2.8041 - accuracy: 0.3156 - val_loss: 3.9843 - val_accuracy: 0.1388\n",
            "Epoch 181/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7886 - accuracy: 0.3170\n",
            "Epoch 00181: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 122ms/step - loss: 2.7870 - accuracy: 0.3174 - val_loss: 3.9945 - val_accuracy: 0.1388\n",
            "Epoch 182/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7770 - accuracy: 0.3170\n",
            "Epoch 00182: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 2.7776 - accuracy: 0.3168 - val_loss: 3.9811 - val_accuracy: 0.1427\n",
            "Epoch 183/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7916 - accuracy: 0.3191\n",
            "Epoch 00183: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 116ms/step - loss: 2.7895 - accuracy: 0.3204 - val_loss: 3.9823 - val_accuracy: 0.1476\n",
            "Epoch 184/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7654 - accuracy: 0.3296\n",
            "Epoch 00184: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.7679 - accuracy: 0.3297 - val_loss: 4.0032 - val_accuracy: 0.1408\n",
            "Epoch 185/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7524 - accuracy: 0.3318\n",
            "Epoch 00185: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 119ms/step - loss: 2.7551 - accuracy: 0.3307 - val_loss: 4.0092 - val_accuracy: 0.1388\n",
            "Epoch 186/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7664 - accuracy: 0.3338\n",
            "Epoch 00186: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 2.7668 - accuracy: 0.3329 - val_loss: 4.0030 - val_accuracy: 0.1427\n",
            "Epoch 187/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7772 - accuracy: 0.3235\n",
            "Epoch 00187: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 2.7747 - accuracy: 0.3243 - val_loss: 4.0021 - val_accuracy: 0.1408\n",
            "Epoch 188/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7501 - accuracy: 0.3260\n",
            "Epoch 00188: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 121ms/step - loss: 2.7512 - accuracy: 0.3255 - val_loss: 4.0036 - val_accuracy: 0.1398\n",
            "Epoch 189/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7394 - accuracy: 0.3304\n",
            "Epoch 00189: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 2.7405 - accuracy: 0.3298 - val_loss: 4.0196 - val_accuracy: 0.1369\n",
            "Epoch 190/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7237 - accuracy: 0.3367\n",
            "Epoch 00190: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 2.7236 - accuracy: 0.3365 - val_loss: 4.0164 - val_accuracy: 0.1329\n",
            "Epoch 191/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7409 - accuracy: 0.3372\n",
            "Epoch 00191: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 116ms/step - loss: 2.7404 - accuracy: 0.3371 - val_loss: 4.0073 - val_accuracy: 0.1398\n",
            "Epoch 192/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7213 - accuracy: 0.3383\n",
            "Epoch 00192: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 2.7253 - accuracy: 0.3375 - val_loss: 4.0199 - val_accuracy: 0.1339\n",
            "Epoch 193/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7043 - accuracy: 0.3440\n",
            "Epoch 00193: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 120ms/step - loss: 2.7029 - accuracy: 0.3443 - val_loss: 4.0276 - val_accuracy: 0.1408\n",
            "Epoch 194/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7261 - accuracy: 0.3300\n",
            "Epoch 00194: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 2.7266 - accuracy: 0.3294 - val_loss: 4.0041 - val_accuracy: 0.1398\n",
            "Epoch 195/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7080 - accuracy: 0.3340\n",
            "Epoch 00195: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 123ms/step - loss: 2.7117 - accuracy: 0.3337 - val_loss: 4.0203 - val_accuracy: 0.1378\n",
            "Epoch 196/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.7027 - accuracy: 0.3376\n",
            "Epoch 00196: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 116ms/step - loss: 2.7027 - accuracy: 0.3368 - val_loss: 4.0113 - val_accuracy: 0.1378\n",
            "Epoch 197/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.6772 - accuracy: 0.3409\n",
            "Epoch 00197: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 2.6795 - accuracy: 0.3406 - val_loss: 4.0293 - val_accuracy: 0.1427\n",
            "Epoch 198/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.6859 - accuracy: 0.3419\n",
            "Epoch 00198: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 116ms/step - loss: 2.6846 - accuracy: 0.3430 - val_loss: 4.0362 - val_accuracy: 0.1408\n",
            "Epoch 199/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.6612 - accuracy: 0.3463\n",
            "Epoch 00199: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 8s 118ms/step - loss: 2.6632 - accuracy: 0.3465 - val_loss: 4.0261 - val_accuracy: 0.1398\n",
            "Epoch 200/200\n",
            "70/71 [============================>.] - ETA: 0s - loss: 2.6634 - accuracy: 0.3465\n",
            "Epoch 00200: val_accuracy did not improve from 0.14956\n",
            "71/71 [==============================] - 9s 121ms/step - loss: 2.6644 - accuracy: 0.3465 - val_loss: 4.0063 - val_accuracy: 0.1339\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERHR1p8Nbs+zNj9bqAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVui_BlsWvbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAaEpg2TdMfB",
        "colab_type": "text"
      },
      "source": [
        "### So far we have looked at only 64x64 images. Let us see if the accuarcy imporves with 224x224 (default for VGG16) size images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIWBSoQYWvZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model224= VGG16(weights=(project_path+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
        "                 include_top=False, pooling='avg', input_shape = (224,224,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayrEdzZ6WvUW",
        "colab_type": "code",
        "outputId": "13d231ab-94df-4a93-b7de-494fad183247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "base_model224.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s7ycvT-WvSn",
        "colab_type": "code",
        "outputId": "49d9b3b5-f1c1-4d28-9514-9557a1644444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "new_model224 = tf.keras.models.Sequential()\n",
        "new_model224.add(base_model224)\n",
        "new_model224.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WtdMiHeWvPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add Dense Layers after flattening the data\n",
        "new_model224.add(tf.keras.layers.Flatten())\n",
        "new_model224.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "new_model224.add(tf.keras.layers.Dropout(0.5))\n",
        "new_model224.add(tf.keras.layers.BatchNormalization())\n",
        "#new_model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "#new_model.add(tf.keras.layers.BatchNormalization())\n",
        "#new_model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "#new_model.add(tf.keras.layers.BatchNormalization())\n",
        "new_model224.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "new_model224.add(tf.keras.layers.Dropout(0.5))\n",
        "new_model224.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Output Layer\n",
        "new_model224.add(tf.keras.layers.Dense(120, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHFzR5kDNHjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR9NHd6PWvMX",
        "colab_type": "code",
        "outputId": "6f313541-71c5-4c42-922e-b03e504fc680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "for layer in new_model224.layers[:1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "for layer in new_model224.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.training.Model object at 0x7f9be0223eb8> False\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7f9be019f8d0> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9be019f908> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9be019fda0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f9be019fd68> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9be019a128> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7f9be0143ef0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f9be00f9d68> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7f9be00f9c88> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N9Ti_tfWvKW",
        "colab_type": "code",
        "outputId": "b0decc97-d93a-44d1-f4aa-0c96c9a3fcf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "new_model224.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 15,538,360\n",
            "Trainable params: 821,112\n",
            "Non-trainable params: 14,717,248\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFE8aKiDdZ0n",
        "colab_type": "text"
      },
      "source": [
        "### **Loading the best model from a previous attempt (Colab keeps getting disconnected)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGBxvhHyNJPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load a saved model\n",
        "from tensorflow.keras.models import load_model\n",
        "new_model224 = load_model('first_model224.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgO-M180WvG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "adm = optimizers.Adam(lr = 0.0001)\n",
        "new_model224.compile(optimizer=adm, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CMNIW5cWu-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model_checkpoint=tf.keras.callbacks.ModelCheckpoint('first_model224.h5', \n",
        "                                                    save_best_only=True, \n",
        "                                                    monitor='val_accuracy', \n",
        "                                                    mode='max', \n",
        "                                                    verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9MFgJ-WWu0s",
        "colab_type": "code",
        "outputId": "e3d8877a-b25b-422b-fb68-42d8892a8d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = new_model224.fit_generator(datagen.flow(X_train, Y_train,batch_size = 128),\n",
        "          validation_data = (X_val, Y_val),\n",
        "          steps_per_epoch=len(X_train) // 128,\n",
        "                    epochs=100, initial_epoch = 55,\n",
        "               callbacks = [model_checkpoint]\n",
        "                    \n",
        "                    )\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 71 steps, validate on 1023 samples\n",
            "Epoch 56/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.8971 - accuracy: 0.2751\n",
            "Epoch 00056: val_accuracy improved from -inf to 0.45846, saving model to first_model224.h5\n",
            "71/71 [==============================] - 126s 2s/step - loss: 2.8947 - accuracy: 0.2755 - val_loss: 2.3390 - val_accuracy: 0.4585\n",
            "Epoch 57/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.8761 - accuracy: 0.2811\n",
            "Epoch 00057: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.8747 - accuracy: 0.2820 - val_loss: 2.3405 - val_accuracy: 0.4428\n",
            "Epoch 58/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.8594 - accuracy: 0.2841\n",
            "Epoch 00058: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 109s 2s/step - loss: 2.8612 - accuracy: 0.2833 - val_loss: 2.3266 - val_accuracy: 0.4477\n",
            "Epoch 59/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.8437 - accuracy: 0.2894\n",
            "Epoch 00059: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 110s 2s/step - loss: 2.8421 - accuracy: 0.2894 - val_loss: 2.2965 - val_accuracy: 0.4516\n",
            "Epoch 60/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.8199 - accuracy: 0.2872\n",
            "Epoch 00060: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 109s 2s/step - loss: 2.8232 - accuracy: 0.2867 - val_loss: 2.2991 - val_accuracy: 0.4516\n",
            "Epoch 61/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.7955 - accuracy: 0.2986\n",
            "Epoch 00061: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 109s 2s/step - loss: 2.7982 - accuracy: 0.2981 - val_loss: 2.3107 - val_accuracy: 0.4457\n",
            "Epoch 62/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.7792 - accuracy: 0.2967\n",
            "Epoch 00062: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 108s 2s/step - loss: 2.7788 - accuracy: 0.2974 - val_loss: 2.3022 - val_accuracy: 0.4506\n",
            "Epoch 63/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.7785 - accuracy: 0.2988\n",
            "Epoch 00063: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.7759 - accuracy: 0.2990 - val_loss: 2.3032 - val_accuracy: 0.4428\n",
            "Epoch 64/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.7373 - accuracy: 0.3053\n",
            "Epoch 00064: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 111s 2s/step - loss: 2.7370 - accuracy: 0.3051 - val_loss: 2.2987 - val_accuracy: 0.4291\n",
            "Epoch 65/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.7273 - accuracy: 0.3094\n",
            "Epoch 00065: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 110s 2s/step - loss: 2.7281 - accuracy: 0.3097 - val_loss: 2.2884 - val_accuracy: 0.4457\n",
            "Epoch 66/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.7192 - accuracy: 0.3116\n",
            "Epoch 00066: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.7211 - accuracy: 0.3112 - val_loss: 2.2735 - val_accuracy: 0.4467\n",
            "Epoch 67/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.6858 - accuracy: 0.3175\n",
            "Epoch 00067: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 108s 2s/step - loss: 2.6850 - accuracy: 0.3178 - val_loss: 2.2998 - val_accuracy: 0.4203\n",
            "Epoch 68/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.6940 - accuracy: 0.3141\n",
            "Epoch 00068: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.6968 - accuracy: 0.3131 - val_loss: 2.2651 - val_accuracy: 0.4370\n",
            "Epoch 69/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.6580 - accuracy: 0.3235\n",
            "Epoch 00069: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.6584 - accuracy: 0.3236 - val_loss: 2.2676 - val_accuracy: 0.4399\n",
            "Epoch 70/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.6515 - accuracy: 0.3232\n",
            "Epoch 00070: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.6546 - accuracy: 0.3226 - val_loss: 2.2831 - val_accuracy: 0.4321\n",
            "Epoch 71/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.6433 - accuracy: 0.3310\n",
            "Epoch 00071: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 108s 2s/step - loss: 2.6438 - accuracy: 0.3311 - val_loss: 2.2485 - val_accuracy: 0.4233\n",
            "Epoch 72/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.6259 - accuracy: 0.3312\n",
            "Epoch 00072: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 108s 2s/step - loss: 2.6273 - accuracy: 0.3305 - val_loss: 2.2652 - val_accuracy: 0.4360\n",
            "Epoch 73/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.6047 - accuracy: 0.3343\n",
            "Epoch 00073: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 108s 2s/step - loss: 2.6094 - accuracy: 0.3333 - val_loss: 2.2375 - val_accuracy: 0.4311\n",
            "Epoch 74/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.5888 - accuracy: 0.3407\n",
            "Epoch 00074: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.5893 - accuracy: 0.3406 - val_loss: 2.2436 - val_accuracy: 0.4301\n",
            "Epoch 75/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.5680 - accuracy: 0.3375\n",
            "Epoch 00075: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.5682 - accuracy: 0.3374 - val_loss: 2.2684 - val_accuracy: 0.4360\n",
            "Epoch 76/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.5676 - accuracy: 0.3497\n",
            "Epoch 00076: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.5660 - accuracy: 0.3501 - val_loss: 2.2530 - val_accuracy: 0.4370\n",
            "Epoch 77/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.5617 - accuracy: 0.3395\n",
            "Epoch 00077: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.5636 - accuracy: 0.3391 - val_loss: 2.2412 - val_accuracy: 0.4389\n",
            "Epoch 78/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.5338 - accuracy: 0.3482\n",
            "Epoch 00078: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 109s 2s/step - loss: 2.5326 - accuracy: 0.3477 - val_loss: 2.2532 - val_accuracy: 0.4174\n",
            "Epoch 79/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.5325 - accuracy: 0.3547\n",
            "Epoch 00079: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.5353 - accuracy: 0.3537 - val_loss: 2.2288 - val_accuracy: 0.4321\n",
            "Epoch 80/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.5005 - accuracy: 0.3552\n",
            "Epoch 00080: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.4980 - accuracy: 0.3563 - val_loss: 2.2475 - val_accuracy: 0.4223\n",
            "Epoch 81/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.4960 - accuracy: 0.3631\n",
            "Epoch 00081: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.4978 - accuracy: 0.3621 - val_loss: 2.2059 - val_accuracy: 0.4457\n",
            "Epoch 82/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.4805 - accuracy: 0.3646\n",
            "Epoch 00082: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.4797 - accuracy: 0.3640 - val_loss: 2.2330 - val_accuracy: 0.4311\n",
            "Epoch 83/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.4751 - accuracy: 0.3608\n",
            "Epoch 00083: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 108s 2s/step - loss: 2.4796 - accuracy: 0.3598 - val_loss: 2.2034 - val_accuracy: 0.4409\n",
            "Epoch 84/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.4680 - accuracy: 0.3621\n",
            "Epoch 00084: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.4662 - accuracy: 0.3631 - val_loss: 2.2011 - val_accuracy: 0.4340\n",
            "Epoch 85/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.4499 - accuracy: 0.3700\n",
            "Epoch 00085: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 104s 1s/step - loss: 2.4477 - accuracy: 0.3707 - val_loss: 2.2076 - val_accuracy: 0.4399\n",
            "Epoch 86/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.4453 - accuracy: 0.3693\n",
            "Epoch 00086: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.4461 - accuracy: 0.3691 - val_loss: 2.2041 - val_accuracy: 0.4379\n",
            "Epoch 87/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.4260 - accuracy: 0.3681\n",
            "Epoch 00087: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 105s 1s/step - loss: 2.4253 - accuracy: 0.3688 - val_loss: 2.2087 - val_accuracy: 0.4477\n",
            "Epoch 88/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.4128 - accuracy: 0.3757\n",
            "Epoch 00088: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.4147 - accuracy: 0.3745 - val_loss: 2.1857 - val_accuracy: 0.4428\n",
            "Epoch 89/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.4054 - accuracy: 0.3743\n",
            "Epoch 00089: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.4020 - accuracy: 0.3746 - val_loss: 2.1916 - val_accuracy: 0.4340\n",
            "Epoch 90/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.3930 - accuracy: 0.3803\n",
            "Epoch 00090: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.3929 - accuracy: 0.3799 - val_loss: 2.2092 - val_accuracy: 0.4330\n",
            "Epoch 91/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.3774 - accuracy: 0.3779\n",
            "Epoch 00091: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 105s 1s/step - loss: 2.3752 - accuracy: 0.3785 - val_loss: 2.1815 - val_accuracy: 0.4370\n",
            "Epoch 92/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.3509 - accuracy: 0.3886\n",
            "Epoch 00092: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 105s 1s/step - loss: 2.3518 - accuracy: 0.3884 - val_loss: 2.2104 - val_accuracy: 0.4252\n",
            "Epoch 93/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.3400 - accuracy: 0.3904\n",
            "Epoch 00093: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 105s 1s/step - loss: 2.3436 - accuracy: 0.3897 - val_loss: 2.1772 - val_accuracy: 0.4340\n",
            "Epoch 94/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.3387 - accuracy: 0.3877\n",
            "Epoch 00094: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 108s 2s/step - loss: 2.3460 - accuracy: 0.3862 - val_loss: 2.1985 - val_accuracy: 0.4350\n",
            "Epoch 95/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.3080 - accuracy: 0.3974\n",
            "Epoch 00095: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.3122 - accuracy: 0.3968 - val_loss: 2.1804 - val_accuracy: 0.4409\n",
            "Epoch 96/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.3170 - accuracy: 0.3970\n",
            "Epoch 00096: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.3178 - accuracy: 0.3974 - val_loss: 2.1786 - val_accuracy: 0.4330\n",
            "Epoch 97/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.3158 - accuracy: 0.3932\n",
            "Epoch 00097: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 107s 2s/step - loss: 2.3132 - accuracy: 0.3940 - val_loss: 2.1640 - val_accuracy: 0.4350\n",
            "Epoch 98/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.3096 - accuracy: 0.3974\n",
            "Epoch 00098: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 108s 2s/step - loss: 2.3098 - accuracy: 0.3976 - val_loss: 2.1760 - val_accuracy: 0.4389\n",
            "Epoch 99/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.2934 - accuracy: 0.3996\n",
            "Epoch 00099: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.2941 - accuracy: 0.3987 - val_loss: 2.1719 - val_accuracy: 0.4487\n",
            "Epoch 100/100\n",
            "70/71 [============================>.] - ETA: 1s - loss: 2.2709 - accuracy: 0.4087\n",
            "Epoch 00100: val_accuracy did not improve from 0.45846\n",
            "71/71 [==============================] - 106s 1s/step - loss: 2.2722 - accuracy: 0.4087 - val_loss: 2.1838 - val_accuracy: 0.4330\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOCIiopYUjoiIqOU/1zPjdltZdNoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPvJz8sZ4FOsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IEibDgZetON",
        "colab_type": "text"
      },
      "source": [
        "# **SUMMARY OF ALL RUNS WITH VGG16**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_rEkGOraRdZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Best results are with 224x224 so the summary is provided for that \n",
        "\n",
        "The trails conducted for different architechtures and hyper-parameters are as follows:\n",
        "*   VGG16 with 1024 + 256 + 120 with softmax, learning rate = 10^-4, adam optimiser --> 45.8% validation accuracy 41% training accuracy **(BEST)**\n",
        "*   VGG16 with 2048 + 1024 + 120 with softmax, learning rate = 10^-4, adam optimiser --> 26.4% validation accuracy 78% training accuracy (overfit)\n",
        "\n",
        "\n",
        "*   VGG16 with 1024 + 120 with softmax, learning rate = 10^-4, adam optimiser --> 36.1% validation accuracy 65% training accuracy (overfit)\n",
        "*   VGG16 with 1024 + 1024 + 120 with softmax, learning rate = 10^-3, adam optimiser --> 15.4% validation accuracy 99% training accuracy (overfit)\n",
        "\n",
        "\n",
        "*   VGG16 with 1024 + 1024 + 120 with softmax, learning rate = 10^-4, adam optimiser with no horizontal flip --> 39% validation accuracy 42% training accuracy \n",
        "*   VGG16 with 1024 + 1024 + 120 with sigmoid, learning rate = 10^-4 with 0.99 momentum and nesterov = True, SGD optimiser --> 31% validation accuracy 89% training accuracy (overfit)\n",
        "\n",
        "\n",
        "**Based on the above trial with VGG16 the submission file (sub.csv) is written for VGG16 with 1024 + 256 + 120 with softmax, learning rate = 10^-4, adam optimiser --> 45.8% validation accuracy 41% training accuracy (BEST)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEH_aHAsaNVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thqr4WLlcIBe",
        "colab_type": "text"
      },
      "source": [
        "# CREATION OF SUBMISSION FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHrVwME4Xfpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "bf72560e-b089-4f11-ff85-39f2010c9995"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>affenpinscher</th>\n",
              "      <th>afghan_hound</th>\n",
              "      <th>african_hunting_dog</th>\n",
              "      <th>airedale</th>\n",
              "      <th>american_staffordshire_terrier</th>\n",
              "      <th>appenzeller</th>\n",
              "      <th>australian_terrier</th>\n",
              "      <th>basenji</th>\n",
              "      <th>basset</th>\n",
              "      <th>beagle</th>\n",
              "      <th>bedlington_terrier</th>\n",
              "      <th>bernese_mountain_dog</th>\n",
              "      <th>black-and-tan_coonhound</th>\n",
              "      <th>blenheim_spaniel</th>\n",
              "      <th>bloodhound</th>\n",
              "      <th>bluetick</th>\n",
              "      <th>border_collie</th>\n",
              "      <th>border_terrier</th>\n",
              "      <th>borzoi</th>\n",
              "      <th>boston_bull</th>\n",
              "      <th>bouvier_des_flandres</th>\n",
              "      <th>boxer</th>\n",
              "      <th>brabancon_griffon</th>\n",
              "      <th>briard</th>\n",
              "      <th>brittany_spaniel</th>\n",
              "      <th>bull_mastiff</th>\n",
              "      <th>cairn</th>\n",
              "      <th>cardigan</th>\n",
              "      <th>chesapeake_bay_retriever</th>\n",
              "      <th>chihuahua</th>\n",
              "      <th>chow</th>\n",
              "      <th>clumber</th>\n",
              "      <th>cocker_spaniel</th>\n",
              "      <th>collie</th>\n",
              "      <th>curly-coated_retriever</th>\n",
              "      <th>dandie_dinmont</th>\n",
              "      <th>dhole</th>\n",
              "      <th>dingo</th>\n",
              "      <th>doberman</th>\n",
              "      <th>english_foxhound</th>\n",
              "      <th>...</th>\n",
              "      <th>norwegian_elkhound</th>\n",
              "      <th>norwich_terrier</th>\n",
              "      <th>old_english_sheepdog</th>\n",
              "      <th>otterhound</th>\n",
              "      <th>papillon</th>\n",
              "      <th>pekinese</th>\n",
              "      <th>pembroke</th>\n",
              "      <th>pomeranian</th>\n",
              "      <th>pug</th>\n",
              "      <th>redbone</th>\n",
              "      <th>rhodesian_ridgeback</th>\n",
              "      <th>rottweiler</th>\n",
              "      <th>saint_bernard</th>\n",
              "      <th>saluki</th>\n",
              "      <th>samoyed</th>\n",
              "      <th>schipperke</th>\n",
              "      <th>scotch_terrier</th>\n",
              "      <th>scottish_deerhound</th>\n",
              "      <th>sealyham_terrier</th>\n",
              "      <th>shetland_sheepdog</th>\n",
              "      <th>shih-tzu</th>\n",
              "      <th>siberian_husky</th>\n",
              "      <th>silky_terrier</th>\n",
              "      <th>soft-coated_wheaten_terrier</th>\n",
              "      <th>staffordshire_bullterrier</th>\n",
              "      <th>standard_poodle</th>\n",
              "      <th>standard_schnauzer</th>\n",
              "      <th>sussex_spaniel</th>\n",
              "      <th>tibetan_mastiff</th>\n",
              "      <th>tibetan_terrier</th>\n",
              "      <th>toy_poodle</th>\n",
              "      <th>toy_terrier</th>\n",
              "      <th>vizsla</th>\n",
              "      <th>walker_hound</th>\n",
              "      <th>weimaraner</th>\n",
              "      <th>welsh_springer_spaniel</th>\n",
              "      <th>west_highland_white_terrier</th>\n",
              "      <th>whippet</th>\n",
              "      <th>wire-haired_fox_terrier</th>\n",
              "      <th>yorkshire_terrier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10352</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10353</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10354</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10355</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10356</th>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10357 rows × 120 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       affenpinscher  afghan_hound  ...  wire-haired_fox_terrier  yorkshire_terrier\n",
              "0           0.008333      0.008333  ...                 0.008333           0.008333\n",
              "1           0.008333      0.008333  ...                 0.008333           0.008333\n",
              "2           0.008333      0.008333  ...                 0.008333           0.008333\n",
              "3           0.008333      0.008333  ...                 0.008333           0.008333\n",
              "4           0.008333      0.008333  ...                 0.008333           0.008333\n",
              "...              ...           ...  ...                      ...                ...\n",
              "10352       0.008333      0.008333  ...                 0.008333           0.008333\n",
              "10353       0.008333      0.008333  ...                 0.008333           0.008333\n",
              "10354       0.008333      0.008333  ...                 0.008333           0.008333\n",
              "10355       0.008333      0.008333  ...                 0.008333           0.008333\n",
              "10356       0.008333      0.008333  ...                 0.008333           0.008333\n",
              "\n",
              "[10357 rows x 120 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqRWXY3d36Uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = new_model224.predict(x_test_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2L67qgQ36SZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "624aee03-32b1-439b-918b-b6e3452fb9ea"
      },
      "source": [
        "predicted_classes = np.argmax(pred, axis = -1)\n",
        "predicted_classes\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([115,  94,  40, ...,  69, 109,  97])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVZD2h5y36P7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5612f8c3-d00f-4a26-83d4-d73f79a2a568"
      },
      "source": [
        "predictions = []\n",
        "for classes in predicted_classes:\n",
        "  predictions.append(y_test.columns[classes])\n",
        "\n",
        "predictions"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['welsh_springer_spaniel',\n",
              " 'samoyed',\n",
              " 'english_setter',\n",
              " 'afghan_hound',\n",
              " 'tibetan_terrier',\n",
              " 'chow',\n",
              " 'australian_terrier',\n",
              " 'pomeranian',\n",
              " 'scottish_deerhound',\n",
              " 'sussex_spaniel',\n",
              " 'tibetan_terrier',\n",
              " 'sealyham_terrier',\n",
              " 'irish_water_spaniel',\n",
              " 'dingo',\n",
              " 'bloodhound',\n",
              " 'leonberg',\n",
              " 'basenji',\n",
              " 'afghan_hound',\n",
              " 'irish_terrier',\n",
              " 'golden_retriever',\n",
              " 'irish_wolfhound',\n",
              " 'eskimo_dog',\n",
              " 'mexican_hairless',\n",
              " 'labrador_retriever',\n",
              " 'irish_setter',\n",
              " 'dhole',\n",
              " 'beagle',\n",
              " 'whippet',\n",
              " 'english_setter',\n",
              " 'kerry_blue_terrier',\n",
              " 'scotch_terrier',\n",
              " 'norwegian_elkhound',\n",
              " 'clumber',\n",
              " 'toy_terrier',\n",
              " 'saluki',\n",
              " 'japanese_spaniel',\n",
              " 'japanese_spaniel',\n",
              " 'yorkshire_terrier',\n",
              " 'english_springer',\n",
              " 'german_short-haired_pointer',\n",
              " 'bedlington_terrier',\n",
              " 'scottish_deerhound',\n",
              " 'brabancon_griffon',\n",
              " 'airedale',\n",
              " 'border_collie',\n",
              " 'bernese_mountain_dog',\n",
              " 'welsh_springer_spaniel',\n",
              " 'papillon',\n",
              " 'toy_terrier',\n",
              " 'clumber',\n",
              " 'beagle',\n",
              " 'silky_terrier',\n",
              " 'malamute',\n",
              " 'blenheim_spaniel',\n",
              " 'weimaraner',\n",
              " 'mexican_hairless',\n",
              " 'weimaraner',\n",
              " 'black-and-tan_coonhound',\n",
              " 'irish_terrier',\n",
              " 'saluki',\n",
              " 'basenji',\n",
              " 'norwegian_elkhound',\n",
              " 'irish_terrier',\n",
              " 'bluetick',\n",
              " 'pembroke',\n",
              " 'french_bulldog',\n",
              " 'eskimo_dog',\n",
              " 'weimaraner',\n",
              " 'soft-coated_wheaten_terrier',\n",
              " 'norwegian_elkhound',\n",
              " 'affenpinscher',\n",
              " 'great_pyrenees',\n",
              " 'beagle',\n",
              " 'blenheim_spaniel',\n",
              " 'lakeland_terrier',\n",
              " 'entlebucher',\n",
              " 'staffordshire_bullterrier',\n",
              " 'bedlington_terrier',\n",
              " 'irish_setter',\n",
              " 'beagle',\n",
              " 'ibizan_hound',\n",
              " 'silky_terrier',\n",
              " 'african_hunting_dog',\n",
              " 'scottish_deerhound',\n",
              " 'weimaraner',\n",
              " 'chesapeake_bay_retriever',\n",
              " 'brabancon_griffon',\n",
              " 'african_hunting_dog',\n",
              " 'ibizan_hound',\n",
              " 'irish_wolfhound',\n",
              " 'labrador_retriever',\n",
              " 'norwich_terrier',\n",
              " 'pug',\n",
              " 'sussex_spaniel',\n",
              " 'rottweiler',\n",
              " 'pug',\n",
              " 'mexican_hairless',\n",
              " 'irish_water_spaniel',\n",
              " 'african_hunting_dog',\n",
              " 'border_terrier',\n",
              " 'otterhound',\n",
              " 'bull_mastiff',\n",
              " 'lakeland_terrier',\n",
              " 'mexican_hairless',\n",
              " 'miniature_pinscher',\n",
              " 'pembroke',\n",
              " 'french_bulldog',\n",
              " 'tibetan_terrier',\n",
              " 'irish_wolfhound',\n",
              " 'silky_terrier',\n",
              " 'ibizan_hound',\n",
              " 'border_collie',\n",
              " 'bernese_mountain_dog',\n",
              " 'dingo',\n",
              " 'basset',\n",
              " 'saint_bernard',\n",
              " 'dhole',\n",
              " 'standard_poodle',\n",
              " 'standard_poodle',\n",
              " 'italian_greyhound',\n",
              " 'pug',\n",
              " 'irish_setter',\n",
              " 'bloodhound',\n",
              " 'shih-tzu',\n",
              " 'bluetick',\n",
              " 'bull_mastiff',\n",
              " 'rhodesian_ridgeback',\n",
              " 'boston_bull',\n",
              " 'borzoi',\n",
              " 'irish_wolfhound',\n",
              " 'shih-tzu',\n",
              " 'samoyed',\n",
              " 'samoyed',\n",
              " 'whippet',\n",
              " 'keeshond',\n",
              " 'irish_wolfhound',\n",
              " 'basenji',\n",
              " 'irish_water_spaniel',\n",
              " 'clumber',\n",
              " 'saluki',\n",
              " 'maltese_dog',\n",
              " 'dhole',\n",
              " 'japanese_spaniel',\n",
              " 'italian_greyhound',\n",
              " 'miniature_poodle',\n",
              " 'chesapeake_bay_retriever',\n",
              " 'scottish_deerhound',\n",
              " 'dhole',\n",
              " 'sealyham_terrier',\n",
              " 'boxer',\n",
              " 'scottish_deerhound',\n",
              " 'bluetick',\n",
              " 'norwegian_elkhound',\n",
              " 'yorkshire_terrier',\n",
              " 'pug',\n",
              " 'brabancon_griffon',\n",
              " 'yorkshire_terrier',\n",
              " 'irish_water_spaniel',\n",
              " 'australian_terrier',\n",
              " 'samoyed',\n",
              " 'yorkshire_terrier',\n",
              " 'afghan_hound',\n",
              " 'samoyed',\n",
              " 'afghan_hound',\n",
              " 'kerry_blue_terrier',\n",
              " 'walker_hound',\n",
              " 'saluki',\n",
              " 'norwegian_elkhound',\n",
              " 'japanese_spaniel',\n",
              " 'great_pyrenees',\n",
              " 'gordon_setter',\n",
              " 'great_dane',\n",
              " 'bluetick',\n",
              " 'beagle',\n",
              " 'siberian_husky',\n",
              " 'redbone',\n",
              " 'dingo',\n",
              " 'old_english_sheepdog',\n",
              " 'great_dane',\n",
              " 'japanese_spaniel',\n",
              " 'walker_hound',\n",
              " 'kerry_blue_terrier',\n",
              " 'sealyham_terrier',\n",
              " 'basenji',\n",
              " 'siberian_husky',\n",
              " 'lhasa',\n",
              " 'airedale',\n",
              " 'english_springer',\n",
              " 'german_short-haired_pointer',\n",
              " 'irish_wolfhound',\n",
              " 'gordon_setter',\n",
              " 'papillon',\n",
              " 'dhole',\n",
              " 'bernese_mountain_dog',\n",
              " 'chow',\n",
              " 'bluetick',\n",
              " 'komondor',\n",
              " 'ibizan_hound',\n",
              " 'whippet',\n",
              " 'komondor',\n",
              " 'welsh_springer_spaniel',\n",
              " 'sealyham_terrier',\n",
              " 'leonberg',\n",
              " 'african_hunting_dog',\n",
              " 'doberman',\n",
              " 'beagle',\n",
              " 'malamute',\n",
              " 'chow',\n",
              " 'whippet',\n",
              " 'golden_retriever',\n",
              " 'scottish_deerhound',\n",
              " 'redbone',\n",
              " 'english_foxhound',\n",
              " 'bernese_mountain_dog',\n",
              " 'pug',\n",
              " 'afghan_hound',\n",
              " 'bluetick',\n",
              " 'samoyed',\n",
              " 'scottish_deerhound',\n",
              " 'norwegian_elkhound',\n",
              " 'border_terrier',\n",
              " 'bloodhound',\n",
              " 'blenheim_spaniel',\n",
              " 'irish_terrier',\n",
              " 'border_terrier',\n",
              " 'irish_wolfhound',\n",
              " 'chow',\n",
              " 'airedale',\n",
              " 'malamute',\n",
              " 'australian_terrier',\n",
              " 'boston_bull',\n",
              " 'entlebucher',\n",
              " 'sussex_spaniel',\n",
              " 'beagle',\n",
              " 'miniature_pinscher',\n",
              " 'bernese_mountain_dog',\n",
              " 'great_dane',\n",
              " 'scotch_terrier',\n",
              " 'shetland_sheepdog',\n",
              " 'boxer',\n",
              " 'sussex_spaniel',\n",
              " 'pug',\n",
              " 'scottish_deerhound',\n",
              " 'german_short-haired_pointer',\n",
              " 'japanese_spaniel',\n",
              " 'chow',\n",
              " 'leonberg',\n",
              " 'african_hunting_dog',\n",
              " 'pug',\n",
              " 'norfolk_terrier',\n",
              " 'great_dane',\n",
              " 'airedale',\n",
              " 'weimaraner',\n",
              " 'siberian_husky',\n",
              " 'toy_terrier',\n",
              " 'african_hunting_dog',\n",
              " 'komondor',\n",
              " 'scottish_deerhound',\n",
              " 'irish_water_spaniel',\n",
              " 'miniature_pinscher',\n",
              " 'chihuahua',\n",
              " 'dandie_dinmont',\n",
              " 'brabancon_griffon',\n",
              " 'kuvasz',\n",
              " 'rhodesian_ridgeback',\n",
              " 'english_setter',\n",
              " 'great_pyrenees',\n",
              " 'airedale',\n",
              " 'standard_poodle',\n",
              " 'boston_bull',\n",
              " 'dandie_dinmont',\n",
              " 'entlebucher',\n",
              " 'dhole',\n",
              " 'irish_terrier',\n",
              " 'pug',\n",
              " 'saluki',\n",
              " 'weimaraner',\n",
              " 'border_terrier',\n",
              " 'irish_water_spaniel',\n",
              " 'siberian_husky',\n",
              " 'old_english_sheepdog',\n",
              " 'border_terrier',\n",
              " 'vizsla',\n",
              " 'standard_schnauzer',\n",
              " 'gordon_setter',\n",
              " 'leonberg',\n",
              " 'golden_retriever',\n",
              " 'german_short-haired_pointer',\n",
              " 'whippet',\n",
              " 'great_pyrenees',\n",
              " 'miniature_schnauzer',\n",
              " 'samoyed',\n",
              " 'welsh_springer_spaniel',\n",
              " 'walker_hound',\n",
              " 'rottweiler',\n",
              " 'saint_bernard',\n",
              " 'dhole',\n",
              " 'basenji',\n",
              " 'siberian_husky',\n",
              " 'miniature_poodle',\n",
              " 'staffordshire_bullterrier',\n",
              " 'norwegian_elkhound',\n",
              " 'bedlington_terrier',\n",
              " 'japanese_spaniel',\n",
              " 'afghan_hound',\n",
              " 'chow',\n",
              " 'flat-coated_retriever',\n",
              " 'west_highland_white_terrier',\n",
              " 'shih-tzu',\n",
              " 'bloodhound',\n",
              " 'bloodhound',\n",
              " 'pug',\n",
              " 'cairn',\n",
              " 'borzoi',\n",
              " 'bernese_mountain_dog',\n",
              " 'tibetan_terrier',\n",
              " 'standard_poodle',\n",
              " 'bloodhound',\n",
              " 'african_hunting_dog',\n",
              " 'old_english_sheepdog',\n",
              " 'pomeranian',\n",
              " 'affenpinscher',\n",
              " 'black-and-tan_coonhound',\n",
              " 'rottweiler',\n",
              " 'irish_water_spaniel',\n",
              " 'boston_bull',\n",
              " 'blenheim_spaniel',\n",
              " 'affenpinscher',\n",
              " 'bluetick',\n",
              " 'lakeland_terrier',\n",
              " 'afghan_hound',\n",
              " 'newfoundland',\n",
              " 'west_highland_white_terrier',\n",
              " 'toy_terrier',\n",
              " 'bloodhound',\n",
              " 'airedale',\n",
              " 'lakeland_terrier',\n",
              " 'bouvier_des_flandres',\n",
              " 'dingo',\n",
              " 'tibetan_terrier',\n",
              " 'english_springer',\n",
              " 'irish_water_spaniel',\n",
              " 'boston_bull',\n",
              " 'toy_poodle',\n",
              " 'pug',\n",
              " 'norwegian_elkhound',\n",
              " 'german_shepherd',\n",
              " 'weimaraner',\n",
              " 'english_setter',\n",
              " 'miniature_schnauzer',\n",
              " 'cairn',\n",
              " 'italian_greyhound',\n",
              " 'komondor',\n",
              " 'tibetan_terrier',\n",
              " 'miniature_poodle',\n",
              " 'border_terrier',\n",
              " 'otterhound',\n",
              " 'irish_terrier',\n",
              " 'great_dane',\n",
              " 'black-and-tan_coonhound',\n",
              " 'leonberg',\n",
              " 'kuvasz',\n",
              " 'african_hunting_dog',\n",
              " 'affenpinscher',\n",
              " 'bernese_mountain_dog',\n",
              " 'labrador_retriever',\n",
              " 'labrador_retriever',\n",
              " 'pug',\n",
              " 'boxer',\n",
              " 'irish_water_spaniel',\n",
              " 'entlebucher',\n",
              " 'australian_terrier',\n",
              " 'pug',\n",
              " 'german_shepherd',\n",
              " 'pomeranian',\n",
              " 'dingo',\n",
              " 'norwegian_elkhound',\n",
              " 'bedlington_terrier',\n",
              " 'japanese_spaniel',\n",
              " 'shih-tzu',\n",
              " 'malamute',\n",
              " 'rottweiler',\n",
              " 'entlebucher',\n",
              " 'scottish_deerhound',\n",
              " 'norwich_terrier',\n",
              " 'boxer',\n",
              " 'pug',\n",
              " 'keeshond',\n",
              " 'miniature_pinscher',\n",
              " 'kelpie',\n",
              " 'collie',\n",
              " 'norwegian_elkhound',\n",
              " 'rhodesian_ridgeback',\n",
              " 'chow',\n",
              " 'saint_bernard',\n",
              " 'miniature_pinscher',\n",
              " 'afghan_hound',\n",
              " 'otterhound',\n",
              " 'miniature_poodle',\n",
              " 'miniature_schnauzer',\n",
              " 'scottish_deerhound',\n",
              " 'pug',\n",
              " 'tibetan_mastiff',\n",
              " 'rhodesian_ridgeback',\n",
              " 'affenpinscher',\n",
              " 'golden_retriever',\n",
              " 'miniature_pinscher',\n",
              " 'australian_terrier',\n",
              " 'afghan_hound',\n",
              " 'dhole',\n",
              " 'blenheim_spaniel',\n",
              " 'basenji',\n",
              " 'shih-tzu',\n",
              " 'scottish_deerhound',\n",
              " 'whippet',\n",
              " 'whippet',\n",
              " 'yorkshire_terrier',\n",
              " 'rhodesian_ridgeback',\n",
              " 'brabancon_griffon',\n",
              " 'american_staffordshire_terrier',\n",
              " 'basset',\n",
              " 'rottweiler',\n",
              " 'airedale',\n",
              " 'black-and-tan_coonhound',\n",
              " 'rottweiler',\n",
              " 'cairn',\n",
              " 'leonberg',\n",
              " 'miniature_pinscher',\n",
              " 'rottweiler',\n",
              " 'airedale',\n",
              " 'doberman',\n",
              " 'weimaraner',\n",
              " 'dingo',\n",
              " 'bedlington_terrier',\n",
              " 'silky_terrier',\n",
              " 'norfolk_terrier',\n",
              " 'mexican_hairless',\n",
              " 'german_shepherd',\n",
              " 'pug',\n",
              " 'airedale',\n",
              " 'entlebucher',\n",
              " 'irish_wolfhound',\n",
              " 'miniature_pinscher',\n",
              " 'boston_bull',\n",
              " 'miniature_pinscher',\n",
              " 'pug',\n",
              " 'german_short-haired_pointer',\n",
              " 'saint_bernard',\n",
              " 'border_terrier',\n",
              " 'great_pyrenees',\n",
              " 'lakeland_terrier',\n",
              " 'whippet',\n",
              " 'pug',\n",
              " 'miniature_pinscher',\n",
              " 'keeshond',\n",
              " 'boston_bull',\n",
              " 'lakeland_terrier',\n",
              " 'clumber',\n",
              " 'kelpie',\n",
              " 'entlebucher',\n",
              " 'affenpinscher',\n",
              " 'african_hunting_dog',\n",
              " 'norwegian_elkhound',\n",
              " 'norwegian_elkhound',\n",
              " 'kelpie',\n",
              " 'chesapeake_bay_retriever',\n",
              " 'rottweiler',\n",
              " 'malinois',\n",
              " 'maltese_dog',\n",
              " 'scottish_deerhound',\n",
              " 'standard_poodle',\n",
              " 'bloodhound',\n",
              " 'boston_bull',\n",
              " 'basenji',\n",
              " 'pembroke',\n",
              " 'norwich_terrier',\n",
              " 'border_collie',\n",
              " 'affenpinscher',\n",
              " 'pug',\n",
              " 'saluki',\n",
              " 'miniature_pinscher',\n",
              " 'papillon',\n",
              " 'airedale',\n",
              " 'afghan_hound',\n",
              " 'redbone',\n",
              " 'airedale',\n",
              " 'pug',\n",
              " 'irish_wolfhound',\n",
              " 'saint_bernard',\n",
              " 'afghan_hound',\n",
              " 'beagle',\n",
              " 'bernese_mountain_dog',\n",
              " 'basenji',\n",
              " 'boxer',\n",
              " 'airedale',\n",
              " 'blenheim_spaniel',\n",
              " 'scotch_terrier',\n",
              " 'airedale',\n",
              " 'lakeland_terrier',\n",
              " 'west_highland_white_terrier',\n",
              " 'toy_terrier',\n",
              " 'dhole',\n",
              " 'leonberg',\n",
              " 'airedale',\n",
              " 'miniature_poodle',\n",
              " 'shih-tzu',\n",
              " 'scottish_deerhound',\n",
              " 'scottish_deerhound',\n",
              " 'scottish_deerhound',\n",
              " 'black-and-tan_coonhound',\n",
              " 'bernese_mountain_dog',\n",
              " 'curly-coated_retriever',\n",
              " 'airedale',\n",
              " 'irish_water_spaniel',\n",
              " 'redbone',\n",
              " 'saluki',\n",
              " 'sussex_spaniel',\n",
              " 'siberian_husky',\n",
              " 'irish_water_spaniel',\n",
              " 'saint_bernard',\n",
              " 'basset',\n",
              " 'bluetick',\n",
              " 'chesapeake_bay_retriever',\n",
              " 'irish_wolfhound',\n",
              " 'keeshond',\n",
              " 'scottish_deerhound',\n",
              " 'dhole',\n",
              " 'cairn',\n",
              " 'clumber',\n",
              " 'brabancon_griffon',\n",
              " 'entlebucher',\n",
              " 'dhole',\n",
              " 'afghan_hound',\n",
              " 'saint_bernard',\n",
              " 'saint_bernard',\n",
              " 'australian_terrier',\n",
              " 'irish_setter',\n",
              " 'bluetick',\n",
              " 'standard_poodle',\n",
              " 'tibetan_terrier',\n",
              " 'norfolk_terrier',\n",
              " 'bedlington_terrier',\n",
              " 'groenendael',\n",
              " 'bull_mastiff',\n",
              " 'miniature_pinscher',\n",
              " 'bernese_mountain_dog',\n",
              " 'kerry_blue_terrier',\n",
              " 'norwegian_elkhound',\n",
              " 'pug',\n",
              " 'irish_wolfhound',\n",
              " 'clumber',\n",
              " 'papillon',\n",
              " 'irish_wolfhound',\n",
              " 'border_terrier',\n",
              " 'labrador_retriever',\n",
              " 'irish_wolfhound',\n",
              " 'pug',\n",
              " 'miniature_poodle',\n",
              " 'scottish_deerhound',\n",
              " 'schipperke',\n",
              " 'border_terrier',\n",
              " 'bluetick',\n",
              " 'bloodhound',\n",
              " 'african_hunting_dog',\n",
              " 'keeshond',\n",
              " 'great_dane',\n",
              " 'australian_terrier',\n",
              " 'ibizan_hound',\n",
              " 'mexican_hairless',\n",
              " 'samoyed',\n",
              " 'leonberg',\n",
              " 'newfoundland',\n",
              " 'rottweiler',\n",
              " 'rhodesian_ridgeback',\n",
              " 'boston_bull',\n",
              " 'english_setter',\n",
              " 'afghan_hound',\n",
              " 'lakeland_terrier',\n",
              " 'american_staffordshire_terrier',\n",
              " 'pomeranian',\n",
              " 'scottish_deerhound',\n",
              " 'golden_retriever',\n",
              " 'pug',\n",
              " 'pomeranian',\n",
              " 'saluki',\n",
              " 'scotch_terrier',\n",
              " 'kelpie',\n",
              " 'mexican_hairless',\n",
              " 'leonberg',\n",
              " 'shih-tzu',\n",
              " 'irish_wolfhound',\n",
              " 'entlebucher',\n",
              " 'bedlington_terrier',\n",
              " 'kelpie',\n",
              " 'miniature_pinscher',\n",
              " 'lakeland_terrier',\n",
              " 'ibizan_hound',\n",
              " 'toy_poodle',\n",
              " 'collie',\n",
              " 'whippet',\n",
              " 'shih-tzu',\n",
              " 'bull_mastiff',\n",
              " 'dingo',\n",
              " 'basenji',\n",
              " 'leonberg',\n",
              " 'dandie_dinmont',\n",
              " 'kelpie',\n",
              " 'affenpinscher',\n",
              " 'tibetan_terrier',\n",
              " 'basenji',\n",
              " 'airedale',\n",
              " 'mexican_hairless',\n",
              " 'english_springer',\n",
              " 'siberian_husky',\n",
              " 'irish_setter',\n",
              " 'dhole',\n",
              " 'leonberg',\n",
              " 'blenheim_spaniel',\n",
              " 'lakeland_terrier',\n",
              " 'dingo',\n",
              " 'english_foxhound',\n",
              " 'miniature_schnauzer',\n",
              " 'leonberg',\n",
              " 'german_short-haired_pointer',\n",
              " 'irish_water_spaniel',\n",
              " 'kerry_blue_terrier',\n",
              " 'border_collie',\n",
              " 'bouvier_des_flandres',\n",
              " 'soft-coated_wheaten_terrier',\n",
              " 'maltese_dog',\n",
              " 'redbone',\n",
              " 'maltese_dog',\n",
              " 'bloodhound',\n",
              " 'shih-tzu',\n",
              " 'italian_greyhound',\n",
              " 'boston_bull',\n",
              " 'chesapeake_bay_retriever',\n",
              " 'yorkshire_terrier',\n",
              " 'airedale',\n",
              " 'greater_swiss_mountain_dog',\n",
              " 'rottweiler',\n",
              " 'walker_hound',\n",
              " 'west_highland_white_terrier',\n",
              " 'shih-tzu',\n",
              " 'silky_terrier',\n",
              " 'golden_retriever',\n",
              " 'bernese_mountain_dog',\n",
              " 'sealyham_terrier',\n",
              " 'english_foxhound',\n",
              " 'newfoundland',\n",
              " 'silky_terrier',\n",
              " 'beagle',\n",
              " 'chow',\n",
              " 'italian_greyhound',\n",
              " 'bloodhound',\n",
              " 'bernese_mountain_dog',\n",
              " 'english_springer',\n",
              " 'pug',\n",
              " 'sealyham_terrier',\n",
              " 'sussex_spaniel',\n",
              " 'standard_schnauzer',\n",
              " 'scottish_deerhound',\n",
              " 'sealyham_terrier',\n",
              " 'bull_mastiff',\n",
              " 'maltese_dog',\n",
              " 'black-and-tan_coonhound',\n",
              " 'border_collie',\n",
              " 'chow',\n",
              " 'chesapeake_bay_retriever',\n",
              " 'siberian_husky',\n",
              " 'beagle',\n",
              " 'boston_bull',\n",
              " 'border_terrier',\n",
              " 'leonberg',\n",
              " 'weimaraner',\n",
              " 'german_shepherd',\n",
              " 'scottish_deerhound',\n",
              " 'airedale',\n",
              " 'bernese_mountain_dog',\n",
              " 'samoyed',\n",
              " 'dingo',\n",
              " 'bluetick',\n",
              " 'vizsla',\n",
              " 'norwegian_elkhound',\n",
              " 'airedale',\n",
              " 'chow',\n",
              " 'great_pyrenees',\n",
              " 'standard_schnauzer',\n",
              " 'great_dane',\n",
              " 'beagle',\n",
              " 'papillon',\n",
              " 'irish_water_spaniel',\n",
              " 'pug',\n",
              " 'samoyed',\n",
              " 'bernese_mountain_dog',\n",
              " 'japanese_spaniel',\n",
              " 'norwegian_elkhound',\n",
              " 'beagle',\n",
              " 'samoyed',\n",
              " 'sussex_spaniel',\n",
              " 'vizsla',\n",
              " 'samoyed',\n",
              " 'pekinese',\n",
              " 'australian_terrier',\n",
              " 'miniature_pinscher',\n",
              " 'english_foxhound',\n",
              " 'entlebucher',\n",
              " 'tibetan_terrier',\n",
              " 'toy_poodle',\n",
              " 'dhole',\n",
              " 'silky_terrier',\n",
              " 'eskimo_dog',\n",
              " 'lhasa',\n",
              " 'pembroke',\n",
              " 'border_collie',\n",
              " 'beagle',\n",
              " 'entlebucher',\n",
              " 'affenpinscher',\n",
              " 'chow',\n",
              " 'irish_wolfhound',\n",
              " 'redbone',\n",
              " 'sealyham_terrier',\n",
              " 'shih-tzu',\n",
              " 'great_dane',\n",
              " 'norfolk_terrier',\n",
              " 'great_dane',\n",
              " 'blenheim_spaniel',\n",
              " 'golden_retriever',\n",
              " 'german_shepherd',\n",
              " 'miniature_schnauzer',\n",
              " 'welsh_springer_spaniel',\n",
              " 'bouvier_des_flandres',\n",
              " 'miniature_pinscher',\n",
              " 'kuvasz',\n",
              " 'german_short-haired_pointer',\n",
              " 'dhole',\n",
              " 'sealyham_terrier',\n",
              " 'eskimo_dog',\n",
              " 'saluki',\n",
              " 'miniature_schnauzer',\n",
              " 'affenpinscher',\n",
              " 'bernese_mountain_dog',\n",
              " 'bluetick',\n",
              " 'old_english_sheepdog',\n",
              " 'afghan_hound',\n",
              " 'toy_poodle',\n",
              " 'sealyham_terrier',\n",
              " 'bedlington_terrier',\n",
              " 'border_terrier',\n",
              " 'irish_water_spaniel',\n",
              " 'pug',\n",
              " 'kerry_blue_terrier',\n",
              " 'chesapeake_bay_retriever',\n",
              " 'border_terrier',\n",
              " 'beagle',\n",
              " 'afghan_hound',\n",
              " 'miniature_schnauzer',\n",
              " 'samoyed',\n",
              " 'toy_poodle',\n",
              " 'irish_water_spaniel',\n",
              " 'curly-coated_retriever',\n",
              " 'sealyham_terrier',\n",
              " 'silky_terrier',\n",
              " 'great_pyrenees',\n",
              " 'rhodesian_ridgeback',\n",
              " 'labrador_retriever',\n",
              " 'miniature_pinscher',\n",
              " 'rottweiler',\n",
              " 'pomeranian',\n",
              " 'bluetick',\n",
              " 'schipperke',\n",
              " 'irish_water_spaniel',\n",
              " 'bull_mastiff',\n",
              " 'whippet',\n",
              " 'standard_poodle',\n",
              " 'bernese_mountain_dog',\n",
              " 'italian_greyhound',\n",
              " 'boston_bull',\n",
              " 'brittany_spaniel',\n",
              " 'maltese_dog',\n",
              " 'scotch_terrier',\n",
              " 'bull_mastiff',\n",
              " 'staffordshire_bullterrier',\n",
              " 'newfoundland',\n",
              " 'curly-coated_retriever',\n",
              " 'shih-tzu',\n",
              " 'sealyham_terrier',\n",
              " 'dhole',\n",
              " 'whippet',\n",
              " 'siberian_husky',\n",
              " 'schipperke',\n",
              " 'pug',\n",
              " 'shetland_sheepdog',\n",
              " 'clumber',\n",
              " 'malamute',\n",
              " 'schipperke',\n",
              " 'walker_hound',\n",
              " 'newfoundland',\n",
              " 'scotch_terrier',\n",
              " 'lakeland_terrier',\n",
              " 'mexican_hairless',\n",
              " 'pug',\n",
              " 'lakeland_terrier',\n",
              " 'borzoi',\n",
              " 'boxer',\n",
              " 'walker_hound',\n",
              " 'boston_bull',\n",
              " 'chow',\n",
              " 'airedale',\n",
              " 'beagle',\n",
              " 'lakeland_terrier',\n",
              " 'irish_wolfhound',\n",
              " 'french_bulldog',\n",
              " 'african_hunting_dog',\n",
              " 'irish_wolfhound',\n",
              " 'old_english_sheepdog',\n",
              " 'italian_greyhound',\n",
              " 'beagle',\n",
              " 'airedale',\n",
              " 'saint_bernard',\n",
              " 'pembroke',\n",
              " 'irish_setter',\n",
              " 'german_short-haired_pointer',\n",
              " 'tibetan_mastiff',\n",
              " 'standard_poodle',\n",
              " 'yorkshire_terrier',\n",
              " 'pomeranian',\n",
              " 'samoyed',\n",
              " 'pug',\n",
              " 'african_hunting_dog',\n",
              " 'schipperke',\n",
              " 'curly-coated_retriever',\n",
              " 'whippet',\n",
              " 'african_hunting_dog',\n",
              " 'blenheim_spaniel',\n",
              " 'maltese_dog',\n",
              " 'african_hunting_dog',\n",
              " 'miniature_poodle',\n",
              " 'weimaraner',\n",
              " 'bloodhound',\n",
              " 'staffordshire_bullterrier',\n",
              " 'irish_water_spaniel',\n",
              " 'african_hunting_dog',\n",
              " 'australian_terrier',\n",
              " 'bernese_mountain_dog',\n",
              " 'pekinese',\n",
              " 'bluetick',\n",
              " 'pug',\n",
              " 'airedale',\n",
              " 'dhole',\n",
              " 'miniature_schnauzer',\n",
              " 'chow',\n",
              " 'siberian_husky',\n",
              " 'gordon_setter',\n",
              " 'irish_water_spaniel',\n",
              " 'bluetick',\n",
              " 'black-and-tan_coonhound',\n",
              " 'bluetick',\n",
              " 'soft-coated_wheaten_terrier',\n",
              " 'welsh_springer_spaniel',\n",
              " 'brabancon_griffon',\n",
              " 'malamute',\n",
              " 'komondor',\n",
              " 'walker_hound',\n",
              " 'bluetick',\n",
              " 'african_hunting_dog',\n",
              " 'black-and-tan_coonhound',\n",
              " 'pembroke',\n",
              " 'chesapeake_bay_retriever',\n",
              " 'great_pyrenees',\n",
              " 'dhole',\n",
              " 'maltese_dog',\n",
              " 'doberman',\n",
              " 'scottish_deerhound',\n",
              " 'rottweiler',\n",
              " 'west_highland_white_terrier',\n",
              " 'maltese_dog',\n",
              " 'cairn',\n",
              " 'yorkshire_terrier',\n",
              " 'bluetick',\n",
              " 'saluki',\n",
              " 'irish_water_spaniel',\n",
              " 'pug',\n",
              " 'entlebucher',\n",
              " 'gordon_setter',\n",
              " 'papillon',\n",
              " 'otterhound',\n",
              " 'miniature_pinscher',\n",
              " 'ibizan_hound',\n",
              " 'bull_mastiff',\n",
              " 'welsh_springer_spaniel',\n",
              " 'wire-haired_fox_terrier',\n",
              " 'norwegian_elkhound',\n",
              " 'cairn',\n",
              " 'dhole',\n",
              " 'bloodhound',\n",
              " 'dhole',\n",
              " 'beagle',\n",
              " 'yorkshire_terrier',\n",
              " 'saluki',\n",
              " 'saluki',\n",
              " 'rottweiler',\n",
              " 'pug',\n",
              " 'lakeland_terrier',\n",
              " 'italian_greyhound',\n",
              " 'malinois',\n",
              " 'kerry_blue_terrier',\n",
              " 'eskimo_dog',\n",
              " 'kelpie',\n",
              " 'norwegian_elkhound',\n",
              " 'maltese_dog',\n",
              " 'kerry_blue_terrier',\n",
              " 'west_highland_white_terrier',\n",
              " 'saluki',\n",
              " 'african_hunting_dog',\n",
              " 'greater_swiss_mountain_dog',\n",
              " 'walker_hound',\n",
              " 'pug',\n",
              " 'great_pyrenees',\n",
              " 'shih-tzu',\n",
              " 'bull_mastiff',\n",
              " 'basenji',\n",
              " 'chesapeake_bay_retriever',\n",
              " 'scottish_deerhound',\n",
              " 'redbone',\n",
              " 'bernese_mountain_dog',\n",
              " 'saluki',\n",
              " 'whippet',\n",
              " 'border_terrier',\n",
              " 'afghan_hound',\n",
              " 'english_foxhound',\n",
              " 'ibizan_hound',\n",
              " 'rhodesian_ridgeback',\n",
              " 'siberian_husky',\n",
              " 'irish_wolfhound',\n",
              " 'entlebucher',\n",
              " 'gordon_setter',\n",
              " 'maltese_dog',\n",
              " 'pomeranian',\n",
              " 'black-and-tan_coonhound',\n",
              " 'miniature_poodle',\n",
              " 'basset',\n",
              " 'welsh_springer_spaniel',\n",
              " 'miniature_pinscher',\n",
              " 'tibetan_mastiff',\n",
              " 'saint_bernard',\n",
              " 'kerry_blue_terrier',\n",
              " 'papillon',\n",
              " 'siberian_husky',\n",
              " 'samoyed',\n",
              " 'rottweiler',\n",
              " 'border_collie',\n",
              " 'saluki',\n",
              " 'border_terrier',\n",
              " 'airedale',\n",
              " 'australian_terrier',\n",
              " 'saint_bernard',\n",
              " 'irish_setter',\n",
              " 'samoyed',\n",
              " 'lakeland_terrier',\n",
              " 'leonberg',\n",
              " 'komondor',\n",
              " 'schipperke',\n",
              " 'collie',\n",
              " 'rottweiler',\n",
              " 'old_english_sheepdog',\n",
              " 'shih-tzu',\n",
              " 'maltese_dog',\n",
              " 'border_collie',\n",
              " 'whippet',\n",
              " 'clumber',\n",
              " 'afghan_hound',\n",
              " 'english_springer',\n",
              " 'rottweiler',\n",
              " 'bull_mastiff',\n",
              " 'german_shepherd',\n",
              " 'border_collie',\n",
              " 'pug',\n",
              " 'dingo',\n",
              " 'borzoi',\n",
              " 'samoyed',\n",
              " 'norfolk_terrier',\n",
              " 'pug',\n",
              " 'shih-tzu',\n",
              " 'greater_swiss_mountain_dog',\n",
              " 'west_highland_white_terrier',\n",
              " 'english_springer',\n",
              " 'borzoi',\n",
              " 'scottish_deerhound',\n",
              " 'clumber',\n",
              " 'staffordshire_bullterrier',\n",
              " 'yorkshire_terrier',\n",
              " 'african_hunting_dog',\n",
              " 'brittany_spaniel',\n",
              " 'african_hunting_dog',\n",
              " 'labrador_retriever',\n",
              " 'weimaraner',\n",
              " 'bull_mastiff',\n",
              " 'dandie_dinmont',\n",
              " 'entlebucher',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIQ8A6wW36Do",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "4e29847a-7915-49c4-9eca-a46b9071a71c"
      },
      "source": [
        "sub = pd.DataFrame(data = pred, index = submision.id, columns = y_test.columns)\n",
        "sub"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>affenpinscher</th>\n",
              "      <th>afghan_hound</th>\n",
              "      <th>african_hunting_dog</th>\n",
              "      <th>airedale</th>\n",
              "      <th>american_staffordshire_terrier</th>\n",
              "      <th>appenzeller</th>\n",
              "      <th>australian_terrier</th>\n",
              "      <th>basenji</th>\n",
              "      <th>basset</th>\n",
              "      <th>beagle</th>\n",
              "      <th>bedlington_terrier</th>\n",
              "      <th>bernese_mountain_dog</th>\n",
              "      <th>black-and-tan_coonhound</th>\n",
              "      <th>blenheim_spaniel</th>\n",
              "      <th>bloodhound</th>\n",
              "      <th>bluetick</th>\n",
              "      <th>border_collie</th>\n",
              "      <th>border_terrier</th>\n",
              "      <th>borzoi</th>\n",
              "      <th>boston_bull</th>\n",
              "      <th>bouvier_des_flandres</th>\n",
              "      <th>boxer</th>\n",
              "      <th>brabancon_griffon</th>\n",
              "      <th>briard</th>\n",
              "      <th>brittany_spaniel</th>\n",
              "      <th>bull_mastiff</th>\n",
              "      <th>cairn</th>\n",
              "      <th>cardigan</th>\n",
              "      <th>chesapeake_bay_retriever</th>\n",
              "      <th>chihuahua</th>\n",
              "      <th>chow</th>\n",
              "      <th>clumber</th>\n",
              "      <th>cocker_spaniel</th>\n",
              "      <th>collie</th>\n",
              "      <th>curly-coated_retriever</th>\n",
              "      <th>dandie_dinmont</th>\n",
              "      <th>dhole</th>\n",
              "      <th>dingo</th>\n",
              "      <th>doberman</th>\n",
              "      <th>english_foxhound</th>\n",
              "      <th>...</th>\n",
              "      <th>norwegian_elkhound</th>\n",
              "      <th>norwich_terrier</th>\n",
              "      <th>old_english_sheepdog</th>\n",
              "      <th>otterhound</th>\n",
              "      <th>papillon</th>\n",
              "      <th>pekinese</th>\n",
              "      <th>pembroke</th>\n",
              "      <th>pomeranian</th>\n",
              "      <th>pug</th>\n",
              "      <th>redbone</th>\n",
              "      <th>rhodesian_ridgeback</th>\n",
              "      <th>rottweiler</th>\n",
              "      <th>saint_bernard</th>\n",
              "      <th>saluki</th>\n",
              "      <th>samoyed</th>\n",
              "      <th>schipperke</th>\n",
              "      <th>scotch_terrier</th>\n",
              "      <th>scottish_deerhound</th>\n",
              "      <th>sealyham_terrier</th>\n",
              "      <th>shetland_sheepdog</th>\n",
              "      <th>shih-tzu</th>\n",
              "      <th>siberian_husky</th>\n",
              "      <th>silky_terrier</th>\n",
              "      <th>soft-coated_wheaten_terrier</th>\n",
              "      <th>staffordshire_bullterrier</th>\n",
              "      <th>standard_poodle</th>\n",
              "      <th>standard_schnauzer</th>\n",
              "      <th>sussex_spaniel</th>\n",
              "      <th>tibetan_mastiff</th>\n",
              "      <th>tibetan_terrier</th>\n",
              "      <th>toy_poodle</th>\n",
              "      <th>toy_terrier</th>\n",
              "      <th>vizsla</th>\n",
              "      <th>walker_hound</th>\n",
              "      <th>weimaraner</th>\n",
              "      <th>welsh_springer_spaniel</th>\n",
              "      <th>west_highland_white_terrier</th>\n",
              "      <th>whippet</th>\n",
              "      <th>wire-haired_fox_terrier</th>\n",
              "      <th>yorkshire_terrier</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000621fb3cbb32d8935728e48679680e</th>\n",
              "      <td>0.001051</td>\n",
              "      <td>1.873785e-02</td>\n",
              "      <td>0.032793</td>\n",
              "      <td>2.636800e-03</td>\n",
              "      <td>4.941280e-03</td>\n",
              "      <td>5.539417e-03</td>\n",
              "      <td>1.876988e-03</td>\n",
              "      <td>0.001947</td>\n",
              "      <td>2.973692e-02</td>\n",
              "      <td>0.039969</td>\n",
              "      <td>0.001505</td>\n",
              "      <td>3.437903e-03</td>\n",
              "      <td>1.391856e-02</td>\n",
              "      <td>2.370280e-02</td>\n",
              "      <td>1.287595e-02</td>\n",
              "      <td>2.613572e-02</td>\n",
              "      <td>0.003040</td>\n",
              "      <td>3.691994e-03</td>\n",
              "      <td>0.009206</td>\n",
              "      <td>0.002146</td>\n",
              "      <td>8.530026e-04</td>\n",
              "      <td>9.582481e-03</td>\n",
              "      <td>2.523505e-03</td>\n",
              "      <td>4.384473e-03</td>\n",
              "      <td>1.589291e-02</td>\n",
              "      <td>0.016863</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.006487</td>\n",
              "      <td>1.339754e-02</td>\n",
              "      <td>0.002190</td>\n",
              "      <td>0.002153</td>\n",
              "      <td>7.654240e-03</td>\n",
              "      <td>1.089501e-02</td>\n",
              "      <td>0.017506</td>\n",
              "      <td>3.587198e-03</td>\n",
              "      <td>0.001724</td>\n",
              "      <td>0.014639</td>\n",
              "      <td>0.005749</td>\n",
              "      <td>1.715236e-03</td>\n",
              "      <td>7.689799e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012911</td>\n",
              "      <td>0.000703</td>\n",
              "      <td>0.001485</td>\n",
              "      <td>1.981795e-03</td>\n",
              "      <td>0.006444</td>\n",
              "      <td>0.005877</td>\n",
              "      <td>0.002308</td>\n",
              "      <td>0.001196</td>\n",
              "      <td>0.018267</td>\n",
              "      <td>6.950467e-03</td>\n",
              "      <td>1.943158e-02</td>\n",
              "      <td>5.864278e-03</td>\n",
              "      <td>0.016393</td>\n",
              "      <td>0.042076</td>\n",
              "      <td>0.000989</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.000597</td>\n",
              "      <td>5.600565e-03</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0.009876</td>\n",
              "      <td>0.003448</td>\n",
              "      <td>0.008712</td>\n",
              "      <td>8.217722e-03</td>\n",
              "      <td>9.163285e-04</td>\n",
              "      <td>4.017293e-03</td>\n",
              "      <td>1.624142e-03</td>\n",
              "      <td>2.390009e-03</td>\n",
              "      <td>9.006322e-03</td>\n",
              "      <td>6.170890e-03</td>\n",
              "      <td>1.156527e-02</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.001088</td>\n",
              "      <td>4.353946e-03</td>\n",
              "      <td>1.630093e-02</td>\n",
              "      <td>1.227670e-02</td>\n",
              "      <td>4.278355e-02</td>\n",
              "      <td>0.000499</td>\n",
              "      <td>1.967330e-02</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>1.509213e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00102ee9d8eb90812350685311fe5890</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>5.439068e-08</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>6.386808e-09</td>\n",
              "      <td>6.729178e-07</td>\n",
              "      <td>4.873548e-07</td>\n",
              "      <td>5.201221e-07</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>1.601524e-08</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>4.614002e-07</td>\n",
              "      <td>9.312658e-09</td>\n",
              "      <td>1.138392e-07</td>\n",
              "      <td>5.821947e-09</td>\n",
              "      <td>1.386595e-08</td>\n",
              "      <td>0.002213</td>\n",
              "      <td>1.009502e-08</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>2.377077e-07</td>\n",
              "      <td>4.479377e-07</td>\n",
              "      <td>1.707212e-07</td>\n",
              "      <td>1.316438e-07</td>\n",
              "      <td>5.619668e-07</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000434</td>\n",
              "      <td>2.450988e-07</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000495</td>\n",
              "      <td>5.717176e-07</td>\n",
              "      <td>1.071022e-07</td>\n",
              "      <td>0.002986</td>\n",
              "      <td>8.186387e-08</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>1.315327e-07</td>\n",
              "      <td>1.125161e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>1.561788e-07</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>5.786159e-08</td>\n",
              "      <td>4.444039e-09</td>\n",
              "      <td>1.194551e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.534377</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>8.850346e-08</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000353</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.340362</td>\n",
              "      <td>4.981437e-09</td>\n",
              "      <td>6.639444e-07</td>\n",
              "      <td>8.980024e-07</td>\n",
              "      <td>6.012768e-07</td>\n",
              "      <td>1.104662e-08</td>\n",
              "      <td>9.518312e-09</td>\n",
              "      <td>7.665193e-07</td>\n",
              "      <td>1.849995e-07</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>5.598338e-08</td>\n",
              "      <td>3.615229e-07</td>\n",
              "      <td>2.165280e-07</td>\n",
              "      <td>3.373735e-07</td>\n",
              "      <td>0.001184</td>\n",
              "      <td>5.592908e-07</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>2.015989e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0012a730dfa437f5f3613fb75efcd4ce</th>\n",
              "      <td>0.001159</td>\n",
              "      <td>6.698846e-02</td>\n",
              "      <td>0.003832</td>\n",
              "      <td>1.073298e-02</td>\n",
              "      <td>8.955132e-04</td>\n",
              "      <td>6.329154e-04</td>\n",
              "      <td>2.936355e-03</td>\n",
              "      <td>0.000346</td>\n",
              "      <td>2.271279e-03</td>\n",
              "      <td>0.002726</td>\n",
              "      <td>0.007935</td>\n",
              "      <td>1.454278e-03</td>\n",
              "      <td>2.533067e-03</td>\n",
              "      <td>3.022657e-03</td>\n",
              "      <td>6.789608e-03</td>\n",
              "      <td>7.063203e-03</td>\n",
              "      <td>0.003453</td>\n",
              "      <td>9.220866e-03</td>\n",
              "      <td>0.036021</td>\n",
              "      <td>0.000402</td>\n",
              "      <td>1.764003e-03</td>\n",
              "      <td>4.437405e-04</td>\n",
              "      <td>6.624572e-04</td>\n",
              "      <td>1.873126e-02</td>\n",
              "      <td>5.039886e-03</td>\n",
              "      <td>0.003212</td>\n",
              "      <td>0.008190</td>\n",
              "      <td>0.000519</td>\n",
              "      <td>4.076688e-03</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.000534</td>\n",
              "      <td>6.525727e-02</td>\n",
              "      <td>1.753310e-02</td>\n",
              "      <td>0.005638</td>\n",
              "      <td>1.657647e-03</td>\n",
              "      <td>0.029810</td>\n",
              "      <td>0.002031</td>\n",
              "      <td>0.002202</td>\n",
              "      <td>4.146691e-04</td>\n",
              "      <td>1.496966e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000951</td>\n",
              "      <td>0.002383</td>\n",
              "      <td>0.008018</td>\n",
              "      <td>2.312750e-02</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>0.000557</td>\n",
              "      <td>0.004382</td>\n",
              "      <td>1.216427e-03</td>\n",
              "      <td>1.753026e-03</td>\n",
              "      <td>9.509549e-04</td>\n",
              "      <td>0.002110</td>\n",
              "      <td>0.028457</td>\n",
              "      <td>0.001967</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.001074</td>\n",
              "      <td>6.528758e-02</td>\n",
              "      <td>0.022113</td>\n",
              "      <td>0.003401</td>\n",
              "      <td>0.003910</td>\n",
              "      <td>0.000902</td>\n",
              "      <td>4.549271e-03</td>\n",
              "      <td>7.311378e-03</td>\n",
              "      <td>5.585288e-04</td>\n",
              "      <td>3.212576e-03</td>\n",
              "      <td>1.400358e-02</td>\n",
              "      <td>1.533270e-02</td>\n",
              "      <td>1.889924e-03</td>\n",
              "      <td>2.264444e-02</td>\n",
              "      <td>0.001694</td>\n",
              "      <td>0.000587</td>\n",
              "      <td>2.584221e-03</td>\n",
              "      <td>1.649314e-03</td>\n",
              "      <td>7.898307e-03</td>\n",
              "      <td>1.200303e-02</td>\n",
              "      <td>0.002061</td>\n",
              "      <td>6.687847e-03</td>\n",
              "      <td>0.004320</td>\n",
              "      <td>2.658817e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>001510bc8570bbeee98c8d80c8a95ec1</th>\n",
              "      <td>0.005452</td>\n",
              "      <td>1.208619e-01</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>7.658057e-03</td>\n",
              "      <td>6.140819e-03</td>\n",
              "      <td>5.574666e-04</td>\n",
              "      <td>2.345107e-03</td>\n",
              "      <td>0.003277</td>\n",
              "      <td>9.140652e-04</td>\n",
              "      <td>0.002467</td>\n",
              "      <td>0.006434</td>\n",
              "      <td>9.516457e-04</td>\n",
              "      <td>1.366269e-02</td>\n",
              "      <td>8.269314e-04</td>\n",
              "      <td>2.533871e-02</td>\n",
              "      <td>4.655774e-03</td>\n",
              "      <td>0.000481</td>\n",
              "      <td>2.324508e-03</td>\n",
              "      <td>0.001223</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>4.315515e-03</td>\n",
              "      <td>3.260375e-03</td>\n",
              "      <td>3.490212e-03</td>\n",
              "      <td>9.017139e-03</td>\n",
              "      <td>8.823031e-04</td>\n",
              "      <td>0.014680</td>\n",
              "      <td>0.004391</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>2.572062e-02</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>0.000714</td>\n",
              "      <td>7.014826e-03</td>\n",
              "      <td>2.768778e-03</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>3.102487e-02</td>\n",
              "      <td>0.002858</td>\n",
              "      <td>0.000715</td>\n",
              "      <td>0.001621</td>\n",
              "      <td>8.587216e-03</td>\n",
              "      <td>3.984313e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004024</td>\n",
              "      <td>0.003095</td>\n",
              "      <td>0.003560</td>\n",
              "      <td>1.261468e-03</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.001769</td>\n",
              "      <td>0.000325</td>\n",
              "      <td>0.001484</td>\n",
              "      <td>0.016199</td>\n",
              "      <td>2.455651e-02</td>\n",
              "      <td>1.402783e-02</td>\n",
              "      <td>8.775686e-03</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.007792</td>\n",
              "      <td>0.003928</td>\n",
              "      <td>0.006253</td>\n",
              "      <td>0.011273</td>\n",
              "      <td>7.238929e-03</td>\n",
              "      <td>0.009996</td>\n",
              "      <td>0.000621</td>\n",
              "      <td>0.001320</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>6.624659e-03</td>\n",
              "      <td>4.390168e-03</td>\n",
              "      <td>8.992359e-03</td>\n",
              "      <td>1.013754e-02</td>\n",
              "      <td>6.614146e-03</td>\n",
              "      <td>1.197993e-02</td>\n",
              "      <td>1.706665e-03</td>\n",
              "      <td>2.777398e-03</td>\n",
              "      <td>0.005547</td>\n",
              "      <td>0.000728</td>\n",
              "      <td>2.405611e-02</td>\n",
              "      <td>1.451426e-03</td>\n",
              "      <td>4.295442e-02</td>\n",
              "      <td>1.382062e-03</td>\n",
              "      <td>0.001046</td>\n",
              "      <td>1.311532e-02</td>\n",
              "      <td>0.000509</td>\n",
              "      <td>4.350570e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>001a5f3114548acdefa3d4da05474c2e</th>\n",
              "      <td>0.014099</td>\n",
              "      <td>1.178031e-02</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>1.079974e-02</td>\n",
              "      <td>2.596087e-04</td>\n",
              "      <td>1.929827e-04</td>\n",
              "      <td>4.730478e-03</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>1.782662e-04</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.007906</td>\n",
              "      <td>4.860616e-04</td>\n",
              "      <td>1.846847e-04</td>\n",
              "      <td>4.805287e-04</td>\n",
              "      <td>2.042219e-04</td>\n",
              "      <td>5.793787e-04</td>\n",
              "      <td>0.001827</td>\n",
              "      <td>6.890218e-03</td>\n",
              "      <td>0.002238</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>2.058219e-02</td>\n",
              "      <td>7.130321e-05</td>\n",
              "      <td>3.017323e-04</td>\n",
              "      <td>3.141742e-02</td>\n",
              "      <td>5.868862e-04</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>0.030238</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>6.351321e-04</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.002363</td>\n",
              "      <td>8.015533e-03</td>\n",
              "      <td>8.497094e-03</td>\n",
              "      <td>0.001058</td>\n",
              "      <td>1.929786e-03</td>\n",
              "      <td>0.087869</td>\n",
              "      <td>0.000412</td>\n",
              "      <td>0.000409</td>\n",
              "      <td>1.028023e-04</td>\n",
              "      <td>4.800832e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.005362</td>\n",
              "      <td>0.023040</td>\n",
              "      <td>6.581376e-02</td>\n",
              "      <td>0.000755</td>\n",
              "      <td>0.004781</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000397</td>\n",
              "      <td>0.000695</td>\n",
              "      <td>1.144487e-04</td>\n",
              "      <td>1.466205e-04</td>\n",
              "      <td>2.147506e-04</td>\n",
              "      <td>0.000901</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>0.001273</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>0.004753</td>\n",
              "      <td>2.315543e-02</td>\n",
              "      <td>0.039700</td>\n",
              "      <td>0.000698</td>\n",
              "      <td>0.048794</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>9.539858e-03</td>\n",
              "      <td>4.433873e-02</td>\n",
              "      <td>2.933997e-04</td>\n",
              "      <td>5.204684e-03</td>\n",
              "      <td>7.188564e-02</td>\n",
              "      <td>4.596027e-03</td>\n",
              "      <td>3.502595e-03</td>\n",
              "      <td>1.543150e-01</td>\n",
              "      <td>0.007236</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>4.311182e-04</td>\n",
              "      <td>1.937260e-04</td>\n",
              "      <td>2.823187e-04</td>\n",
              "      <td>1.378768e-03</td>\n",
              "      <td>0.013437</td>\n",
              "      <td>2.048061e-04</td>\n",
              "      <td>0.014189</td>\n",
              "      <td>1.321160e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ffeda8623d4eee33c6d1156a2ecbfcf8</th>\n",
              "      <td>0.001384</td>\n",
              "      <td>7.792518e-03</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>3.177274e-02</td>\n",
              "      <td>1.216241e-02</td>\n",
              "      <td>9.713200e-04</td>\n",
              "      <td>4.045997e-04</td>\n",
              "      <td>0.000902</td>\n",
              "      <td>6.100705e-03</td>\n",
              "      <td>0.004062</td>\n",
              "      <td>0.195459</td>\n",
              "      <td>5.824458e-04</td>\n",
              "      <td>1.972750e-03</td>\n",
              "      <td>1.073737e-03</td>\n",
              "      <td>1.141619e-02</td>\n",
              "      <td>8.956763e-03</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>2.277289e-02</td>\n",
              "      <td>0.008302</td>\n",
              "      <td>0.001444</td>\n",
              "      <td>7.318749e-03</td>\n",
              "      <td>4.662529e-03</td>\n",
              "      <td>1.719565e-03</td>\n",
              "      <td>4.499801e-03</td>\n",
              "      <td>2.419549e-03</td>\n",
              "      <td>0.006932</td>\n",
              "      <td>0.004470</td>\n",
              "      <td>0.000948</td>\n",
              "      <td>1.034785e-02</td>\n",
              "      <td>0.000391</td>\n",
              "      <td>0.001460</td>\n",
              "      <td>1.276256e-02</td>\n",
              "      <td>2.132192e-02</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>7.020305e-03</td>\n",
              "      <td>0.006458</td>\n",
              "      <td>0.000814</td>\n",
              "      <td>0.002753</td>\n",
              "      <td>7.173962e-04</td>\n",
              "      <td>5.511185e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.000864</td>\n",
              "      <td>0.006172</td>\n",
              "      <td>7.059527e-03</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.009979</td>\n",
              "      <td>2.723539e-03</td>\n",
              "      <td>3.748454e-03</td>\n",
              "      <td>1.143973e-03</td>\n",
              "      <td>0.006556</td>\n",
              "      <td>0.004128</td>\n",
              "      <td>0.001478</td>\n",
              "      <td>0.000621</td>\n",
              "      <td>0.000903</td>\n",
              "      <td>1.591439e-02</td>\n",
              "      <td>0.006388</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.001708</td>\n",
              "      <td>0.000409</td>\n",
              "      <td>1.137796e-03</td>\n",
              "      <td>2.620450e-02</td>\n",
              "      <td>8.914796e-03</td>\n",
              "      <td>4.107703e-02</td>\n",
              "      <td>1.495138e-02</td>\n",
              "      <td>4.665853e-03</td>\n",
              "      <td>1.975304e-03</td>\n",
              "      <td>6.599644e-03</td>\n",
              "      <td>0.010411</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>1.889053e-02</td>\n",
              "      <td>3.105449e-03</td>\n",
              "      <td>1.310865e-02</td>\n",
              "      <td>4.936261e-03</td>\n",
              "      <td>0.002822</td>\n",
              "      <td>3.077402e-03</td>\n",
              "      <td>0.047842</td>\n",
              "      <td>1.292110e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fff1ec9e6e413275984966f745a313b0</th>\n",
              "      <td>0.000120</td>\n",
              "      <td>2.313380e-03</td>\n",
              "      <td>0.002969</td>\n",
              "      <td>2.756084e-03</td>\n",
              "      <td>7.431544e-03</td>\n",
              "      <td>9.780404e-04</td>\n",
              "      <td>1.960150e-04</td>\n",
              "      <td>0.004247</td>\n",
              "      <td>1.951681e-02</td>\n",
              "      <td>0.069376</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>1.892447e-04</td>\n",
              "      <td>9.819584e-03</td>\n",
              "      <td>1.033856e-03</td>\n",
              "      <td>6.514653e-02</td>\n",
              "      <td>2.443933e-02</td>\n",
              "      <td>0.000203</td>\n",
              "      <td>4.012586e-03</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>1.102554e-04</td>\n",
              "      <td>1.897244e-02</td>\n",
              "      <td>2.202781e-03</td>\n",
              "      <td>2.471697e-04</td>\n",
              "      <td>4.297462e-03</td>\n",
              "      <td>0.053208</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000569</td>\n",
              "      <td>4.204753e-02</td>\n",
              "      <td>0.000666</td>\n",
              "      <td>0.000539</td>\n",
              "      <td>1.789272e-03</td>\n",
              "      <td>2.630093e-03</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>6.988420e-04</td>\n",
              "      <td>0.000468</td>\n",
              "      <td>0.001421</td>\n",
              "      <td>0.002890</td>\n",
              "      <td>2.421242e-03</td>\n",
              "      <td>1.303131e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002193</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>4.726573e-04</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000479</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>0.000296</td>\n",
              "      <td>0.014592</td>\n",
              "      <td>3.204156e-02</td>\n",
              "      <td>6.523009e-02</td>\n",
              "      <td>4.630871e-03</td>\n",
              "      <td>0.006053</td>\n",
              "      <td>0.030866</td>\n",
              "      <td>0.000548</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>2.153597e-03</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>0.000465</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>3.718558e-04</td>\n",
              "      <td>7.438032e-04</td>\n",
              "      <td>4.725762e-03</td>\n",
              "      <td>7.590117e-04</td>\n",
              "      <td>3.012017e-04</td>\n",
              "      <td>1.604402e-03</td>\n",
              "      <td>6.762810e-04</td>\n",
              "      <td>3.227175e-04</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.000711</td>\n",
              "      <td>3.029540e-02</td>\n",
              "      <td>3.125019e-02</td>\n",
              "      <td>1.478041e-01</td>\n",
              "      <td>4.178595e-03</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>5.284193e-02</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>1.859115e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fff74b59b758bbbf13a5793182a9bbe4</th>\n",
              "      <td>0.008316</td>\n",
              "      <td>4.736369e-03</td>\n",
              "      <td>0.004446</td>\n",
              "      <td>1.559033e-02</td>\n",
              "      <td>2.871540e-03</td>\n",
              "      <td>1.571528e-03</td>\n",
              "      <td>1.022944e-02</td>\n",
              "      <td>0.007386</td>\n",
              "      <td>1.749566e-03</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.003944</td>\n",
              "      <td>2.149959e-03</td>\n",
              "      <td>1.418240e-02</td>\n",
              "      <td>1.260130e-03</td>\n",
              "      <td>5.957670e-03</td>\n",
              "      <td>3.073432e-03</td>\n",
              "      <td>0.003989</td>\n",
              "      <td>2.087914e-02</td>\n",
              "      <td>0.012726</td>\n",
              "      <td>0.000892</td>\n",
              "      <td>1.419724e-02</td>\n",
              "      <td>2.904797e-03</td>\n",
              "      <td>1.156263e-02</td>\n",
              "      <td>1.219874e-02</td>\n",
              "      <td>3.255655e-03</td>\n",
              "      <td>0.004535</td>\n",
              "      <td>0.010324</td>\n",
              "      <td>0.002819</td>\n",
              "      <td>1.212876e-02</td>\n",
              "      <td>0.002005</td>\n",
              "      <td>0.009814</td>\n",
              "      <td>2.062994e-03</td>\n",
              "      <td>1.925486e-03</td>\n",
              "      <td>0.009471</td>\n",
              "      <td>8.939939e-03</td>\n",
              "      <td>0.003778</td>\n",
              "      <td>0.017305</td>\n",
              "      <td>0.018564</td>\n",
              "      <td>5.931315e-03</td>\n",
              "      <td>2.367381e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014124</td>\n",
              "      <td>0.023911</td>\n",
              "      <td>0.001331</td>\n",
              "      <td>4.454609e-02</td>\n",
              "      <td>0.001370</td>\n",
              "      <td>0.005618</td>\n",
              "      <td>0.008779</td>\n",
              "      <td>0.004908</td>\n",
              "      <td>0.003761</td>\n",
              "      <td>6.443375e-03</td>\n",
              "      <td>7.943147e-03</td>\n",
              "      <td>4.748981e-03</td>\n",
              "      <td>0.001273</td>\n",
              "      <td>0.012920</td>\n",
              "      <td>0.005516</td>\n",
              "      <td>0.013401</td>\n",
              "      <td>0.003376</td>\n",
              "      <td>4.807085e-02</td>\n",
              "      <td>0.005378</td>\n",
              "      <td>0.007468</td>\n",
              "      <td>0.001399</td>\n",
              "      <td>0.004963</td>\n",
              "      <td>2.830026e-03</td>\n",
              "      <td>6.302725e-03</td>\n",
              "      <td>3.680681e-03</td>\n",
              "      <td>2.429207e-03</td>\n",
              "      <td>5.253806e-03</td>\n",
              "      <td>1.317900e-02</td>\n",
              "      <td>1.541624e-02</td>\n",
              "      <td>1.806477e-03</td>\n",
              "      <td>0.001315</td>\n",
              "      <td>0.002446</td>\n",
              "      <td>5.431834e-03</td>\n",
              "      <td>1.702015e-03</td>\n",
              "      <td>1.410196e-03</td>\n",
              "      <td>2.444470e-03</td>\n",
              "      <td>0.001890</td>\n",
              "      <td>5.520327e-03</td>\n",
              "      <td>0.028825</td>\n",
              "      <td>4.256441e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fff7d50d848e8014ac1e9172dc6762a3</th>\n",
              "      <td>0.004974</td>\n",
              "      <td>1.360308e-02</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>1.501031e-03</td>\n",
              "      <td>5.108670e-04</td>\n",
              "      <td>1.232025e-03</td>\n",
              "      <td>4.030282e-03</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>1.335793e-03</td>\n",
              "      <td>0.001441</td>\n",
              "      <td>0.001777</td>\n",
              "      <td>7.209315e-03</td>\n",
              "      <td>5.060544e-04</td>\n",
              "      <td>1.591299e-02</td>\n",
              "      <td>8.471883e-04</td>\n",
              "      <td>9.022556e-04</td>\n",
              "      <td>0.002532</td>\n",
              "      <td>1.901405e-03</td>\n",
              "      <td>0.002202</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>1.316248e-03</td>\n",
              "      <td>3.571002e-04</td>\n",
              "      <td>1.424127e-04</td>\n",
              "      <td>1.838190e-02</td>\n",
              "      <td>6.880367e-03</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>0.004687</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>1.160303e-03</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.003072</td>\n",
              "      <td>6.251499e-02</td>\n",
              "      <td>2.788209e-02</td>\n",
              "      <td>0.002276</td>\n",
              "      <td>8.798752e-04</td>\n",
              "      <td>0.030263</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>1.484075e-04</td>\n",
              "      <td>5.889166e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>0.028029</td>\n",
              "      <td>1.005656e-02</td>\n",
              "      <td>0.009420</td>\n",
              "      <td>0.018831</td>\n",
              "      <td>0.000285</td>\n",
              "      <td>0.001711</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>5.807491e-04</td>\n",
              "      <td>4.478310e-04</td>\n",
              "      <td>7.951243e-04</td>\n",
              "      <td>0.006967</td>\n",
              "      <td>0.000921</td>\n",
              "      <td>0.000819</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.001149</td>\n",
              "      <td>1.960635e-03</td>\n",
              "      <td>0.007170</td>\n",
              "      <td>0.002122</td>\n",
              "      <td>0.145995</td>\n",
              "      <td>0.000572</td>\n",
              "      <td>1.256477e-02</td>\n",
              "      <td>1.438673e-02</td>\n",
              "      <td>1.810484e-04</td>\n",
              "      <td>4.378923e-03</td>\n",
              "      <td>6.177075e-03</td>\n",
              "      <td>1.600475e-02</td>\n",
              "      <td>5.622009e-03</td>\n",
              "      <td>1.791264e-01</td>\n",
              "      <td>0.015357</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>1.355010e-03</td>\n",
              "      <td>7.331566e-04</td>\n",
              "      <td>1.529637e-03</td>\n",
              "      <td>8.429556e-03</td>\n",
              "      <td>0.002141</td>\n",
              "      <td>3.251376e-04</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>1.381085e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fffbff22c1f51e3dc80c4bf04089545b</th>\n",
              "      <td>0.001344</td>\n",
              "      <td>3.594427e-02</td>\n",
              "      <td>0.004670</td>\n",
              "      <td>1.601026e-02</td>\n",
              "      <td>1.163873e-03</td>\n",
              "      <td>2.810163e-04</td>\n",
              "      <td>7.491765e-04</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>6.459990e-04</td>\n",
              "      <td>0.000753</td>\n",
              "      <td>0.010510</td>\n",
              "      <td>3.477708e-04</td>\n",
              "      <td>1.943879e-03</td>\n",
              "      <td>4.652996e-04</td>\n",
              "      <td>3.069017e-03</td>\n",
              "      <td>1.798380e-03</td>\n",
              "      <td>0.001506</td>\n",
              "      <td>1.997160e-02</td>\n",
              "      <td>0.042796</td>\n",
              "      <td>0.000302</td>\n",
              "      <td>6.537185e-03</td>\n",
              "      <td>4.304935e-04</td>\n",
              "      <td>2.704362e-03</td>\n",
              "      <td>1.690380e-02</td>\n",
              "      <td>9.738579e-04</td>\n",
              "      <td>0.009055</td>\n",
              "      <td>0.009490</td>\n",
              "      <td>0.000271</td>\n",
              "      <td>2.911597e-03</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.003520</td>\n",
              "      <td>3.044982e-03</td>\n",
              "      <td>1.747489e-03</td>\n",
              "      <td>0.005437</td>\n",
              "      <td>3.704928e-03</td>\n",
              "      <td>0.004727</td>\n",
              "      <td>0.001355</td>\n",
              "      <td>0.004036</td>\n",
              "      <td>6.013023e-04</td>\n",
              "      <td>1.586984e-03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006196</td>\n",
              "      <td>0.006344</td>\n",
              "      <td>0.002894</td>\n",
              "      <td>6.480601e-02</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.002119</td>\n",
              "      <td>0.000805</td>\n",
              "      <td>0.001143</td>\n",
              "      <td>0.003342</td>\n",
              "      <td>7.666300e-04</td>\n",
              "      <td>2.024628e-03</td>\n",
              "      <td>7.961351e-04</td>\n",
              "      <td>0.001002</td>\n",
              "      <td>0.013696</td>\n",
              "      <td>0.004319</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>0.001822</td>\n",
              "      <td>2.507167e-01</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>0.002317</td>\n",
              "      <td>0.000924</td>\n",
              "      <td>0.001278</td>\n",
              "      <td>6.754108e-04</td>\n",
              "      <td>6.677512e-03</td>\n",
              "      <td>7.076709e-04</td>\n",
              "      <td>3.595157e-03</td>\n",
              "      <td>8.907159e-03</td>\n",
              "      <td>4.492850e-03</td>\n",
              "      <td>6.393658e-03</td>\n",
              "      <td>1.679526e-03</td>\n",
              "      <td>0.000673</td>\n",
              "      <td>0.000331</td>\n",
              "      <td>9.683291e-04</td>\n",
              "      <td>4.971435e-04</td>\n",
              "      <td>2.212167e-03</td>\n",
              "      <td>8.146660e-04</td>\n",
              "      <td>0.000840</td>\n",
              "      <td>4.928623e-03</td>\n",
              "      <td>0.009956</td>\n",
              "      <td>6.722719e-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10357 rows × 120 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  affenpinscher  ...  yorkshire_terrier\n",
              "id                                               ...                   \n",
              "000621fb3cbb32d8935728e48679680e       0.001051  ...       1.509213e-03\n",
              "00102ee9d8eb90812350685311fe5890       0.000001  ...       2.015989e-07\n",
              "0012a730dfa437f5f3613fb75efcd4ce       0.001159  ...       2.658817e-03\n",
              "001510bc8570bbeee98c8d80c8a95ec1       0.005452  ...       4.350570e-03\n",
              "001a5f3114548acdefa3d4da05474c2e       0.014099  ...       1.321160e-02\n",
              "...                                         ...  ...                ...\n",
              "ffeda8623d4eee33c6d1156a2ecbfcf8       0.001384  ...       1.292110e-03\n",
              "fff1ec9e6e413275984966f745a313b0       0.000120  ...       1.859115e-04\n",
              "fff74b59b758bbbf13a5793182a9bbe4       0.008316  ...       4.256441e-03\n",
              "fff7d50d848e8014ac1e9172dc6762a3       0.004974  ...       1.381085e-02\n",
              "fffbff22c1f51e3dc80c4bf04089545b       0.001344  ...       6.722719e-04\n",
              "\n",
              "[10357 rows x 120 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4hJ1lszZPdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub.to_csv('./sub.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki6_NP6tcPjE",
        "colab_type": "text"
      },
      "source": [
        "This sub.csv can now be uploaded to kaggle to check test accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgpkWlcEcPLB",
        "colab_type": "text"
      },
      "source": [
        "# TRIALS WITH OTHER BASE MODELS - ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsarbRl5N2Op",
        "colab_type": "code",
        "outputId": "125244b5-1fbb-41b7-a189-a6c63e9fbe7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
        "# Instantiate the model with the pre-trained weights (no top)\n",
        "tf.keras.backend.clear_session()\n",
        "base_model2= ResNet50(weights='imagenet',\n",
        "                 include_top=False, pooling='avg', input_shape = (64,64,3))\n",
        "base_model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 32, 32, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 16, 16, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 16, 16, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 16, 16, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 16, 16, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 16, 16, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 16, 16, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 16, 16, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 16, 16, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 16, 16, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 16, 16, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 16, 16, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 8, 8, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 8, 8, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 8, 8, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 8, 8, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 8, 8, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 8, 8, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 8, 8, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 8, 8, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 8, 8, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 8, 8, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 8, 8, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 8, 8, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 8, 8, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 4, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 4, 4, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 4, 4, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 4, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 4, 4, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 4, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 4, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 4, 4, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 4, 4, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 4, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 4, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 4, 4, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 4, 4, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 4, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 4, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 4, 4, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 4, 4, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 4, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 4, 4, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 4, 4, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 2, 2, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 2, 2, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 2, 2, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8FObW6q23ap",
        "colab_type": "code",
        "outputId": "9928be73-8b3a-4d81-8d0c-592d207c72d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "new_model2 = tf.keras.models.Sequential()\n",
        "new_model2.add(base_model2)\n",
        "new_model2.summary()\n",
        "#base_model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "=================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcq5bdRP28rR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Add Dense Layers after flattening the data\n",
        "new_model2.add(tf.keras.layers.Flatten())\n",
        "new_model2.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "new_model2.add(tf.keras.layers.Dropout(0.5))\n",
        "new_model2.add(tf.keras.layers.BatchNormalization())\n",
        "#new_model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "#new_model.add(tf.keras.layers.BatchNormalization())\n",
        "#new_model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "#new_model.add(tf.keras.layers.BatchNormalization())\n",
        "new_model2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "new_model2.add(tf.keras.layers.Dropout(0.5))\n",
        "new_model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Output Layer\n",
        "new_model2.add(tf.keras.layers.Dense(120, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPZ0xxEg3AP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in new_model2.layers[:1]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckUVPVIl3D39",
        "colab_type": "code",
        "outputId": "e0b90ac3-6206-43c7-dff0-635e0a3cb5e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "for layer in new_model2.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.training.Model object at 0x7fbb022fd8d0> False\n",
            "<tensorflow.python.keras.layers.core.Flatten object at 0x7fb9e3736c88> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb9e3736cc0> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fb9e3736ef0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb9e3738710> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb9e3738278> True\n",
            "<tensorflow.python.keras.layers.core.Dropout object at 0x7fb9e374cfd0> True\n",
            "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fb9e36f1f60> True\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fb9e3753048> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s6ExcpN3GfQ",
        "colab_type": "code",
        "outputId": "b65e730d-baf6-4f1f-9238-697ae37639d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "new_model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 25,984,248\n",
            "Trainable params: 2,393,976\n",
            "Non-trainable params: 23,590,272\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNlQ2nF63InT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "adm = optimizers.Adam(lr = 0.0001)\n",
        "new_model2.compile(optimizer=adm, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcl3nklb3Lb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the best model using model checkpoint callback\n",
        "model_checkpoint=tf.keras.callbacks.ModelCheckpoint('first_model_resnet.h5', \n",
        "                                                    save_best_only=True, \n",
        "                                                    monitor='val_accuracy', \n",
        "                                                    mode='max', \n",
        "                                                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwenbN4B3PVb",
        "colab_type": "code",
        "outputId": "d6802c07-8af8-4d70-fc21-e0f39861b433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train = preprocess_input(X_train)\n",
        "X_val = preprocess_input(X_val)\n",
        "new_model2.fit_generator(datagen.flow(X_train, Y_train,batch_size = 128),\n",
        "          validation_data = (X_val, Y_val),\n",
        "          steps_per_epoch=len(X_train) // 128,\n",
        "                    epochs=100, \n",
        "               callbacks = [model_checkpoint]\n",
        "                    \n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 71 steps, validate on 1023 samples\n",
            "Epoch 1/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.4372 - accuracy: 0.0092\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.01369, saving model to first_model_resnet.h5\n",
            "71/71 [==============================] - 17s 245ms/step - loss: 5.4330 - accuracy: 0.0094 - val_loss: 4.8509 - val_accuracy: 0.0137\n",
            "Epoch 2/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.3795 - accuracy: 0.0095\n",
            "Epoch 00002: val_accuracy did not improve from 0.01369\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 5.3764 - accuracy: 0.0096 - val_loss: 4.8616 - val_accuracy: 0.0137\n",
            "Epoch 3/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.3263 - accuracy: 0.0096\n",
            "Epoch 00003: val_accuracy did not improve from 0.01369\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 5.3274 - accuracy: 0.0095 - val_loss: 4.8703 - val_accuracy: 0.0137\n",
            "Epoch 4/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.2699 - accuracy: 0.0118\n",
            "Epoch 00004: val_accuracy did not improve from 0.01369\n",
            "71/71 [==============================] - 10s 148ms/step - loss: 5.2695 - accuracy: 0.0120 - val_loss: 4.8686 - val_accuracy: 0.0137\n",
            "Epoch 5/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.2228 - accuracy: 0.0131\n",
            "Epoch 00005: val_accuracy improved from 0.01369 to 0.01466, saving model to first_model_resnet.h5\n",
            "71/71 [==============================] - 12s 175ms/step - loss: 5.2247 - accuracy: 0.0129 - val_loss: 4.8666 - val_accuracy: 0.0147\n",
            "Epoch 6/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.1577 - accuracy: 0.0133\n",
            "Epoch 00006: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 5.1572 - accuracy: 0.0132 - val_loss: 4.8638 - val_accuracy: 0.0117\n",
            "Epoch 7/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.1429 - accuracy: 0.0146\n",
            "Epoch 00007: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 5.1415 - accuracy: 0.0150 - val_loss: 4.8622 - val_accuracy: 0.0108\n",
            "Epoch 8/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.0981 - accuracy: 0.0169\n",
            "Epoch 00008: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 5.0985 - accuracy: 0.0169 - val_loss: 4.8630 - val_accuracy: 0.0117\n",
            "Epoch 9/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.0903 - accuracy: 0.0163\n",
            "Epoch 00009: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 5.0912 - accuracy: 0.0164 - val_loss: 4.8607 - val_accuracy: 0.0127\n",
            "Epoch 10/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.0379 - accuracy: 0.0163\n",
            "Epoch 00010: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 5.0374 - accuracy: 0.0162 - val_loss: 4.8621 - val_accuracy: 0.0108\n",
            "Epoch 11/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 5.0001 - accuracy: 0.0183\n",
            "Epoch 00011: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 157ms/step - loss: 5.0011 - accuracy: 0.0186 - val_loss: 4.8688 - val_accuracy: 0.0108\n",
            "Epoch 12/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.9849 - accuracy: 0.0176\n",
            "Epoch 00012: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.9892 - accuracy: 0.0176 - val_loss: 4.8705 - val_accuracy: 0.0108\n",
            "Epoch 13/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.9501 - accuracy: 0.0212\n",
            "Epoch 00013: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 4.9500 - accuracy: 0.0214 - val_loss: 4.8696 - val_accuracy: 0.0108\n",
            "Epoch 14/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.9356 - accuracy: 0.0235\n",
            "Epoch 00014: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.9360 - accuracy: 0.0233 - val_loss: 4.8690 - val_accuracy: 0.0108\n",
            "Epoch 15/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.8945 - accuracy: 0.0244\n",
            "Epoch 00015: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.8938 - accuracy: 0.0244 - val_loss: 4.8711 - val_accuracy: 0.0108\n",
            "Epoch 16/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.8544 - accuracy: 0.0245\n",
            "Epoch 00016: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 153ms/step - loss: 4.8541 - accuracy: 0.0244 - val_loss: 4.8718 - val_accuracy: 0.0108\n",
            "Epoch 17/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.8551 - accuracy: 0.0275\n",
            "Epoch 00017: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.8551 - accuracy: 0.0277 - val_loss: 4.8720 - val_accuracy: 0.0108\n",
            "Epoch 18/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.8298 - accuracy: 0.0281\n",
            "Epoch 00018: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.8305 - accuracy: 0.0282 - val_loss: 4.8746 - val_accuracy: 0.0147\n",
            "Epoch 19/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.8246 - accuracy: 0.0271\n",
            "Epoch 00019: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.8224 - accuracy: 0.0278 - val_loss: 4.8769 - val_accuracy: 0.0127\n",
            "Epoch 20/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.8029 - accuracy: 0.0296\n",
            "Epoch 00020: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 148ms/step - loss: 4.8055 - accuracy: 0.0294 - val_loss: 4.8804 - val_accuracy: 0.0137\n",
            "Epoch 21/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.7685 - accuracy: 0.0294\n",
            "Epoch 00021: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.7700 - accuracy: 0.0297 - val_loss: 4.8798 - val_accuracy: 0.0127\n",
            "Epoch 22/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.7670 - accuracy: 0.0313\n",
            "Epoch 00022: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.7674 - accuracy: 0.0311 - val_loss: 4.8753 - val_accuracy: 0.0108\n",
            "Epoch 23/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.7486 - accuracy: 0.0302\n",
            "Epoch 00023: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 148ms/step - loss: 4.7467 - accuracy: 0.0302 - val_loss: 4.8751 - val_accuracy: 0.0137\n",
            "Epoch 24/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.7215 - accuracy: 0.0314\n",
            "Epoch 00024: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 4.7222 - accuracy: 0.0316 - val_loss: 4.8754 - val_accuracy: 0.0108\n",
            "Epoch 25/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.7025 - accuracy: 0.0331\n",
            "Epoch 00025: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.7016 - accuracy: 0.0333 - val_loss: 4.8802 - val_accuracy: 0.0117\n",
            "Epoch 26/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.6990 - accuracy: 0.0365\n",
            "Epoch 00026: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 4.6992 - accuracy: 0.0364 - val_loss: 4.8857 - val_accuracy: 0.0108\n",
            "Epoch 27/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.6693 - accuracy: 0.0363\n",
            "Epoch 00027: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.6692 - accuracy: 0.0366 - val_loss: 4.8910 - val_accuracy: 0.0108\n",
            "Epoch 28/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.6550 - accuracy: 0.0417\n",
            "Epoch 00028: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.6554 - accuracy: 0.0416 - val_loss: 4.8974 - val_accuracy: 0.0108\n",
            "Epoch 29/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.6319 - accuracy: 0.0407\n",
            "Epoch 00029: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.6323 - accuracy: 0.0411 - val_loss: 4.8984 - val_accuracy: 0.0108\n",
            "Epoch 30/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.6040 - accuracy: 0.0397\n",
            "Epoch 00030: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.6032 - accuracy: 0.0400 - val_loss: 4.9047 - val_accuracy: 0.0108\n",
            "Epoch 31/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.6108 - accuracy: 0.0403\n",
            "Epoch 00031: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.6117 - accuracy: 0.0403 - val_loss: 4.9088 - val_accuracy: 0.0108\n",
            "Epoch 32/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.6061 - accuracy: 0.0428\n",
            "Epoch 00032: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.6100 - accuracy: 0.0423 - val_loss: 4.9150 - val_accuracy: 0.0108\n",
            "Epoch 33/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.5853 - accuracy: 0.0455\n",
            "Epoch 00033: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.5853 - accuracy: 0.0451 - val_loss: 4.9196 - val_accuracy: 0.0108\n",
            "Epoch 34/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.5559 - accuracy: 0.0474\n",
            "Epoch 00034: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 4.5557 - accuracy: 0.0474 - val_loss: 4.9286 - val_accuracy: 0.0108\n",
            "Epoch 35/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.5776 - accuracy: 0.0452\n",
            "Epoch 00035: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.5772 - accuracy: 0.0446 - val_loss: 4.9268 - val_accuracy: 0.0108\n",
            "Epoch 36/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.5519 - accuracy: 0.0469\n",
            "Epoch 00036: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.5527 - accuracy: 0.0469 - val_loss: 4.9243 - val_accuracy: 0.0108\n",
            "Epoch 37/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.5365 - accuracy: 0.0452\n",
            "Epoch 00037: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 148ms/step - loss: 4.5373 - accuracy: 0.0452 - val_loss: 4.9379 - val_accuracy: 0.0108\n",
            "Epoch 38/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.5160 - accuracy: 0.0485\n",
            "Epoch 00038: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.5171 - accuracy: 0.0482 - val_loss: 4.9446 - val_accuracy: 0.0108\n",
            "Epoch 39/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.5142 - accuracy: 0.0498\n",
            "Epoch 00039: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.5116 - accuracy: 0.0504 - val_loss: 4.9485 - val_accuracy: 0.0108\n",
            "Epoch 40/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.5001 - accuracy: 0.0552\n",
            "Epoch 00040: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.4996 - accuracy: 0.0549 - val_loss: 4.9541 - val_accuracy: 0.0108\n",
            "Epoch 41/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.5072 - accuracy: 0.0499\n",
            "Epoch 00041: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.5063 - accuracy: 0.0505 - val_loss: 4.9660 - val_accuracy: 0.0108\n",
            "Epoch 42/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4635 - accuracy: 0.0515\n",
            "Epoch 00042: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 4.4642 - accuracy: 0.0514 - val_loss: 4.9671 - val_accuracy: 0.0108\n",
            "Epoch 43/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4750 - accuracy: 0.0529\n",
            "Epoch 00043: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.4749 - accuracy: 0.0532 - val_loss: 4.9700 - val_accuracy: 0.0108\n",
            "Epoch 44/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4671 - accuracy: 0.0502\n",
            "Epoch 00044: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.4673 - accuracy: 0.0500 - val_loss: 4.9822 - val_accuracy: 0.0108\n",
            "Epoch 45/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4362 - accuracy: 0.0586\n",
            "Epoch 00045: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.4359 - accuracy: 0.0590 - val_loss: 4.9791 - val_accuracy: 0.0108\n",
            "Epoch 46/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4528 - accuracy: 0.0558\n",
            "Epoch 00046: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.4524 - accuracy: 0.0553 - val_loss: 4.9928 - val_accuracy: 0.0108\n",
            "Epoch 47/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4371 - accuracy: 0.0566\n",
            "Epoch 00047: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.4380 - accuracy: 0.0566 - val_loss: 5.0071 - val_accuracy: 0.0108\n",
            "Epoch 48/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4276 - accuracy: 0.0549\n",
            "Epoch 00048: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.4289 - accuracy: 0.0546 - val_loss: 5.0172 - val_accuracy: 0.0108\n",
            "Epoch 49/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4087 - accuracy: 0.0556\n",
            "Epoch 00049: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.4077 - accuracy: 0.0559 - val_loss: 5.0265 - val_accuracy: 0.0108\n",
            "Epoch 50/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4003 - accuracy: 0.0589\n",
            "Epoch 00050: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 155ms/step - loss: 4.4027 - accuracy: 0.0588 - val_loss: 5.0508 - val_accuracy: 0.0108\n",
            "Epoch 51/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.4044 - accuracy: 0.0586\n",
            "Epoch 00051: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 4.4031 - accuracy: 0.0589 - val_loss: 5.0606 - val_accuracy: 0.0108\n",
            "Epoch 52/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3805 - accuracy: 0.0568\n",
            "Epoch 00052: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.3814 - accuracy: 0.0568 - val_loss: 5.0693 - val_accuracy: 0.0108\n",
            "Epoch 53/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3702 - accuracy: 0.0612\n",
            "Epoch 00053: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.3697 - accuracy: 0.0611 - val_loss: 5.0895 - val_accuracy: 0.0108\n",
            "Epoch 54/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3767 - accuracy: 0.0613\n",
            "Epoch 00054: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 4.3793 - accuracy: 0.0609 - val_loss: 5.1163 - val_accuracy: 0.0108\n",
            "Epoch 55/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3682 - accuracy: 0.0623\n",
            "Epoch 00055: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 155ms/step - loss: 4.3696 - accuracy: 0.0624 - val_loss: 5.1224 - val_accuracy: 0.0108\n",
            "Epoch 56/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3693 - accuracy: 0.0583\n",
            "Epoch 00056: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.3685 - accuracy: 0.0582 - val_loss: 5.1364 - val_accuracy: 0.0108\n",
            "Epoch 57/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3574 - accuracy: 0.0635\n",
            "Epoch 00057: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.3536 - accuracy: 0.0644 - val_loss: 5.1386 - val_accuracy: 0.0108\n",
            "Epoch 58/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3325 - accuracy: 0.0670\n",
            "Epoch 00058: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.3321 - accuracy: 0.0671 - val_loss: 5.1371 - val_accuracy: 0.0108\n",
            "Epoch 59/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3237 - accuracy: 0.0679\n",
            "Epoch 00059: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.3234 - accuracy: 0.0676 - val_loss: 5.1269 - val_accuracy: 0.0108\n",
            "Epoch 60/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3264 - accuracy: 0.0739\n",
            "Epoch 00060: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.3251 - accuracy: 0.0739 - val_loss: 5.1279 - val_accuracy: 0.0108\n",
            "Epoch 61/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3207 - accuracy: 0.0704\n",
            "Epoch 00061: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.3209 - accuracy: 0.0702 - val_loss: 5.1404 - val_accuracy: 0.0108\n",
            "Epoch 62/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2925 - accuracy: 0.0730\n",
            "Epoch 00062: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.2928 - accuracy: 0.0728 - val_loss: 5.1561 - val_accuracy: 0.0108\n",
            "Epoch 63/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.3047 - accuracy: 0.0708\n",
            "Epoch 00063: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.3051 - accuracy: 0.0715 - val_loss: 5.1600 - val_accuracy: 0.0108\n",
            "Epoch 64/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2839 - accuracy: 0.0732\n",
            "Epoch 00064: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.2825 - accuracy: 0.0732 - val_loss: 5.1746 - val_accuracy: 0.0117\n",
            "Epoch 65/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2756 - accuracy: 0.0757\n",
            "Epoch 00065: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.2756 - accuracy: 0.0751 - val_loss: 5.2001 - val_accuracy: 0.0108\n",
            "Epoch 66/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2703 - accuracy: 0.0763\n",
            "Epoch 00066: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 155ms/step - loss: 4.2714 - accuracy: 0.0761 - val_loss: 5.2161 - val_accuracy: 0.0117\n",
            "Epoch 67/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2592 - accuracy: 0.0798\n",
            "Epoch 00067: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.2599 - accuracy: 0.0801 - val_loss: 5.2300 - val_accuracy: 0.0127\n",
            "Epoch 68/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2837 - accuracy: 0.0787\n",
            "Epoch 00068: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.2819 - accuracy: 0.0788 - val_loss: 5.2537 - val_accuracy: 0.0127\n",
            "Epoch 69/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2641 - accuracy: 0.0715\n",
            "Epoch 00069: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.2624 - accuracy: 0.0710 - val_loss: 5.2711 - val_accuracy: 0.0117\n",
            "Epoch 70/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2451 - accuracy: 0.0765\n",
            "Epoch 00070: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 153ms/step - loss: 4.2448 - accuracy: 0.0764 - val_loss: 5.2847 - val_accuracy: 0.0117\n",
            "Epoch 71/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2272 - accuracy: 0.0817\n",
            "Epoch 00071: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 152ms/step - loss: 4.2258 - accuracy: 0.0812 - val_loss: 5.2704 - val_accuracy: 0.0117\n",
            "Epoch 72/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2360 - accuracy: 0.0744\n",
            "Epoch 00072: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 157ms/step - loss: 4.2343 - accuracy: 0.0747 - val_loss: 5.2977 - val_accuracy: 0.0117\n",
            "Epoch 73/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2239 - accuracy: 0.0767\n",
            "Epoch 00073: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 151ms/step - loss: 4.2234 - accuracy: 0.0766 - val_loss: 5.3175 - val_accuracy: 0.0117\n",
            "Epoch 74/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2111 - accuracy: 0.0792\n",
            "Epoch 00074: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 150ms/step - loss: 4.2116 - accuracy: 0.0793 - val_loss: 5.3306 - val_accuracy: 0.0117\n",
            "Epoch 75/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2098 - accuracy: 0.0831\n",
            "Epoch 00075: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 153ms/step - loss: 4.2105 - accuracy: 0.0833 - val_loss: 5.3392 - val_accuracy: 0.0117\n",
            "Epoch 76/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2157 - accuracy: 0.0807\n",
            "Epoch 00076: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 149ms/step - loss: 4.2148 - accuracy: 0.0810 - val_loss: 5.3761 - val_accuracy: 0.0117\n",
            "Epoch 77/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1864 - accuracy: 0.0859\n",
            "Epoch 00077: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.1853 - accuracy: 0.0867 - val_loss: 5.3767 - val_accuracy: 0.0088\n",
            "Epoch 78/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1879 - accuracy: 0.0816\n",
            "Epoch 00078: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 158ms/step - loss: 4.1892 - accuracy: 0.0819 - val_loss: 5.3782 - val_accuracy: 0.0078\n",
            "Epoch 79/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.2049 - accuracy: 0.0848\n",
            "Epoch 00079: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 155ms/step - loss: 4.2042 - accuracy: 0.0850 - val_loss: 5.3873 - val_accuracy: 0.0078\n",
            "Epoch 80/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1826 - accuracy: 0.0838\n",
            "Epoch 00080: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 155ms/step - loss: 4.1830 - accuracy: 0.0835 - val_loss: 5.4062 - val_accuracy: 0.0078\n",
            "Epoch 81/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1772 - accuracy: 0.0836\n",
            "Epoch 00081: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 155ms/step - loss: 4.1768 - accuracy: 0.0836 - val_loss: 5.4106 - val_accuracy: 0.0088\n",
            "Epoch 82/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1493 - accuracy: 0.0933\n",
            "Epoch 00082: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.1487 - accuracy: 0.0929 - val_loss: 5.4185 - val_accuracy: 0.0078\n",
            "Epoch 83/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1307 - accuracy: 0.0950\n",
            "Epoch 00083: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 158ms/step - loss: 4.1322 - accuracy: 0.0949 - val_loss: 5.4121 - val_accuracy: 0.0078\n",
            "Epoch 84/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1489 - accuracy: 0.0863\n",
            "Epoch 00084: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.1482 - accuracy: 0.0866 - val_loss: 5.4470 - val_accuracy: 0.0098\n",
            "Epoch 85/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1460 - accuracy: 0.0920\n",
            "Epoch 00085: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.1471 - accuracy: 0.0919 - val_loss: 5.4425 - val_accuracy: 0.0078\n",
            "Epoch 86/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1399 - accuracy: 0.0920\n",
            "Epoch 00086: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.1412 - accuracy: 0.0922 - val_loss: 5.4601 - val_accuracy: 0.0078\n",
            "Epoch 87/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1218 - accuracy: 0.0967\n",
            "Epoch 00087: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.1233 - accuracy: 0.0959 - val_loss: 5.4761 - val_accuracy: 0.0078\n",
            "Epoch 88/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1141 - accuracy: 0.0918\n",
            "Epoch 00088: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 157ms/step - loss: 4.1147 - accuracy: 0.0913 - val_loss: 5.4878 - val_accuracy: 0.0078\n",
            "Epoch 89/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1124 - accuracy: 0.0982\n",
            "Epoch 00089: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 157ms/step - loss: 4.1155 - accuracy: 0.0976 - val_loss: 5.4528 - val_accuracy: 0.0078\n",
            "Epoch 90/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1298 - accuracy: 0.0896\n",
            "Epoch 00090: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.1278 - accuracy: 0.0902 - val_loss: 5.4711 - val_accuracy: 0.0078\n",
            "Epoch 91/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1055 - accuracy: 0.0990\n",
            "Epoch 00091: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 157ms/step - loss: 4.1036 - accuracy: 0.0989 - val_loss: 5.4909 - val_accuracy: 0.0078\n",
            "Epoch 92/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1074 - accuracy: 0.0934\n",
            "Epoch 00092: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.1073 - accuracy: 0.0934 - val_loss: 5.5357 - val_accuracy: 0.0078\n",
            "Epoch 93/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.0988 - accuracy: 0.0955\n",
            "Epoch 00093: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 157ms/step - loss: 4.0980 - accuracy: 0.0955 - val_loss: 5.5642 - val_accuracy: 0.0078\n",
            "Epoch 94/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.0847 - accuracy: 0.0994\n",
            "Epoch 00094: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 158ms/step - loss: 4.0847 - accuracy: 0.0993 - val_loss: 5.5910 - val_accuracy: 0.0078\n",
            "Epoch 95/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.1031 - accuracy: 0.0985\n",
            "Epoch 00095: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.1023 - accuracy: 0.0981 - val_loss: 5.6230 - val_accuracy: 0.0078\n",
            "Epoch 96/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.0814 - accuracy: 0.1031\n",
            "Epoch 00096: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 154ms/step - loss: 4.0803 - accuracy: 0.1033 - val_loss: 5.6607 - val_accuracy: 0.0088\n",
            "Epoch 97/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.0713 - accuracy: 0.0990\n",
            "Epoch 00097: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 160ms/step - loss: 4.0699 - accuracy: 0.0994 - val_loss: 5.7022 - val_accuracy: 0.0127\n",
            "Epoch 98/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.0637 - accuracy: 0.1069\n",
            "Epoch 00098: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 158ms/step - loss: 4.0639 - accuracy: 0.1068 - val_loss: 5.6906 - val_accuracy: 0.0127\n",
            "Epoch 99/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.0567 - accuracy: 0.1039\n",
            "Epoch 00099: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 12s 162ms/step - loss: 4.0571 - accuracy: 0.1033 - val_loss: 5.6910 - val_accuracy: 0.0098\n",
            "Epoch 100/100\n",
            "70/71 [============================>.] - ETA: 0s - loss: 4.0519 - accuracy: 0.1097\n",
            "Epoch 00100: val_accuracy did not improve from 0.01466\n",
            "71/71 [==============================] - 11s 156ms/step - loss: 4.0496 - accuracy: 0.1102 - val_loss: 5.7232 - val_accuracy: 0.0108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb9e369aa58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G-EZrBycXdb",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy with ResNet is very poor. Inception was also tried. Results were not encouraging. So attempt was discarded. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0pVK5Incfm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}