{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('SVHN_single_grey1.h5','r')\n",
    "data = f.get('SVHN_single_grey1.h5')\n",
    "data_as_array = np.array(data)\n",
    "list(f.keys())\n",
    "\n",
    "\n",
    "\n",
    "#data = pd.read_hdf('SVHN_single_grey1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<f4')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(f['X_test'])\n",
    "x_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = f['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(f['y_test'])\n",
    "y_train = f['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 2, ..., 7, 9, 2], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.array(f['X_val'])\n",
    "y_val = np.array(f['y_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is seen that the data gas been read correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "valY = tf.keras.utils.to_categorical(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 10)\n",
      "First 5 examples now are:  [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Data has been converted to catgorical variable  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network is built next. First a Vanilla DNN is built and then DNN with Batch Normalization is added. \n",
    "## Finally CNN is added to see if the accuracy is improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32,)))\n",
    "\n",
    "# Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
    "\n",
    "# Dropout layer\n",
    "#model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(60, activation='relu', name='Layer_3'))\n",
    "model.add(tf.keras.layers.Dense(30, activation='relu', name='Layer_4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "Layer_3 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "Layer_4 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 237,396\n",
      "Trainable params: 235,348\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'h5py._hl.dataset.Dataset'>, <class 'NoneType'>\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 5s 128us/sample - loss: 1.8710 - accuracy: 0.3459 - val_loss: 1.3295 - val_accuracy: 0.5718\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 5s 122us/sample - loss: 1.1879 - accuracy: 0.6220 - val_loss: 0.9689 - val_accuracy: 0.6963\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 6s 134us/sample - loss: 0.9777 - accuracy: 0.6960 - val_loss: 0.9117 - val_accuracy: 0.7218\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 6s 136us/sample - loss: 0.8678 - accuracy: 0.7279 - val_loss: 0.7430 - val_accuracy: 0.7736\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 0.7890 - accuracy: 0.7510 - val_loss: 0.6948 - val_accuracy: 0.7882\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 5s 131us/sample - loss: 0.7340 - accuracy: 0.7719 - val_loss: 0.6747 - val_accuracy: 0.7932\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 6s 132us/sample - loss: 0.6883 - accuracy: 0.7850 - val_loss: 0.6193 - val_accuracy: 0.8115\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 0.6536 - accuracy: 0.7940 - val_loss: 0.6042 - val_accuracy: 0.8166\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 0.6208 - accuracy: 0.8039 - val_loss: 0.5520 - val_accuracy: 0.8347\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 5s 119us/sample - loss: 0.5922 - accuracy: 0.8135 - val_loss: 0.5497 - val_accuracy: 0.8321\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 5s 123us/sample - loss: 0.5673 - accuracy: 0.8203 - val_loss: 0.5391 - val_accuracy: 0.8372\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 6s 135us/sample - loss: 0.5432 - accuracy: 0.8285 - val_loss: 0.5343 - val_accuracy: 0.8390\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 5s 123us/sample - loss: 0.5257 - accuracy: 0.8344 - val_loss: 0.4851 - val_accuracy: 0.8543\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 5s 123us/sample - loss: 0.5070 - accuracy: 0.8386 - val_loss: 0.4843 - val_accuracy: 0.8522\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 5s 120us/sample - loss: 0.4887 - accuracy: 0.8450 - val_loss: 0.4835 - val_accuracy: 0.8543\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 5s 119us/sample - loss: 0.4695 - accuracy: 0.8512 - val_loss: 0.4567 - val_accuracy: 0.8643\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 5s 123us/sample - loss: 0.4567 - accuracy: 0.8547 - val_loss: 0.4961 - val_accuracy: 0.8529\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 5s 121us/sample - loss: 0.4443 - accuracy: 0.8597 - val_loss: 0.4430 - val_accuracy: 0.8684\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 5s 125us/sample - loss: 0.4315 - accuracy: 0.8622 - val_loss: 0.4578 - val_accuracy: 0.8630\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 5s 122us/sample - loss: 0.4166 - accuracy: 0.8666 - val_loss: 0.4375 - val_accuracy: 0.8691\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 5s 123us/sample - loss: 0.4057 - accuracy: 0.8712 - val_loss: 0.4304 - val_accuracy: 0.8729\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 5s 125us/sample - loss: 0.3942 - accuracy: 0.8729 - val_loss: 0.4318 - val_accuracy: 0.8739\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 0.3851 - accuracy: 0.8777 - val_loss: 0.4317 - val_accuracy: 0.8701\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 5s 125us/sample - loss: 0.3744 - accuracy: 0.8791 - val_loss: 0.4212 - val_accuracy: 0.8750\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 0.3644 - accuracy: 0.8831 - val_loss: 0.4444 - val_accuracy: 0.8687\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 0.3592 - accuracy: 0.8858 - val_loss: 0.4290 - val_accuracy: 0.8734\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 5s 128us/sample - loss: 0.3470 - accuracy: 0.8883 - val_loss: 0.4131 - val_accuracy: 0.8780\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 5s 127us/sample - loss: 0.3334 - accuracy: 0.8936 - val_loss: 0.4346 - val_accuracy: 0.8749\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 5s 124us/sample - loss: 0.3257 - accuracy: 0.8958 - val_loss: 0.4319 - val_accuracy: 0.8748\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 5s 126us/sample - loss: 0.3194 - accuracy: 0.8985 - val_loss: 0.4055 - val_accuracy: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x6375baa90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, trainY, validation_data=(x_val, valY), epochs=30,\n",
    "          batch_size = 32, shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/1 - 1s - loss: 0.4966 - accuracy: 0.8327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6806755538185437, 0.83272225]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, testY, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training accuracy is 0.8985\n",
    "### The validation accuracy is 0.8844\n",
    "### The testing accuracy is 0.8327"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model_batch.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32,)))\n",
    "\n",
    "# Normalize the data\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch.add(tf.keras.layers.Dense(1000, activation='relu', name='Layer_1'))\n",
    "\n",
    "# Normalize the data\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "model_batch.add(tf.keras.layers.Dense(500, activation='relu', name='Layer_2'))\n",
    "\n",
    "# Normalize the data\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Dropout layer\n",
    "#model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Hidden layers\n",
    "model_batch.add(tf.keras.layers.Dense(250, activation='relu', name='Layer_3'))\n",
    "\n",
    "# Normalize the data\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "model_batch.add(tf.keras.layers.Dense(125, activation='relu', name='Layer_4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model_batch.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "Layer_3 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "Layer_4 (Dense)              (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                1260      \n",
      "=================================================================\n",
      "Total params: 1,694,481\n",
      "Trainable params: 1,688,933\n",
      "Non-trainable params: 5,548\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_batch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'h5py._hl.dataset.Dataset'>, <class 'NoneType'>\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 17s 401us/sample - loss: 1.4213 - accuracy: 0.5256 - val_loss: 0.9175 - val_accuracy: 0.7142\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 17s 412us/sample - loss: 0.9483 - accuracy: 0.6933 - val_loss: 0.7732 - val_accuracy: 0.7578\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 17s 397us/sample - loss: 0.7849 - accuracy: 0.7499 - val_loss: 0.6706 - val_accuracy: 0.7896\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 18s 421us/sample - loss: 0.6693 - accuracy: 0.7871 - val_loss: 0.5834 - val_accuracy: 0.8197\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 16s 380us/sample - loss: 0.5811 - accuracy: 0.8162 - val_loss: 0.5856 - val_accuracy: 0.8158\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 16s 392us/sample - loss: 0.5082 - accuracy: 0.8377 - val_loss: 0.5580 - val_accuracy: 0.8278\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 17s 394us/sample - loss: 0.4467 - accuracy: 0.8592 - val_loss: 0.5174 - val_accuracy: 0.8395\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 18s 423us/sample - loss: 0.3917 - accuracy: 0.8771 - val_loss: 0.4681 - val_accuracy: 0.8569\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 17s 413us/sample - loss: 0.3450 - accuracy: 0.8937 - val_loss: 0.4727 - val_accuracy: 0.8545\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 18s 418us/sample - loss: 0.2969 - accuracy: 0.9084 - val_loss: 0.4361 - val_accuracy: 0.8667\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 17s 416us/sample - loss: 0.2583 - accuracy: 0.9216 - val_loss: 0.4232 - val_accuracy: 0.8718\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 18s 418us/sample - loss: 0.2158 - accuracy: 0.9359 - val_loss: 0.4098 - val_accuracy: 0.8770\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 19s 454us/sample - loss: 0.1916 - accuracy: 0.9427 - val_loss: 0.4104 - val_accuracy: 0.8782\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 17s 416us/sample - loss: 0.1597 - accuracy: 0.9536 - val_loss: 0.4233 - val_accuracy: 0.8757\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 17s 407us/sample - loss: 0.1337 - accuracy: 0.9622 - val_loss: 0.3931 - val_accuracy: 0.8875\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 17s 406us/sample - loss: 0.1113 - accuracy: 0.9692 - val_loss: 0.4081 - val_accuracy: 0.8857\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 17s 408us/sample - loss: 0.0998 - accuracy: 0.9735 - val_loss: 0.3931 - val_accuracy: 0.8905\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 19s 443us/sample - loss: 0.0777 - accuracy: 0.9802 - val_loss: 0.4105 - val_accuracy: 0.8893\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 17s 417us/sample - loss: 0.0608 - accuracy: 0.9846 - val_loss: 0.4394 - val_accuracy: 0.8826\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 18s 427us/sample - loss: 0.0507 - accuracy: 0.9882 - val_loss: 0.3794 - val_accuracy: 0.8990\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 18s 421us/sample - loss: 0.0405 - accuracy: 0.9915 - val_loss: 0.3707 - val_accuracy: 0.9044\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 19s 441us/sample - loss: 0.0389 - accuracy: 0.9910 - val_loss: 0.3783 - val_accuracy: 0.9034\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 17s 410us/sample - loss: 0.0261 - accuracy: 0.9948 - val_loss: 0.3740 - val_accuracy: 0.9056\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 17s 405us/sample - loss: 0.0202 - accuracy: 0.9965 - val_loss: 0.3550 - val_accuracy: 0.9122\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 17s 405us/sample - loss: 0.0148 - accuracy: 0.9978 - val_loss: 0.3602 - val_accuracy: 0.9129\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 17s 404us/sample - loss: 0.0097 - accuracy: 0.9988 - val_loss: 0.3507 - val_accuracy: 0.9164\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 18s 418us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9201\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 18s 418us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9210\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 18s 420us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9208\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 18s 425us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x637b96450>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_batch.fit(x_train, trainY, validation_data=(x_val, valY), epochs=30,\n",
    "          batch_size = 32, shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/1 - 1s - loss: 0.4895 - accuracy: 0.8362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8554650974505478, 0.83622223]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_batch.evaluate(x_test, testY, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training accuracy is 1.0000\n",
    "### The validation accuracy is 0.9215\n",
    "### The testing accuracy is 0.8362\n",
    "##### Performance is slightly better than Vanilla network but overfitting is definately present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "#Initialize model, reshape & normalize data\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D (28,28) to 3D (28, 28, 1)\n",
    "model.add(tf.keras.layers.Reshape((32,32,1),input_shape=(32,32,)))\n",
    "\n",
    "#normalize data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add first convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(32, #Number of filters \n",
    "                                 kernel_size=(3,3), #Size of the filter\n",
    "                                 activation='relu'))\n",
    "\n",
    "#Add second convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "#Add MaxPooling layer\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the output\n",
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense layer\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "#Add another dropout layer\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,625,870\n",
      "Trainable params: 1,625,868\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'h5py._hl.dataset.Dataset'>, <class 'NoneType'>\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/15\n",
      "42000/42000 [==============================] - 72s 2ms/sample - loss: 0.3537 - accuracy: 0.8933 - val_loss: 0.2951 - val_accuracy: 0.9198\n",
      "Epoch 2/15\n",
      "42000/42000 [==============================] - 73s 2ms/sample - loss: 0.3205 - accuracy: 0.9028 - val_loss: 0.2697 - val_accuracy: 0.9270\n",
      "Epoch 3/15\n",
      "42000/42000 [==============================] - 74s 2ms/sample - loss: 0.2867 - accuracy: 0.9142 - val_loss: 0.2439 - val_accuracy: 0.9344\n",
      "Epoch 4/15\n",
      "42000/42000 [==============================] - 70s 2ms/sample - loss: 0.2618 - accuracy: 0.9203 - val_loss: 0.2315 - val_accuracy: 0.9396\n",
      "Epoch 5/15\n",
      "42000/42000 [==============================] - 70s 2ms/sample - loss: 0.2331 - accuracy: 0.9288 - val_loss: 0.2162 - val_accuracy: 0.9440\n",
      "Epoch 6/15\n",
      "42000/42000 [==============================] - 70s 2ms/sample - loss: 0.2152 - accuracy: 0.9343 - val_loss: 0.2025 - val_accuracy: 0.9474\n",
      "Epoch 7/15\n",
      "42000/42000 [==============================] - 70s 2ms/sample - loss: 0.1933 - accuracy: 0.9395 - val_loss: 0.1965 - val_accuracy: 0.9513\n",
      "Epoch 8/15\n",
      "42000/42000 [==============================] - 71s 2ms/sample - loss: 0.1804 - accuracy: 0.9432 - val_loss: 0.1905 - val_accuracy: 0.9533\n",
      "Epoch 9/15\n",
      "42000/42000 [==============================] - 70s 2ms/sample - loss: 0.1646 - accuracy: 0.9499 - val_loss: 0.1788 - val_accuracy: 0.9573\n",
      "Epoch 10/15\n",
      "42000/42000 [==============================] - 70s 2ms/sample - loss: 0.1492 - accuracy: 0.9530 - val_loss: 0.1795 - val_accuracy: 0.9569\n",
      "Epoch 11/15\n",
      "42000/42000 [==============================] - 76s 2ms/sample - loss: 0.1400 - accuracy: 0.9565 - val_loss: 0.1696 - val_accuracy: 0.9600\n",
      "Epoch 12/15\n",
      "42000/42000 [==============================] - 75s 2ms/sample - loss: 0.1306 - accuracy: 0.9590 - val_loss: 0.1685 - val_accuracy: 0.9626\n",
      "Epoch 13/15\n",
      "42000/42000 [==============================] - 75s 2ms/sample - loss: 0.1237 - accuracy: 0.9613 - val_loss: 0.1662 - val_accuracy: 0.9631\n",
      "Epoch 14/15\n",
      "42000/42000 [==============================] - 75s 2ms/sample - loss: 0.1120 - accuracy: 0.9648 - val_loss: 0.1681 - val_accuracy: 0.9630\n",
      "Epoch 15/15\n",
      "42000/42000 [==============================] - 75s 2ms/sample - loss: 0.1088 - accuracy: 0.9660 - val_loss: 0.1598 - val_accuracy: 0.9662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x63ac2be10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(x_train,trainY,          \n",
    "          validation_data=(x_val,valY),\n",
    "          epochs=15,\n",
    "          batch_size=32, shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/1 - 4s - loss: 0.4228 - accuracy: 0.9035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47568908135096233, 0.9035]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, testY, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training accuracy is 0.9660rchi\n",
    "### The validation accuracy is 0.9662\n",
    "### The testing accuracy is 0.9035\n",
    "##### Performace is much better with CNN\n",
    "\n",
    "\n",
    "#### Potential to improve\n",
    "- Architecture\n",
    "- SGD is used here but Adam might improve model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question/Note to moderator\n",
    "- This notebook works as expected locally on all machines (Windows, Mac and Linux tested)\n",
    "- All the models in this notebook stop learning (0.1 accuracy) on Google Colab\n",
    "- Why is this happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
